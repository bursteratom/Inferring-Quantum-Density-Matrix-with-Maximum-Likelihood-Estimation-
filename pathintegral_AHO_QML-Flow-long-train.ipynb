{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pylab\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "#from category_encoders import *\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "# import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "pylab.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as integrate\n",
    "from numpy import sqrt, sin, cos, pi, tan, sinh, cosh, exp, tanh, log, log10\n",
    "import scipy.special as ssf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 CPUs\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count\n",
    "import emcee\n",
    "from tqdm import tqdm\n",
    "\n",
    "ncpu = cpu_count()\n",
    "print(\"{0} CPUs\".format(ncpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lower(side_len):\n",
    "    mask = np.zeros((side_len, side_len), dtype = np.intc)\n",
    "    for i in range(side_len):\n",
    "        for j in range(i+1):\n",
    "            mask[i, j] = 1\n",
    "    mask = torch.from_numpy(mask)\n",
    "    return mask\n",
    "\n",
    "def make_diag(side_len):\n",
    "    mask = np.zeros((side_len, side_len), dtype = np.intc)\n",
    "    for i in range(side_len):\n",
    "        mask[i, i] = 1\n",
    "    mask = torch.from_numpy(mask)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psiHOpoint(n, x):\n",
    "    return exp(-0.5*x*x)*ssf.hermite(n)(x)/sqrt(math.factorial(n)*sqrt(pi)*2**n)\n",
    "\n",
    "def psiHO(n, x):\n",
    "    x=np.array(x)\n",
    "    return exp(-0.5*x*x)*ssf.hermite(n)(x)/sqrt(math.factorial(n)*sqrt(pi)*2**n)\n",
    "\n",
    "def psiHOall(n, x):\n",
    "    return np.array([psiHO(i, x) for i in range(n+1)])\n",
    "\n",
    "def HM(n, x):\n",
    "    return np.array([psiHO(i, x) for i in range(n+1)]).T\n",
    "\n",
    "def FM(k, L, x): #k Fourier modes in the interval (-L,L)\n",
    "    x=np.array(x)\n",
    "    xkmat = np.reshape(x, [len(x),1])*np.array(range(1,k+1))\n",
    "    zeromode = 1/sqrt(2*L)*np.ones([len(x),1])\n",
    "    cosmodes = cos(xkmat*pi/L)/sqrt(L)\n",
    "    sinmodes = sin(xkmat*pi/L)/sqrt(L)\n",
    "    return np.concatenate((zeromode,cosmodes,sinmodes),axis=1)\n",
    "\n",
    "def FCpsiHO(n, k, L) :#k Fourier coefficients for the nth harmonic oscillator wavefunction in (-L,L)\n",
    "    coeff0 = np.array([integrate.quad(lambda x: psiHOpoint(n, x)/sqrt(2*L), -L, L)[0]])\n",
    "    coeffcos = np.array([integrate.quad(lambda x: psiHOpoint(n, x)*cos(x*i*pi/L)/sqrt(L), -L, L)[0] \\\n",
    "                         for i in range(1,k+1)])\n",
    "    coeffsin = np.array([integrate.quad(lambda x: psiHOpoint(n, x)*sin(x*i*pi/L)/sqrt(L), -L, L)[0] \\\n",
    "                         for i in range(1,k+1)])\n",
    "    return np.concatenate((coeff0,coeffcos,coeffsin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FM0(k, L, x): #k Fourier modes in the interval (-L,L)\n",
    "    kvec = np.array(range(1,k+1))\n",
    "    zeromode = 1/sqrt(2*L)\n",
    "    cosmodes = cos(kvec*x*pi/L)/sqrt(L)\n",
    "    sinmodes = sin(kvec*x*pi/L)/sqrt(L)\n",
    "    return np.concatenate(([zeromode],cosmodes,sinmodes))\n",
    "\n",
    "def D2FM0(k, L, x): #second derivative of k Fourier modes in the interval (-L,L)\n",
    "    kvec = np.array(range(1,k+1))\n",
    "    zeromode = 0\n",
    "    cosmodes = -(kvec*pi/L)**2*cos(kvec*x*pi/L)/sqrt(L)\n",
    "    sinmodes = -(kvec*pi/L)**2*sin(kvec*x*pi/L)/sqrt(L)\n",
    "    return np.concatenate(([zeromode],cosmodes,sinmodes))\n",
    "\n",
    "def H_HO_FM_int(k, L):\n",
    "    return np.array([[integrate.quad(lambda x: FM0(k, L, x)[i]*(x**2*FM0(k, L, x)[j]- D2FM0(k, L, x)[j]), -L, L)[0] \\\n",
    "                     for i in range(2*k+1)] for j in range(2*k+1)])\n",
    "\n",
    "def V_AHO(x):\n",
    "    return -x**2/2-x+x**4/16\n",
    "\n",
    "def H_AHO_FM_int(k, L, V): #V is the function that calculates the potential\n",
    "    return np.array([[integrate.quad(lambda x: FM0(k, L, x)[i]*(2*V(x)*FM0(k, L, x)[j]- D2FM0(k, L, x)[j]), -L, L)[0] \\\n",
    "                     for i in range(2*k+1)] for j in range(2*k+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tridiag(a, b, c, k1=-1, k2=0, k3=1):\n",
    "    return np.diag(a, k1) + np.diag(b, k2) + np.diag(c, k3)\n",
    "\n",
    "def K(n):\n",
    "    upper = -1*np.ones(n-1)\n",
    "    center = np.concatenate(([1],2*np.ones(n-2),[1]))\n",
    "    return tridiag(upper,center,upper)\n",
    "\n",
    "def covHO(n,a):\n",
    "    upper = -1*np.ones(n-1)\n",
    "    center = np.concatenate(([1+a**2],(2+a**2)*np.ones(n-2),[1+a**2]))\n",
    "    return np.linalg.inv(1/a*tridiag(upper,center,upper))\n",
    "\n",
    "def solveHOE(t,a,b,T):\n",
    "    t=np.array(t)\n",
    "    return a*cosh(t) + (-a*cosh(T)/sinh(T) + b/sinh(T))*sinh(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def V_AHO(x):\n",
    "    return -x**2/2-x+x**4/16\n",
    "\n",
    "def lnprob_V(x, n, a):\n",
    "    return -np.dot(x,np.dot(K(n),x))/2.0/a - np.sum(a*V_AHO(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HM_PT(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, n=10):\n",
    "        ctx.save_for_backward(x)\n",
    "        x_np = x.numpy()\n",
    "        z = HM(n,x_np)\n",
    "        \n",
    "        return torch.from_numpy(z)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output_torch):\n",
    "        [x_torch] = ctx.saved_tensors\n",
    "\n",
    "        x = x_torch.numpy()\n",
    "        [x_len, n] = list(grad_output_torch.size())\n",
    "        \n",
    "        \n",
    "        psiHO_der = np.array([exp(-0.5*x*x)*(x*ssf.hermite(i)(x) - ssf.hermite(i+1)(x))/sqrt(math.factorial(i)*sqrt(pi)*2**i) \\\n",
    "                                                                                        for i in range(n)])\n",
    "        psiHO_der = torch.from_numpy(psiHO_der)\n",
    "        grad_input = [torch.matmul(grad_output_torch[i,:], psiHO_der[:,i]) for i in range(x_len)]\n",
    "        \n",
    "\n",
    "        return torch.Tensor(grad_input), None\n",
    "    \n",
    "def flow(coeff, x, latt_pt):\n",
    "    coeff = coeff.reshape([-1,1])\n",
    "    x = x.reshape([-1,1]) \n",
    "    latt_pt = latt_pt.reshape([1, -1])\n",
    "    a = x - latt_pt\n",
    "    z = torch.tanh(a)\n",
    "    z = torch.matmul(z, coeff)\n",
    "    z = z.reshape(-1,)\n",
    "    \n",
    "    det_x = torch.matmul(1/(torch.cosh(a)**2), coeff)\n",
    "    \n",
    "    return z, det_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QML(nn.Module):\n",
    "    def __init__(self, n_ES, n_B):\n",
    "        super(QML, self).__init__()\n",
    "        \n",
    "        self.n_Ba = n_B\n",
    "        self.n_EL = n_ES + 1\n",
    "        \n",
    "        n_latt_spacing = 400\n",
    "        self.fl_prm = torch.nn.Parameter(torch.from_numpy(np.ones((n_latt_spacing+1,), dtype = float)))\n",
    "        self.fl_prm.requires_grad = True\n",
    "        self.latt_pt = torch.from_numpy(np.linspace(-10, 10, num = n_latt_spacing+1))\n",
    "        self.latt_pt.requires_grad = False\n",
    "        \n",
    "        self.levels = torch.nn.Parameter(torch.from_numpy(np.random.uniform(1,2,self.n_EL)))\n",
    "        self.levels.requires_grad = True\n",
    "        \n",
    "        self.var_BaC = torch.nn.Parameter(torch.from_numpy(np.random.uniform(-1,1,[self.n_Ba, self.n_EL])))\n",
    "        self.var_BaC.requires_grad = True\n",
    "        \n",
    "        self.mask = (make_lower(self.n_EL) - make_diag(self.n_EL) ) > 0 #convert to boolean\n",
    "        self.diag = make_diag(self.n_EL) > 0 #convert to boolean  \n",
    "   \n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        fl_var = self.fl_prm * self.fl_prm\n",
    "        [fl_x, det_fl_x] = flow(fl_var, x, self.latt_pt)\n",
    "        [fl_y, det_fl_y] = flow(fl_var, y, self.latt_pt)\n",
    "        hm = HM_PT.apply\n",
    "        psi_x = hm(fl_x, self.n_Ba-1)\n",
    "        psi_y = hm(fl_y, self.n_Ba-1)\n",
    "        \n",
    "        psi_x = torch.sqrt(det_fl_x) * psi_x\n",
    "        psi_y = torch.sqrt(det_fl_y) * psi_y\n",
    "        \n",
    "        norms_BaC = torch.linalg.norm(self.var_BaC, dim = 0)\n",
    "        var_BaC_N = self.var_BaC/norms_BaC\n",
    "        logits = F.softmin(self.levels, dim = 0)\n",
    "        \n",
    "        c_orth = 1000\n",
    "        loss_orth = c_orth * torch.mean(torch.masked_select(torch.matmul(torch.transpose(var_BaC_N, 0, 1),var_BaC_N) \\\n",
    "                                                                  , self.mask)**2)\n",
    "        \n",
    "        loss_ML = -1 * torch.mean(torch.matmul( torch.matmul(psi_x, var_BaC_N) * torch.matmul(psi_y, var_BaC_N) \\\n",
    "                    , torch.log(logits*(10**4.)+1) ) )\n",
    "        \n",
    "        loss = loss_orth + loss_ML\n",
    "        \n",
    "        return loss, loss_ML, loss_orth, self.levels, logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train_states_QML(G, in_x, in_y, batch_size = 500, epochs = 200000, step = 1e-3):\n",
    "    n_samples = len(in_x)\n",
    "        \n",
    "        \n",
    "    optimiser = torch.optim.Adam(G.parameters(), lr=step)\n",
    "    \n",
    "    \n",
    "    loss_hist = np.zeros((epochs,), dtype = float)\n",
    "    loss_ML_hist = np.zeros((epochs,), dtype = float)\n",
    "    loss_orth_hist = np.zeros((epochs,), dtype = float)\n",
    "    \n",
    "    levels_hist = np.zeros((epochs, G.n_EL), dtype = float)\n",
    "    logits_hist = np.zeros((epochs, G.n_EL), dtype = float)\n",
    "        \n",
    "        \n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        idx = np.random.choice(n_samples, batch_size, replace=True)\n",
    "        #mini_in_x = in_x[idx]\n",
    "        #mini_in_y = in_y[idx]\n",
    "        \n",
    "        #loop_start = time.time()\n",
    "        \n",
    "        [loss, loss_ML, loss_orth, levels, logits] = G(in_x[idx], in_y[idx])\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        \n",
    "        loss_hist[i] = loss.tolist()\n",
    "        loss_ML_hist[i] = loss_ML.tolist()\n",
    "        loss_orth_hist[i] = loss_orth.tolist()\n",
    "        \n",
    "        levels_hist[i, :] = levels.tolist()\n",
    "        logits_hist[i, :] = logits.tolist()\n",
    "            \n",
    "        #loop_end = time.time()\n",
    "        #print('Time taken for loop ' + str(i) + ': {0:.3f} seconds'.format(loop_end - loop_start))\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "                \n",
    "            print('Batch number ', i)\n",
    "            print('Loss: ', loss_hist[i])\n",
    "            print('Loss_orth: ', loss_orth_hist[i])\n",
    "            print('Loss_ML: ', loss_ML_hist[i])\n",
    "            print('Logits: ', logits)\n",
    "            end_time = time.time()\n",
    "            print('Time taken: {0:.3f} seconds'.format(end_time - start_time))\n",
    "            start_time = time.time()\n",
    "            print('@----------------------------------------------------------@')\n",
    "            #writer.add_summary(summary, i)\n",
    "            #writer.flush()\n",
    "                \n",
    "        \n",
    "          \n",
    "                \n",
    "    var_BaC = G.var_BaC\n",
    "    norms_BaC = torch.linalg.norm(var_BaC, dim = 0)\n",
    "    var_BaC_N = (var_BaC / norms_BaC).detach().numpy() #normalise the coefficients of basis states\n",
    "    levels_hist = np.array(levels_hist)\n",
    "    logits_hist = np.array(logits_hist)\n",
    "    \n",
    "    \n",
    "    ##Sort energy levels and associated coefficients of basis states in ascending order\n",
    "    fin_EL = G.levels\n",
    "    fin_EL = fin_EL.detach()\n",
    "    fin_logits = F.softmin(fin_EL, dim = 0)\n",
    "    fin_EL = fin_EL.numpy()\n",
    "    fin_logits = fin_logits.numpy()\n",
    "    fl_coeff = (G.fl_prm * G.fl_prm).detach().numpy()\n",
    "    \n",
    "    fin_EL_argsort = fin_EL.argsort()\n",
    "    levels_hist = levels_hist[:, fin_EL_argsort]\n",
    "    logits_hist = logits_hist[:, fin_EL_argsort]\n",
    "    var_BaC_N = var_BaC_N[:, fin_EL_argsort]\n",
    "    fin_EL = fin_EL[fin_EL_argsort]\n",
    "    fin_logits = fin_logits[fin_EL_argsort]\n",
    "    #EL_ranks = np.empty_like(fin_EL_argsort)\n",
    "    #EL_ranks[fin_EL_argsort] = np.arange(len(fin_EL))\n",
    "    \n",
    "    return loss_hist, loss_ML_hist, loss_orth_hist, levels_hist, logits_hist, var_BaC_N, fl_coeff, fin_EL, fin_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000000, 40)\n"
     ]
    }
   ],
   "source": [
    "infile = \"AHO_PI_MCMC_T\" + str(T) + \".npy\"\n",
    "paths = np.load(infile)\n",
    "print(paths.shape)\n",
    "\n",
    "x = torch.from_numpy(paths[:, 0])\n",
    "y = torch.from_numpy(paths[:, -1])\n",
    "\n",
    "del paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00257110595703125\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100000000\n",
    "batch_size = 500\n",
    "start_time = time.time()\n",
    "idx = np.random.choice(n_samples, batch_size, replace=True)\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scl489/.env/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  0\n",
      "Loss:  83.6453107483901\n",
      "Loss_orth:  83.64613219058762\n",
      "Loss_ML:  -0.0008214421975240239\n",
      "Logits:  tensor([0.0807, 0.1002, 0.0712, 0.1061, 0.0888, 0.1436, 0.1006, 0.0857, 0.0649,\n",
      "        0.0850, 0.0732], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 0.350 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  1000\n",
      "Loss:  -0.26303308823356614\n",
      "Loss_orth:  0.0003943133753145555\n",
      "Loss_ML:  -0.2634274016088807\n",
      "Logits:  tensor([0.0870, 0.1163, 0.0654, 0.1161, 0.0846, 0.1284, 0.1092, 0.0739, 0.0652,\n",
      "        0.0853, 0.0686], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.675 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  2000\n",
      "Loss:  -0.028258788574325\n",
      "Loss_orth:  0.0002750553722276197\n",
      "Loss_ML:  -0.02853384394655262\n",
      "Logits:  tensor([0.0987, 0.1401, 0.0590, 0.1269, 0.0848, 0.1063, 0.1057, 0.0671, 0.0658,\n",
      "        0.0806, 0.0650], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.071 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  3000\n",
      "Loss:  -0.15268104110608594\n",
      "Loss_orth:  0.0004437246972954984\n",
      "Loss_ML:  -0.15312476580338144\n",
      "Logits:  tensor([0.1071, 0.1620, 0.0549, 0.1329, 0.0830, 0.0925, 0.1032, 0.0615, 0.0613,\n",
      "        0.0793, 0.0624], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.640 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  4000\n",
      "Loss:  -0.0009149205973016902\n",
      "Loss_orth:  0.00047844239752214404\n",
      "Loss_ML:  -0.0013933629948238342\n",
      "Logits:  tensor([0.1159, 0.1900, 0.0480, 0.1374, 0.0840, 0.0815, 0.0998, 0.0541, 0.0609,\n",
      "        0.0715, 0.0569], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.948 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  5000\n",
      "Loss:  0.06246538074803571\n",
      "Loss_orth:  0.0009465102599045408\n",
      "Loss_ML:  0.06151887048813117\n",
      "Logits:  tensor([0.1251, 0.2228, 0.0429, 0.1383, 0.0768, 0.0757, 0.0981, 0.0459, 0.0563,\n",
      "        0.0664, 0.0518], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.198 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  6000\n",
      "Loss:  0.0004763621397910114\n",
      "Loss_orth:  0.00047615641268070367\n",
      "Loss_ML:  2.0572711030773467e-07\n",
      "Logits:  tensor([0.1281, 0.2399, 0.0443, 0.1414, 0.0727, 0.0638, 0.0980, 0.0401, 0.0575,\n",
      "        0.0667, 0.0474], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.222 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  7000\n",
      "Loss:  -0.01935290734767043\n",
      "Loss_orth:  0.0015884533886330239\n",
      "Loss_ML:  -0.020941360736303455\n",
      "Logits:  tensor([0.1389, 0.2391, 0.0435, 0.1456, 0.0721, 0.0570, 0.0977, 0.0371, 0.0573,\n",
      "        0.0663, 0.0454], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.679 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  8000\n",
      "Loss:  0.001475696622035532\n",
      "Loss_orth:  0.0014756966221528686\n",
      "Loss_ML:  -1.1733645202692052e-13\n",
      "Logits:  tensor([0.1403, 0.2561, 0.0391, 0.1497, 0.0702, 0.0512, 0.1004, 0.0337, 0.0549,\n",
      "        0.0626, 0.0418], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.933 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  9000\n",
      "Loss:  0.06464551612734666\n",
      "Loss_orth:  0.0005970704289243978\n",
      "Loss_ML:  0.06404844569842226\n",
      "Logits:  tensor([0.1443, 0.2681, 0.0363, 0.1581, 0.0673, 0.0509, 0.0931, 0.0312, 0.0531,\n",
      "        0.0595, 0.0381], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.758 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  10000\n",
      "Loss:  -0.007429953356545813\n",
      "Loss_orth:  0.001215863279666184\n",
      "Loss_ML:  -0.008645816636211997\n",
      "Logits:  tensor([0.1411, 0.2866, 0.0341, 0.1672, 0.0668, 0.0448, 0.0895, 0.0287, 0.0493,\n",
      "        0.0563, 0.0356], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.812 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  11000\n",
      "Loss:  0.0806297968938597\n",
      "Loss_orth:  0.0018326821104355066\n",
      "Loss_ML:  0.07879711478342419\n",
      "Logits:  tensor([0.1446, 0.3071, 0.0325, 0.1686, 0.0609, 0.0393, 0.0888, 0.0281, 0.0440,\n",
      "        0.0523, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.983 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  12000\n",
      "Loss:  -0.06020691340692672\n",
      "Loss_orth:  0.0010071059278593027\n",
      "Loss_ML:  -0.06121401933478603\n",
      "Logits:  tensor([0.1433, 0.3232, 0.0298, 0.1690, 0.0573, 0.0350, 0.0913, 0.0253, 0.0439,\n",
      "        0.0485, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.753 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  13000\n",
      "Loss:  -0.049840066876603965\n",
      "Loss_orth:  0.0010964948632396668\n",
      "Loss_ML:  -0.05093656173984363\n",
      "Logits:  tensor([0.1394, 0.3317, 0.0290, 0.1759, 0.0540, 0.0325, 0.0916, 0.0237, 0.0436,\n",
      "        0.0465, 0.0320], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.564 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  14000\n",
      "Loss:  0.0013586511214876244\n",
      "Loss_orth:  0.0013603112887763606\n",
      "Loss_ML:  -1.6601672887360794e-06\n",
      "Logits:  tensor([0.1421, 0.3625, 0.0270, 0.1694, 0.0493, 0.0315, 0.0870, 0.0212, 0.0386,\n",
      "        0.0429, 0.0285], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.780 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  15000\n",
      "Loss:  -0.1436163026583867\n",
      "Loss_orth:  0.001144196591331096\n",
      "Loss_ML:  -0.14476049924971782\n",
      "Logits:  tensor([0.1388, 0.3872, 0.0269, 0.1633, 0.0447, 0.0300, 0.0837, 0.0204, 0.0372,\n",
      "        0.0400, 0.0278], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.237 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  16000\n",
      "Loss:  -0.10277855924732683\n",
      "Loss_orth:  0.0014137567800214881\n",
      "Loss_ML:  -0.10419231602734833\n",
      "Logits:  tensor([0.1340, 0.4346, 0.0244, 0.1574, 0.0386, 0.0266, 0.0756, 0.0182, 0.0312,\n",
      "        0.0359, 0.0235], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.641 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  17000\n",
      "Loss:  -0.14810153367095094\n",
      "Loss_orth:  0.001700437142861362\n",
      "Loss_ML:  -0.1498019708138123\n",
      "Logits:  tensor([0.1268, 0.4774, 0.0222, 0.1533, 0.0335, 0.0236, 0.0682, 0.0167, 0.0273,\n",
      "        0.0302, 0.0207], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.295 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  18000\n",
      "Loss:  -0.16280135898729856\n",
      "Loss_orth:  0.0014149604101650422\n",
      "Loss_ML:  -0.1642163193974636\n",
      "Logits:  tensor([0.1250, 0.5013, 0.0198, 0.1521, 0.0319, 0.0211, 0.0621, 0.0163, 0.0240,\n",
      "        0.0281, 0.0182], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.368 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  19000\n",
      "Loss:  -0.0003636615180322199\n",
      "Loss_orth:  0.0016679083554167386\n",
      "Loss_ML:  -0.0020315698734489586\n",
      "Logits:  tensor([0.1164, 0.5476, 0.0175, 0.1373, 0.0292, 0.0181, 0.0542, 0.0149, 0.0211,\n",
      "        0.0260, 0.0175], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.223 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  20000\n",
      "Loss:  -0.1814427377285296\n",
      "Loss_orth:  0.002477606411233973\n",
      "Loss_ML:  -0.18392034413976358\n",
      "Logits:  tensor([0.1039, 0.5851, 0.0151, 0.1305, 0.0265, 0.0168, 0.0493, 0.0137, 0.0197,\n",
      "        0.0239, 0.0154], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.721 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  21000\n",
      "Loss:  -0.09037012976624442\n",
      "Loss_orth:  0.0021914180686604416\n",
      "Loss_ML:  -0.09256154783490486\n",
      "Logits:  tensor([0.0897, 0.6375, 0.0133, 0.1153, 0.0232, 0.0151, 0.0416, 0.0120, 0.0176,\n",
      "        0.0202, 0.0145], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.944 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  22000\n",
      "Loss:  -0.9041722095334631\n",
      "Loss_orth:  0.00241433818010328\n",
      "Loss_ML:  -0.9065865477135664\n",
      "Logits:  tensor([0.0778, 0.6757, 0.0126, 0.1009, 0.0212, 0.0139, 0.0385, 0.0113, 0.0167,\n",
      "        0.0181, 0.0132], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.163 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  23000\n",
      "Loss:  0.08799339788654442\n",
      "Loss_orth:  0.004200810573865216\n",
      "Loss_ML:  0.0837925873126792\n",
      "Logits:  tensor([0.0679, 0.7411, 0.0099, 0.0756, 0.0168, 0.0110, 0.0279, 0.0094, 0.0144,\n",
      "        0.0145, 0.0115], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.808 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  24000\n",
      "Loss:  0.0014881894411140181\n",
      "Loss_orth:  0.004466806577376802\n",
      "Loss_ML:  -0.002978617136262784\n",
      "Logits:  tensor([0.0550, 0.7945, 0.0082, 0.0572, 0.0136, 0.0087, 0.0219, 0.0080, 0.0119,\n",
      "        0.0119, 0.0091], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.678 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  25000\n",
      "Loss:  -0.09007151787750363\n",
      "Loss_orth:  0.0023928656350720836\n",
      "Loss_ML:  -0.09246438351257572\n",
      "Logits:  tensor([0.0411, 0.8350, 0.0068, 0.0460, 0.0116, 0.0076, 0.0170, 0.0066, 0.0104,\n",
      "        0.0098, 0.0080], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.912 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  26000\n",
      "Loss:  -0.27951706903093365\n",
      "Loss_orth:  0.0013682374954868842\n",
      "Loss_ML:  -0.2808853065264205\n",
      "Logits:  tensor([0.0359, 0.8446, 0.0065, 0.0433, 0.0115, 0.0077, 0.0169, 0.0063, 0.0096,\n",
      "        0.0097, 0.0080], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.329 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  27000\n",
      "Loss:  -0.7796589832466161\n",
      "Loss_orth:  0.0019270532816553845\n",
      "Loss_ML:  -0.7815860365282715\n",
      "Logits:  tensor([0.0316, 0.8611, 0.0059, 0.0377, 0.0107, 0.0071, 0.0147, 0.0058, 0.0089,\n",
      "        0.0089, 0.0076], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.110 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  28000\n",
      "Loss:  -0.5997415854097938\n",
      "Loss_orth:  0.0013104647135650479\n",
      "Loss_ML:  -0.6010520501233588\n",
      "Logits:  tensor([0.0258, 0.8826, 0.0054, 0.0304, 0.0091, 0.0063, 0.0125, 0.0052, 0.0077,\n",
      "        0.0081, 0.0068], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.404 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  29000\n",
      "Loss:  -0.637238555628532\n",
      "Loss_orth:  0.002227295887726986\n",
      "Loss_ML:  -0.639465851516259\n",
      "Logits:  tensor([0.0227, 0.8955, 0.0050, 0.0256, 0.0088, 0.0059, 0.0114, 0.0049, 0.0069,\n",
      "        0.0071, 0.0062], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.479 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  30000\n",
      "Loss:  -0.5470345480660948\n",
      "Loss_orth:  0.002014782469787812\n",
      "Loss_ML:  -0.5490493305358826\n",
      "Logits:  tensor([0.0182, 0.9116, 0.0045, 0.0211, 0.0077, 0.0053, 0.0097, 0.0044, 0.0060,\n",
      "        0.0060, 0.0055], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.326 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  31000\n",
      "Loss:  -1.234892222674437\n",
      "Loss_orth:  0.002036301036645364\n",
      "Loss_ML:  -1.2369285237110823\n",
      "Logits:  tensor([0.0165, 0.9207, 0.0041, 0.0171, 0.0077, 0.0049, 0.0084, 0.0043, 0.0057,\n",
      "        0.0056, 0.0048], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.273 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  32000\n",
      "Loss:  -2.068163563700722\n",
      "Loss_orth:  0.0038944793915706333\n",
      "Loss_ML:  -2.0720580430922926\n",
      "Logits:  tensor([0.0158, 0.9198, 0.0047, 0.0145, 0.0104, 0.0050, 0.0085, 0.0053, 0.0058,\n",
      "        0.0054, 0.0049], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.012 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  33000\n",
      "Loss:  -2.4298101333859603\n",
      "Loss_orth:  0.006490499211390547\n",
      "Loss_ML:  -2.4363006325973506\n",
      "Logits:  tensor([0.0201, 0.8688, 0.0088, 0.0166, 0.0307, 0.0072, 0.0109, 0.0141, 0.0084,\n",
      "        0.0074, 0.0071], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.060 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  34000\n",
      "Loss:  -2.5253091043694047\n",
      "Loss_orth:  0.008341893782873264\n",
      "Loss_ML:  -2.533650998152278\n",
      "Logits:  tensor([0.0231, 0.7140, 0.0192, 0.0193, 0.1210, 0.0119, 0.0134, 0.0437, 0.0119,\n",
      "        0.0110, 0.0116], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.302 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  35000\n",
      "Loss:  -2.626395979828355\n",
      "Loss_orth:  0.008226784858872795\n",
      "Loss_ML:  -2.6346227646872276\n",
      "Logits:  tensor([0.0198, 0.6086, 0.0225, 0.0163, 0.2034, 0.0170, 0.0121, 0.0644, 0.0106,\n",
      "        0.0139, 0.0114], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.638 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  36000\n",
      "Loss:  -4.188159306727794\n",
      "Loss_orth:  0.006893139251158674\n",
      "Loss_ML:  -4.195052445978953\n",
      "Logits:  tensor([0.0211, 0.5707, 0.0181, 0.0130, 0.2340, 0.0237, 0.0120, 0.0743, 0.0087,\n",
      "        0.0146, 0.0096], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.562 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  37000\n",
      "Loss:  -3.531952778592925\n",
      "Loss_orth:  0.008437444968183952\n",
      "Loss_ML:  -3.5403902235611087\n",
      "Logits:  tensor([0.0267, 0.5560, 0.0144, 0.0102, 0.2386, 0.0269, 0.0131, 0.0866, 0.0070,\n",
      "        0.0124, 0.0081], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.728 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  38000\n",
      "Loss:  -4.1612709278445985\n",
      "Loss_orth:  0.0033488615907735445\n",
      "Loss_ML:  -4.164619789435372\n",
      "Logits:  tensor([0.0296, 0.5508, 0.0110, 0.0079, 0.2449, 0.0242, 0.0141, 0.0958, 0.0055,\n",
      "        0.0092, 0.0069], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.850 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  39000\n",
      "Loss:  -3.861542883990412\n",
      "Loss_orth:  0.0028605771362876092\n",
      "Loss_ML:  -3.8644034611266997\n",
      "Logits:  tensor([0.0295, 0.5509, 0.0091, 0.0063, 0.2462, 0.0220, 0.0145, 0.1039, 0.0046,\n",
      "        0.0072, 0.0057], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.838 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  40000\n",
      "Loss:  -3.89994574297144\n",
      "Loss_orth:  0.002842514177243273\n",
      "Loss_ML:  -3.9027882571486834\n",
      "Logits:  tensor([0.0302, 0.5495, 0.0076, 0.0053, 0.2447, 0.0201, 0.0156, 0.1114, 0.0041,\n",
      "        0.0061, 0.0053], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.248 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  41000\n",
      "Loss:  -3.684675190945234\n",
      "Loss_orth:  0.0025322452191574407\n",
      "Loss_ML:  -3.6872074361643916\n",
      "Logits:  tensor([0.0341, 0.5388, 0.0072, 0.0048, 0.2446, 0.0197, 0.0195, 0.1160, 0.0041,\n",
      "        0.0061, 0.0051], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.555 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  42000\n",
      "Loss:  -4.284024104105404\n",
      "Loss_orth:  0.002015941876888962\n",
      "Loss_ML:  -4.2860400459822925\n",
      "Logits:  tensor([0.0365, 0.5343, 0.0062, 0.0040, 0.2440, 0.0185, 0.0217, 0.1204, 0.0038,\n",
      "        0.0054, 0.0050], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.970 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  43000\n",
      "Loss:  -3.9224935431958707\n",
      "Loss_orth:  0.002187718390437296\n",
      "Loss_ML:  -3.924681261586308\n",
      "Logits:  tensor([0.0431, 0.5225, 0.0056, 0.0038, 0.2449, 0.0173, 0.0252, 0.1233, 0.0039,\n",
      "        0.0054, 0.0051], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.424 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  44000\n",
      "Loss:  -4.210910355630434\n",
      "Loss_orth:  0.0016697476878099597\n",
      "Loss_ML:  -4.212580103318244\n",
      "Logits:  tensor([0.0460, 0.5197, 0.0049, 0.0034, 0.2421, 0.0148, 0.0285, 0.1263, 0.0038,\n",
      "        0.0056, 0.0050], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.639 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  45000\n",
      "Loss:  -4.336134298440232\n",
      "Loss_orth:  0.002731553267139309\n",
      "Loss_ML:  -4.3388658517073715\n",
      "Logits:  tensor([0.0513, 0.5095, 0.0041, 0.0031, 0.2447, 0.0131, 0.0322, 0.1275, 0.0038,\n",
      "        0.0056, 0.0051], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.814 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  46000\n",
      "Loss:  -3.944656119840701\n",
      "Loss_orth:  0.0063262607086007555\n",
      "Loss_ML:  -3.9509823805493016\n",
      "Logits:  tensor([0.0590, 0.5004, 0.0036, 0.0030, 0.2426, 0.0112, 0.0334, 0.1308, 0.0039,\n",
      "        0.0061, 0.0059], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.254 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  47000\n",
      "Loss:  -3.88085683481671\n",
      "Loss_orth:  0.0023859320540274578\n",
      "Loss_ML:  -3.8832427668707377\n",
      "Logits:  tensor([0.0638, 0.4974, 0.0033, 0.0029, 0.2408, 0.0098, 0.0360, 0.1290, 0.0041,\n",
      "        0.0064, 0.0064], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 50.633 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  48000\n",
      "Loss:  -4.1589594175119196\n",
      "Loss_orth:  0.003941597032023253\n",
      "Loss_ML:  -4.162901014543943\n",
      "Logits:  tensor([0.0658, 0.4964, 0.0030, 0.0028, 0.2398, 0.0081, 0.0371, 0.1298, 0.0041,\n",
      "        0.0062, 0.0068], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.511 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  49000\n",
      "Loss:  -4.092746973967034\n",
      "Loss_orth:  0.006135066408944015\n",
      "Loss_ML:  -4.098882040375978\n",
      "Logits:  tensor([0.0690, 0.4883, 0.0029, 0.0028, 0.2403, 0.0071, 0.0395, 0.1320, 0.0040,\n",
      "        0.0064, 0.0078], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.898 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  50000\n",
      "Loss:  -4.449380913016141\n",
      "Loss_orth:  0.005001526028494683\n",
      "Loss_ML:  -4.454382439044635\n",
      "Logits:  tensor([0.0730, 0.4867, 0.0027, 0.0030, 0.2373, 0.0070, 0.0411, 0.1296, 0.0041,\n",
      "        0.0066, 0.0089], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.587 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  51000\n",
      "Loss:  -4.060195054903806\n",
      "Loss_orth:  0.006629704263419123\n",
      "Loss_ML:  -4.0668247591672255\n",
      "Logits:  tensor([0.0740, 0.4800, 0.0024, 0.0032, 0.2416, 0.0065, 0.0413, 0.1312, 0.0040,\n",
      "        0.0066, 0.0093], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.297 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  52000\n",
      "Loss:  -4.240650396021585\n",
      "Loss_orth:  0.00509443864187375\n",
      "Loss_ML:  -4.2457448346634585\n",
      "Logits:  tensor([0.0765, 0.4772, 0.0023, 0.0035, 0.2366, 0.0062, 0.0444, 0.1315, 0.0042,\n",
      "        0.0066, 0.0111], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 50.677 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  53000\n",
      "Loss:  -4.143000904443649\n",
      "Loss_orth:  0.006254941207905217\n",
      "Loss_ML:  -4.149255845651554\n",
      "Logits:  tensor([0.0777, 0.4756, 0.0022, 0.0039, 0.2363, 0.0061, 0.0448, 0.1293, 0.0041,\n",
      "        0.0070, 0.0130], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.157 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  54000\n",
      "Loss:  -4.309093711236004\n",
      "Loss_orth:  0.002802885184919634\n",
      "Loss_ML:  -4.311896596420924\n",
      "Logits:  tensor([0.0807, 0.4670, 0.0023, 0.0044, 0.2361, 0.0060, 0.0464, 0.1309, 0.0041,\n",
      "        0.0071, 0.0151], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.117 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  55000\n",
      "Loss:  -4.198247014750329\n",
      "Loss_orth:  0.007740415433811616\n",
      "Loss_ML:  -4.205987430184141\n",
      "Logits:  tensor([0.0819, 0.4619, 0.0021, 0.0050, 0.2370, 0.0060, 0.0468, 0.1300, 0.0040,\n",
      "        0.0077, 0.0176], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.367 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  56000\n",
      "Loss:  -4.199728688573704\n",
      "Loss_orth:  0.006045736056138282\n",
      "Loss_ML:  -4.205774424629842\n",
      "Logits:  tensor([0.0811, 0.4650, 0.0020, 0.0050, 0.2336, 0.0059, 0.0478, 0.1289, 0.0036,\n",
      "        0.0076, 0.0196], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.170 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  57000\n",
      "Loss:  -4.252303554029543\n",
      "Loss_orth:  0.0038276567113355487\n",
      "Loss_ML:  -4.256131210740878\n",
      "Logits:  tensor([0.0820, 0.4601, 0.0020, 0.0056, 0.2346, 0.0061, 0.0480, 0.1280, 0.0033,\n",
      "        0.0085, 0.0217], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.784 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  58000\n",
      "Loss:  -4.668341002734388\n",
      "Loss_orth:  0.005896657650828507\n",
      "Loss_ML:  -4.6742376603852165\n",
      "Logits:  tensor([0.0819, 0.4583, 0.0020, 0.0057, 0.2330, 0.0060, 0.0497, 0.1282, 0.0029,\n",
      "        0.0088, 0.0234], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.286 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  59000\n",
      "Loss:  -4.185517238941242\n",
      "Loss_orth:  0.005887797320106429\n",
      "Loss_ML:  -4.191405036261348\n",
      "Logits:  tensor([0.0822, 0.4595, 0.0019, 0.0064, 0.2339, 0.0059, 0.0492, 0.1259, 0.0026,\n",
      "        0.0087, 0.0238], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.117 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  60000\n",
      "Loss:  -4.331770529273168\n",
      "Loss_orth:  0.006292091837057469\n",
      "Loss_ML:  -4.338062621110225\n",
      "Logits:  tensor([0.0830, 0.4564, 0.0018, 0.0067, 0.2305, 0.0063, 0.0506, 0.1259, 0.0024,\n",
      "        0.0096, 0.0266], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.526 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  61000\n",
      "Loss:  -4.488640539042908\n",
      "Loss_orth:  0.006148972201200983\n",
      "Loss_ML:  -4.494789511244109\n",
      "Logits:  tensor([0.0842, 0.4521, 0.0017, 0.0069, 0.2325, 0.0062, 0.0506, 0.1269, 0.0020,\n",
      "        0.0097, 0.0273], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.276 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  62000\n",
      "Loss:  -4.570227905489703\n",
      "Loss_orth:  0.005370095941270909\n",
      "Loss_ML:  -4.575598001430974\n",
      "Logits:  tensor([0.0829, 0.4568, 0.0017, 0.0072, 0.2318, 0.0062, 0.0504, 0.1239, 0.0018,\n",
      "        0.0103, 0.0271], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.809 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  63000\n",
      "Loss:  -4.26467691146492\n",
      "Loss_orth:  0.004483742617083047\n",
      "Loss_ML:  -4.269160654082003\n",
      "Logits:  tensor([0.0826, 0.4546, 0.0016, 0.0074, 0.2312, 0.0065, 0.0516, 0.1227, 0.0017,\n",
      "        0.0111, 0.0288], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.247 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  64000\n",
      "Loss:  -4.607932145327049\n",
      "Loss_orth:  0.004977934535070516\n",
      "Loss_ML:  -4.61291007986212\n",
      "Logits:  tensor([0.0821, 0.4555, 0.0015, 0.0080, 0.2285, 0.0065, 0.0517, 0.1230, 0.0016,\n",
      "        0.0118, 0.0296], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.551 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  65000\n",
      "Loss:  -4.2962249752010715\n",
      "Loss_orth:  0.008604684469619314\n",
      "Loss_ML:  -4.304829659670691\n",
      "Logits:  tensor([0.0829, 0.4526, 0.0016, 0.0077, 0.2298, 0.0067, 0.0530, 0.1217, 0.0015,\n",
      "        0.0125, 0.0300], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.433 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  66000\n",
      "Loss:  -4.259450387407136\n",
      "Loss_orth:  0.005870281165544109\n",
      "Loss_ML:  -4.26532066857268\n",
      "Logits:  tensor([0.0831, 0.4550, 0.0015, 0.0080, 0.2270, 0.0067, 0.0528, 0.1210, 0.0013,\n",
      "        0.0130, 0.0305], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.924 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  67000\n",
      "Loss:  -4.381185972076627\n",
      "Loss_orth:  0.007759026677328997\n",
      "Loss_ML:  -4.3889449987539555\n",
      "Logits:  tensor([0.0827, 0.4544, 0.0015, 0.0083, 0.2254, 0.0069, 0.0527, 0.1217, 0.0012,\n",
      "        0.0140, 0.0313], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.585 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  68000\n",
      "Loss:  -4.4230704220474335\n",
      "Loss_orth:  0.004584050661830211\n",
      "Loss_ML:  -4.427654472709264\n",
      "Logits:  tensor([0.0816, 0.4543, 0.0015, 0.0084, 0.2273, 0.0071, 0.0522, 0.1198, 0.0012,\n",
      "        0.0149, 0.0316], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.270 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  69000\n",
      "Loss:  -4.212835650866328\n",
      "Loss_orth:  0.005239278228958173\n",
      "Loss_ML:  -4.218074929095287\n",
      "Logits:  tensor([0.0818, 0.4566, 0.0013, 0.0083, 0.2250, 0.0066, 0.0524, 0.1210, 0.0011,\n",
      "        0.0150, 0.0309], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.366 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  70000\n",
      "Loss:  -4.503793187081524\n",
      "Loss_orth:  0.007468178778799838\n",
      "Loss_ML:  -4.5112613658603244\n",
      "Logits:  tensor([0.0815, 0.4564, 0.0013, 0.0083, 0.2242, 0.0062, 0.0530, 0.1212, 0.0011,\n",
      "        0.0156, 0.0311], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.488 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  71000\n",
      "Loss:  -4.423018563113226\n",
      "Loss_orth:  0.004210012577103486\n",
      "Loss_ML:  -4.42722857569033\n",
      "Logits:  tensor([0.0836, 0.4560, 0.0013, 0.0085, 0.2240, 0.0061, 0.0527, 0.1194, 0.0011,\n",
      "        0.0160, 0.0313], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.638 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  72000\n",
      "Loss:  -4.358526134811979\n",
      "Loss_orth:  0.007624827339447112\n",
      "Loss_ML:  -4.366150962151426\n",
      "Logits:  tensor([0.0825, 0.4555, 0.0013, 0.0084, 0.2239, 0.0061, 0.0532, 0.1199, 0.0010,\n",
      "        0.0166, 0.0317], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.513 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  73000\n",
      "Loss:  -4.202720639911509\n",
      "Loss_orth:  0.006417402209311929\n",
      "Loss_ML:  -4.209138042120821\n",
      "Logits:  tensor([0.0824, 0.4514, 0.0013, 0.0085, 0.2244, 0.0061, 0.0543, 0.1207, 0.0010,\n",
      "        0.0175, 0.0324], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.279 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  74000\n",
      "Loss:  -4.729155845730663\n",
      "Loss_orth:  0.002447282955355501\n",
      "Loss_ML:  -4.731603128686018\n",
      "Logits:  tensor([0.0818, 0.4539, 0.0012, 0.0086, 0.2233, 0.0057, 0.0536, 0.1206, 0.0009,\n",
      "        0.0180, 0.0323], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.704 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  75000\n",
      "Loss:  -4.538531105647573\n",
      "Loss_orth:  0.0031052665053168537\n",
      "Loss_ML:  -4.54163637215289\n",
      "Logits:  tensor([0.0814, 0.4551, 0.0012, 0.0085, 0.2235, 0.0057, 0.0539, 0.1198, 0.0009,\n",
      "        0.0176, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.587 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  76000\n",
      "Loss:  -4.338927935654289\n",
      "Loss_orth:  0.002762505550825915\n",
      "Loss_ML:  -4.341690441205115\n",
      "Logits:  tensor([0.0812, 0.4564, 0.0012, 0.0084, 0.2223, 0.0055, 0.0547, 0.1193, 0.0008,\n",
      "        0.0180, 0.0322], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.795 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  77000\n",
      "Loss:  -4.292400316401827\n",
      "Loss_orth:  0.006323502689151008\n",
      "Loss_ML:  -4.298723819090978\n",
      "Logits:  tensor([0.0814, 0.4549, 0.0012, 0.0082, 0.2247, 0.0053, 0.0539, 0.1193, 0.0008,\n",
      "        0.0178, 0.0326], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.486 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  78000\n",
      "Loss:  -4.285609380891949\n",
      "Loss_orth:  0.004275756568456283\n",
      "Loss_ML:  -4.289885137460406\n",
      "Logits:  tensor([0.0821, 0.4559, 0.0011, 0.0084, 0.2228, 0.0053, 0.0534, 0.1193, 0.0007,\n",
      "        0.0184, 0.0326], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.876 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  79000\n",
      "Loss:  -4.404365622340692\n",
      "Loss_orth:  0.004849972036395573\n",
      "Loss_ML:  -4.409215594377088\n",
      "Logits:  tensor([0.0826, 0.4580, 0.0012, 0.0089, 0.2193, 0.0053, 0.0533, 0.1181, 0.0007,\n",
      "        0.0191, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.685 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  80000\n",
      "Loss:  -4.423950247802362\n",
      "Loss_orth:  0.0035571882958789812\n",
      "Loss_ML:  -4.427507436098241\n",
      "Logits:  tensor([0.0822, 0.4517, 0.0012, 0.0089, 0.2229, 0.0055, 0.0538, 0.1203, 0.0007,\n",
      "        0.0190, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.119 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  81000\n",
      "Loss:  -4.366750786971778\n",
      "Loss_orth:  0.0046638712836676215\n",
      "Loss_ML:  -4.371414658255445\n",
      "Logits:  tensor([0.0817, 0.4576, 0.0011, 0.0089, 0.2211, 0.0054, 0.0529, 0.1191, 0.0007,\n",
      "        0.0189, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.616 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  82000\n",
      "Loss:  -4.1303026811521555\n",
      "Loss_orth:  0.0036995857619915706\n",
      "Loss_ML:  -4.134002266914147\n",
      "Logits:  tensor([0.0823, 0.4554, 0.0011, 0.0090, 0.2213, 0.0054, 0.0540, 0.1190, 0.0006,\n",
      "        0.0189, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.123 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  83000\n",
      "Loss:  -4.213301524854604\n",
      "Loss_orth:  0.0015968997028255026\n",
      "Loss_ML:  -4.214898424557429\n",
      "Logits:  tensor([0.0819, 0.4571, 0.0011, 0.0091, 0.2208, 0.0052, 0.0539, 0.1186, 0.0007,\n",
      "        0.0186, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.844 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  84000\n",
      "Loss:  -4.792614878642524\n",
      "Loss_orth:  0.005033046698779195\n",
      "Loss_ML:  -4.797647925341303\n",
      "Logits:  tensor([0.0817, 0.4583, 0.0010, 0.0093, 0.2201, 0.0051, 0.0532, 0.1191, 0.0007,\n",
      "        0.0189, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.741 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  85000\n",
      "Loss:  -4.34632853090572\n",
      "Loss_orth:  0.0019920429838558573\n",
      "Loss_ML:  -4.348320573889576\n",
      "Logits:  tensor([0.0801, 0.4623, 0.0010, 0.0090, 0.2201, 0.0052, 0.0535, 0.1157, 0.0007,\n",
      "        0.0190, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.096 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  86000\n",
      "Loss:  -4.580396823609501\n",
      "Loss_orth:  0.0019392247120628378\n",
      "Loss_ML:  -4.582336048321563\n",
      "Logits:  tensor([0.0821, 0.4575, 0.0010, 0.0092, 0.2199, 0.0051, 0.0534, 0.1192, 0.0006,\n",
      "        0.0189, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.071 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  87000\n",
      "Loss:  -4.277907910793595\n",
      "Loss_orth:  0.002799471067787905\n",
      "Loss_ML:  -4.280707381861383\n",
      "Logits:  tensor([0.0812, 0.4601, 0.0009, 0.0098, 0.2189, 0.0051, 0.0527, 0.1182, 0.0007,\n",
      "        0.0192, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.843 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  88000\n",
      "Loss:  -4.4867051228845956\n",
      "Loss_orth:  0.000994196844434177\n",
      "Loss_ML:  -4.48769931972903\n",
      "Logits:  tensor([0.0812, 0.4606, 0.0009, 0.0098, 0.2175, 0.0052, 0.0534, 0.1175, 0.0006,\n",
      "        0.0198, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.685 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  89000\n",
      "Loss:  -4.272898853492431\n",
      "Loss_orth:  0.002155189778872795\n",
      "Loss_ML:  -4.275054043271304\n",
      "Logits:  tensor([0.0804, 0.4608, 0.0009, 0.0097, 0.2209, 0.0052, 0.0526, 0.1181, 0.0006,\n",
      "        0.0190, 0.0319], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.875 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  90000\n",
      "Loss:  -4.518133036682861\n",
      "Loss_orth:  0.000907462257290811\n",
      "Loss_ML:  -4.519040498940152\n",
      "Logits:  tensor([0.0832, 0.4592, 0.0008, 0.0094, 0.2181, 0.0052, 0.0535, 0.1175, 0.0006,\n",
      "        0.0193, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.725 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  91000\n",
      "Loss:  -4.505034590970015\n",
      "Loss_orth:  0.0021120904060989753\n",
      "Loss_ML:  -4.507146681376114\n",
      "Logits:  tensor([0.0822, 0.4575, 0.0008, 0.0095, 0.2185, 0.0052, 0.0535, 0.1190, 0.0006,\n",
      "        0.0198, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.360 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  92000\n",
      "Loss:  -4.563282155728005\n",
      "Loss_orth:  0.0007199002903475791\n",
      "Loss_ML:  -4.564002056018352\n",
      "Logits:  tensor([0.0811, 0.4602, 0.0008, 0.0096, 0.2169, 0.0055, 0.0538, 0.1176, 0.0006,\n",
      "        0.0199, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.472 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  93000\n",
      "Loss:  -4.347768279600482\n",
      "Loss_orth:  0.004250618543858241\n",
      "Loss_ML:  -4.35201889814434\n",
      "Logits:  tensor([0.0813, 0.4593, 0.0008, 0.0095, 0.2183, 0.0055, 0.0536, 0.1181, 0.0006,\n",
      "        0.0196, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.831 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  94000\n",
      "Loss:  -4.499730150146396\n",
      "Loss_orth:  0.0037965948039025152\n",
      "Loss_ML:  -4.503526744950299\n",
      "Logits:  tensor([0.0822, 0.4573, 0.0008, 0.0098, 0.2189, 0.0057, 0.0535, 0.1174, 0.0006,\n",
      "        0.0198, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.497 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  95000\n",
      "Loss:  -4.575801798287934\n",
      "Loss_orth:  0.0017116721048339404\n",
      "Loss_ML:  -4.577513470392768\n",
      "Logits:  tensor([0.0834, 0.4547, 0.0007, 0.0094, 0.2193, 0.0054, 0.0541, 0.1197, 0.0005,\n",
      "        0.0192, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.255 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  96000\n",
      "Loss:  -4.865796260145757\n",
      "Loss_orth:  0.0014286900404490244\n",
      "Loss_ML:  -4.867224950186206\n",
      "Logits:  tensor([0.0806, 0.4615, 0.0008, 0.0098, 0.2175, 0.0058, 0.0531, 0.1175, 0.0006,\n",
      "        0.0195, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.061 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  97000\n",
      "Loss:  -4.466660803443539\n",
      "Loss_orth:  0.0019134945188513408\n",
      "Loss_ML:  -4.468574297962391\n",
      "Logits:  tensor([0.0825, 0.4576, 0.0008, 0.0099, 0.2184, 0.0057, 0.0535, 0.1176, 0.0006,\n",
      "        0.0197, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.695 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  98000\n",
      "Loss:  -4.744504002816491\n",
      "Loss_orth:  0.0012013267664179195\n",
      "Loss_ML:  -4.745705329582909\n",
      "Logits:  tensor([0.0809, 0.4600, 0.0008, 0.0103, 0.2179, 0.0056, 0.0533, 0.1185, 0.0006,\n",
      "        0.0194, 0.0327], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.214 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  99000\n",
      "Loss:  -4.33336278982621\n",
      "Loss_orth:  0.0005409596245705035\n",
      "Loss_ML:  -4.333903749450781\n",
      "Logits:  tensor([0.0807, 0.4609, 0.0008, 0.0102, 0.2164, 0.0055, 0.0535, 0.1183, 0.0006,\n",
      "        0.0195, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.492 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  100000\n",
      "Loss:  -4.417990519210031\n",
      "Loss_orth:  0.000679496161470283\n",
      "Loss_ML:  -4.418670015371501\n",
      "Logits:  tensor([0.0822, 0.4622, 0.0007, 0.0101, 0.2163, 0.0056, 0.0529, 0.1176, 0.0006,\n",
      "        0.0192, 0.0326], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.401 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  101000\n",
      "Loss:  -4.523892791078342\n",
      "Loss_orth:  0.0012796833328897717\n",
      "Loss_ML:  -4.5251724744112325\n",
      "Logits:  tensor([0.0821, 0.4619, 0.0007, 0.0101, 0.2162, 0.0057, 0.0539, 0.1166, 0.0006,\n",
      "        0.0195, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.542 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  102000\n",
      "Loss:  -4.463143560466088\n",
      "Loss_orth:  0.0030370781687583184\n",
      "Loss_ML:  -4.466180638634847\n",
      "Logits:  tensor([0.0806, 0.4583, 0.0007, 0.0103, 0.2186, 0.0058, 0.0534, 0.1186, 0.0006,\n",
      "        0.0198, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.555 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  103000\n",
      "Loss:  -4.18915568234915\n",
      "Loss_orth:  0.003594201236353021\n",
      "Loss_ML:  -4.1927498835855035\n",
      "Logits:  tensor([0.0804, 0.4609, 0.0007, 0.0100, 0.2185, 0.0058, 0.0541, 0.1163, 0.0006,\n",
      "        0.0192, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.220 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  104000\n",
      "Loss:  -4.980611671345036\n",
      "Loss_orth:  0.0025209614621799236\n",
      "Loss_ML:  -4.983132632807216\n",
      "Logits:  tensor([0.0813, 0.4629, 0.0006, 0.0095, 0.2163, 0.0057, 0.0535, 0.1181, 0.0006,\n",
      "        0.0190, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.482 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  105000\n",
      "Loss:  -4.560561014066276\n",
      "Loss_orth:  0.0019484259935453028\n",
      "Loss_ML:  -4.562509440059821\n",
      "Logits:  tensor([0.0812, 0.4614, 0.0006, 0.0099, 0.2154, 0.0057, 0.0535, 0.1185, 0.0006,\n",
      "        0.0195, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.860 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  106000\n",
      "Loss:  -4.821982701410992\n",
      "Loss_orth:  0.00034749721300424\n",
      "Loss_ML:  -4.822330198623996\n",
      "Logits:  tensor([0.0810, 0.4608, 0.0006, 0.0095, 0.2184, 0.0056, 0.0536, 0.1177, 0.0005,\n",
      "        0.0190, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.654 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  107000\n",
      "Loss:  -4.763853136618573\n",
      "Loss_orth:  0.001188465930431627\n",
      "Loss_ML:  -4.7650416025490046\n",
      "Logits:  tensor([0.0818, 0.4581, 0.0006, 0.0102, 0.2170, 0.0060, 0.0541, 0.1172, 0.0005,\n",
      "        0.0200, 0.0345], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.500 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  108000\n",
      "Loss:  -5.035207240799533\n",
      "Loss_orth:  0.0011278686634200248\n",
      "Loss_ML:  -5.036335109462953\n",
      "Logits:  tensor([0.0814, 0.4620, 0.0007, 0.0103, 0.2148, 0.0060, 0.0539, 0.1179, 0.0006,\n",
      "        0.0197, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.117 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  109000\n",
      "Loss:  -4.71910832599571\n",
      "Loss_orth:  0.0011851225576476098\n",
      "Loss_ML:  -4.720293448553358\n",
      "Logits:  tensor([0.0804, 0.4629, 0.0006, 0.0102, 0.2161, 0.0059, 0.0533, 0.1173, 0.0006,\n",
      "        0.0195, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.272 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  110000\n",
      "Loss:  -4.673618366871538\n",
      "Loss_orth:  0.0017323861390236364\n",
      "Loss_ML:  -4.675350753010561\n",
      "Logits:  tensor([0.0805, 0.4626, 0.0006, 0.0099, 0.2168, 0.0057, 0.0534, 0.1175, 0.0006,\n",
      "        0.0191, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.115 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  111000\n",
      "Loss:  -4.567953585843761\n",
      "Loss_orth:  0.000440417700659978\n",
      "Loss_ML:  -4.568394003544421\n",
      "Logits:  tensor([0.0804, 0.4638, 0.0006, 0.0102, 0.2146, 0.0058, 0.0529, 0.1177, 0.0006,\n",
      "        0.0194, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.590 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  112000\n",
      "Loss:  -4.412485832881645\n",
      "Loss_orth:  0.001177909795420806\n",
      "Loss_ML:  -4.413663742677065\n",
      "Logits:  tensor([0.0808, 0.4644, 0.0005, 0.0100, 0.2138, 0.0060, 0.0541, 0.1169, 0.0006,\n",
      "        0.0193, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.933 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  113000\n",
      "Loss:  -4.436665259740453\n",
      "Loss_orth:  0.001790985819283084\n",
      "Loss_ML:  -4.438456245559736\n",
      "Logits:  tensor([0.0811, 0.4623, 0.0006, 0.0102, 0.2154, 0.0059, 0.0537, 0.1174, 0.0006,\n",
      "        0.0198, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.096 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  114000\n",
      "Loss:  -4.603810293685274\n",
      "Loss_orth:  0.0009431575330946277\n",
      "Loss_ML:  -4.604753451218368\n",
      "Logits:  tensor([0.0821, 0.4622, 0.0006, 0.0108, 0.2135, 0.0058, 0.0538, 0.1170, 0.0007,\n",
      "        0.0199, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.574 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  115000\n",
      "Loss:  -4.359506525255885\n",
      "Loss_orth:  0.0007742730072452487\n",
      "Loss_ML:  -4.36028079826313\n",
      "Logits:  tensor([0.0808, 0.4625, 0.0006, 0.0106, 0.2134, 0.0059, 0.0547, 0.1172, 0.0007,\n",
      "        0.0196, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.955 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  116000\n",
      "Loss:  -4.336105812637429\n",
      "Loss_orth:  0.0004841194216774857\n",
      "Loss_ML:  -4.336589932059106\n",
      "Logits:  tensor([0.0804, 0.4646, 0.0006, 0.0106, 0.2148, 0.0059, 0.0543, 0.1152, 0.0007,\n",
      "        0.0195, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.805 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  117000\n",
      "Loss:  -4.843397290706315\n",
      "Loss_orth:  0.0007928685182692548\n",
      "Loss_ML:  -4.844190159224585\n",
      "Logits:  tensor([0.0811, 0.4642, 0.0006, 0.0105, 0.2134, 0.0058, 0.0538, 0.1177, 0.0007,\n",
      "        0.0193, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.606 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  118000\n",
      "Loss:  -4.3382129606656585\n",
      "Loss_orth:  0.0005724661917265818\n",
      "Loss_ML:  -4.3387854268573856\n",
      "Logits:  tensor([0.0815, 0.4601, 0.0006, 0.0112, 0.2138, 0.0062, 0.0544, 0.1168, 0.0008,\n",
      "        0.0205, 0.0342], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.434 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  119000\n",
      "Loss:  -4.3133085281458925\n",
      "Loss_orth:  0.0012677884925203662\n",
      "Loss_ML:  -4.314576316638413\n",
      "Logits:  tensor([0.0802, 0.4647, 0.0006, 0.0106, 0.2160, 0.0060, 0.0526, 0.1159, 0.0008,\n",
      "        0.0192, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.552 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  120000\n",
      "Loss:  -4.3739984837779184\n",
      "Loss_orth:  0.0006368359585556903\n",
      "Loss_ML:  -4.374635319736474\n",
      "Logits:  tensor([0.0805, 0.4659, 0.0006, 0.0103, 0.2137, 0.0062, 0.0535, 0.1163, 0.0008,\n",
      "        0.0191, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.384 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  121000\n",
      "Loss:  -4.702731551810036\n",
      "Loss_orth:  0.0007387331783142071\n",
      "Loss_ML:  -4.7034702849883505\n",
      "Logits:  tensor([0.0814, 0.4601, 0.0006, 0.0104, 0.2160, 0.0062, 0.0537, 0.1178, 0.0008,\n",
      "        0.0195, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.921 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  122000\n",
      "Loss:  -4.5788742143587475\n",
      "Loss_orth:  0.001385157812287057\n",
      "Loss_ML:  -4.580259372171034\n",
      "Logits:  tensor([0.0818, 0.4606, 0.0006, 0.0104, 0.2164, 0.0058, 0.0539, 0.1170, 0.0008,\n",
      "        0.0196, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.991 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  123000\n",
      "Loss:  -4.566889955247576\n",
      "Loss_orth:  0.0009954911513589348\n",
      "Loss_ML:  -4.567885446398935\n",
      "Logits:  tensor([0.0809, 0.4626, 0.0006, 0.0103, 0.2150, 0.0060, 0.0538, 0.1170, 0.0008,\n",
      "        0.0193, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.411 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  124000\n",
      "Loss:  -4.449542145902611\n",
      "Loss_orth:  0.0003929138049749875\n",
      "Loss_ML:  -4.449935059707586\n",
      "Logits:  tensor([0.0805, 0.4623, 0.0006, 0.0106, 0.2142, 0.0061, 0.0531, 0.1186, 0.0009,\n",
      "        0.0201, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.246 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  125000\n",
      "Loss:  -4.38096605100173\n",
      "Loss_orth:  0.001003619241711452\n",
      "Loss_ML:  -4.381969670243441\n",
      "Logits:  tensor([0.0818, 0.4620, 0.0006, 0.0106, 0.2118, 0.0063, 0.0548, 0.1171, 0.0009,\n",
      "        0.0199, 0.0342], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.705 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  126000\n",
      "Loss:  -4.373787215652823\n",
      "Loss_orth:  0.0008369618921491998\n",
      "Loss_ML:  -4.374624177544972\n",
      "Logits:  tensor([0.0808, 0.4607, 0.0006, 0.0109, 0.2154, 0.0062, 0.0539, 0.1168, 0.0010,\n",
      "        0.0197, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.762 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  127000\n",
      "Loss:  -4.366740798813642\n",
      "Loss_orth:  0.00031959302714351526\n",
      "Loss_ML:  -4.367060391840785\n",
      "Logits:  tensor([0.0809, 0.4617, 0.0006, 0.0108, 0.2152, 0.0061, 0.0540, 0.1165, 0.0010,\n",
      "        0.0196, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.496 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  128000\n",
      "Loss:  -4.481046336951198\n",
      "Loss_orth:  0.000993923578353221\n",
      "Loss_ML:  -4.482040260529551\n",
      "Logits:  tensor([0.0810, 0.4634, 0.0006, 0.0104, 0.2157, 0.0058, 0.0530, 0.1165, 0.0009,\n",
      "        0.0193, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.496 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  129000\n",
      "Loss:  -4.622612007010218\n",
      "Loss_orth:  0.000645660564087886\n",
      "Loss_ML:  -4.623257667574307\n",
      "Logits:  tensor([0.0809, 0.4611, 0.0006, 0.0106, 0.2146, 0.0061, 0.0545, 0.1172, 0.0010,\n",
      "        0.0197, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.129 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  130000\n",
      "Loss:  -4.1919797154449965\n",
      "Loss_orth:  0.00035158288336282833\n",
      "Loss_ML:  -4.19233129832836\n",
      "Logits:  tensor([0.0803, 0.4613, 0.0006, 0.0107, 0.2167, 0.0063, 0.0527, 0.1171, 0.0010,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.935 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  131000\n",
      "Loss:  -4.229220577756799\n",
      "Loss_orth:  0.0011803756437989163\n",
      "Loss_ML:  -4.230400953400598\n",
      "Logits:  tensor([0.0791, 0.4666, 0.0006, 0.0106, 0.2139, 0.0063, 0.0531, 0.1161, 0.0010,\n",
      "        0.0191, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.776 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  132000\n",
      "Loss:  -4.370408674691411\n",
      "Loss_orth:  0.0005828817560626774\n",
      "Loss_ML:  -4.370991556447473\n",
      "Logits:  tensor([0.0811, 0.4639, 0.0006, 0.0106, 0.2121, 0.0065, 0.0537, 0.1176, 0.0010,\n",
      "        0.0193, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.289 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  133000\n",
      "Loss:  -4.2711678894848415\n",
      "Loss_orth:  0.0010917412723990816\n",
      "Loss_ML:  -4.27225963075724\n",
      "Logits:  tensor([0.0804, 0.4606, 0.0006, 0.0110, 0.2155, 0.0067, 0.0529, 0.1169, 0.0011,\n",
      "        0.0202, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.018 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  134000\n",
      "Loss:  -4.0517827856982365\n",
      "Loss_orth:  0.0009272648030899478\n",
      "Loss_ML:  -4.052710050501326\n",
      "Logits:  tensor([0.0801, 0.4632, 0.0007, 0.0107, 0.2145, 0.0067, 0.0531, 0.1172, 0.0011,\n",
      "        0.0197, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.604 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  135000\n",
      "Loss:  -4.35498467360044\n",
      "Loss_orth:  0.0010456095498401258\n",
      "Loss_ML:  -4.356030283150281\n",
      "Logits:  tensor([0.0807, 0.4609, 0.0006, 0.0103, 0.2160, 0.0064, 0.0539, 0.1174, 0.0011,\n",
      "        0.0190, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.144 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  136000\n",
      "Loss:  -4.34201805773123\n",
      "Loss_orth:  0.0006805622732787907\n",
      "Loss_ML:  -4.342698620004509\n",
      "Logits:  tensor([0.0815, 0.4612, 0.0006, 0.0108, 0.2138, 0.0061, 0.0543, 0.1175, 0.0011,\n",
      "        0.0196, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.277 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  137000\n",
      "Loss:  -4.3606373370792175\n",
      "Loss_orth:  0.0017531520461830314\n",
      "Loss_ML:  -4.3623904891254\n",
      "Logits:  tensor([0.0806, 0.4613, 0.0006, 0.0107, 0.2165, 0.0062, 0.0531, 0.1170, 0.0011,\n",
      "        0.0196, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.084 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  138000\n",
      "Loss:  -4.4798551137584965\n",
      "Loss_orth:  0.0004631912483529899\n",
      "Loss_ML:  -4.48031830500685\n",
      "Logits:  tensor([0.0805, 0.4607, 0.0006, 0.0104, 0.2158, 0.0064, 0.0536, 0.1174, 0.0011,\n",
      "        0.0197, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.708 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  139000\n",
      "Loss:  -4.577243484050183\n",
      "Loss_orth:  0.0011792136797901046\n",
      "Loss_ML:  -4.578422697729973\n",
      "Logits:  tensor([0.0806, 0.4617, 0.0006, 0.0104, 0.2152, 0.0063, 0.0535, 0.1173, 0.0011,\n",
      "        0.0195, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.256 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  140000\n",
      "Loss:  -4.494771333311221\n",
      "Loss_orth:  0.001060519190611859\n",
      "Loss_ML:  -4.4958318525018335\n",
      "Logits:  tensor([0.0803, 0.4651, 0.0006, 0.0111, 0.2125, 0.0062, 0.0531, 0.1160, 0.0011,\n",
      "        0.0202, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.844 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  141000\n",
      "Loss:  -4.447731527521704\n",
      "Loss_orth:  0.0006866836176025014\n",
      "Loss_ML:  -4.448418211139306\n",
      "Logits:  tensor([0.0805, 0.4641, 0.0006, 0.0105, 0.2134, 0.0059, 0.0535, 0.1171, 0.0010,\n",
      "        0.0199, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.050 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  142000\n",
      "Loss:  -4.423390697496321\n",
      "Loss_orth:  0.001402990233955932\n",
      "Loss_ML:  -4.4247936877302765\n",
      "Logits:  tensor([0.0806, 0.4609, 0.0006, 0.0106, 0.2159, 0.0061, 0.0532, 0.1175, 0.0010,\n",
      "        0.0199, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.736 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  143000\n",
      "Loss:  -4.287729152877692\n",
      "Loss_orth:  0.001044935419316934\n",
      "Loss_ML:  -4.288774088297009\n",
      "Logits:  tensor([0.0805, 0.4595, 0.0006, 0.0110, 0.2145, 0.0062, 0.0538, 0.1185, 0.0010,\n",
      "        0.0205, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.428 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  144000\n",
      "Loss:  -4.617204265724192\n",
      "Loss_orth:  0.0005313034876034994\n",
      "Loss_ML:  -4.617735569211796\n",
      "Logits:  tensor([0.0818, 0.4621, 0.0006, 0.0109, 0.2130, 0.0062, 0.0538, 0.1164, 0.0011,\n",
      "        0.0199, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.076 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  145000\n",
      "Loss:  -4.401770891066905\n",
      "Loss_orth:  0.0006079243287601254\n",
      "Loss_ML:  -4.4023788153956644\n",
      "Logits:  tensor([0.0808, 0.4623, 0.0006, 0.0106, 0.2146, 0.0063, 0.0536, 0.1167, 0.0011,\n",
      "        0.0197, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.225 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  146000\n",
      "Loss:  -4.597427047984218\n",
      "Loss_orth:  0.0006579781532982506\n",
      "Loss_ML:  -4.598085026137516\n",
      "Logits:  tensor([0.0814, 0.4576, 0.0006, 0.0106, 0.2148, 0.0064, 0.0543, 0.1192, 0.0011,\n",
      "        0.0197, 0.0343], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.408 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  147000\n",
      "Loss:  -4.255230907345067\n",
      "Loss_orth:  0.0006814398187167678\n",
      "Loss_ML:  -4.255912347163783\n",
      "Logits:  tensor([0.0803, 0.4662, 0.0007, 0.0104, 0.2147, 0.0064, 0.0532, 0.1160, 0.0011,\n",
      "        0.0188, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.029 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  148000\n",
      "Loss:  -4.543951514180932\n",
      "Loss_orth:  0.0005032027812450809\n",
      "Loss_ML:  -4.544454716962178\n",
      "Logits:  tensor([0.0811, 0.4618, 0.0006, 0.0108, 0.2140, 0.0065, 0.0543, 0.1169, 0.0010,\n",
      "        0.0192, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.120 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  149000\n",
      "Loss:  -4.291121167270418\n",
      "Loss_orth:  0.0005928306808789004\n",
      "Loss_ML:  -4.291713997951297\n",
      "Logits:  tensor([0.0793, 0.4650, 0.0006, 0.0107, 0.2160, 0.0063, 0.0523, 0.1154, 0.0010,\n",
      "        0.0198, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.316 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  150000\n",
      "Loss:  -4.266411718555787\n",
      "Loss_orth:  0.0002995538857120152\n",
      "Loss_ML:  -4.2667112724414995\n",
      "Logits:  tensor([0.0800, 0.4626, 0.0006, 0.0109, 0.2136, 0.0066, 0.0532, 0.1181, 0.0010,\n",
      "        0.0201, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.422 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  151000\n",
      "Loss:  -4.406920687165098\n",
      "Loss_orth:  0.0006827212447321877\n",
      "Loss_ML:  -4.4076034084098294\n",
      "Logits:  tensor([0.0803, 0.4600, 0.0006, 0.0109, 0.2172, 0.0063, 0.0532, 0.1166, 0.0011,\n",
      "        0.0200, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.353 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  152000\n",
      "Loss:  -4.063486493492676\n",
      "Loss_orth:  0.0005388269499016964\n",
      "Loss_ML:  -4.064025320442578\n",
      "Logits:  tensor([0.0818, 0.4611, 0.0007, 0.0104, 0.2131, 0.0063, 0.0550, 0.1171, 0.0011,\n",
      "        0.0198, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.519 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  153000\n",
      "Loss:  -4.323408027277822\n",
      "Loss_orth:  0.00042417969696383637\n",
      "Loss_ML:  -4.323832206974786\n",
      "Logits:  tensor([0.0808, 0.4589, 0.0007, 0.0106, 0.2147, 0.0063, 0.0546, 0.1185, 0.0012,\n",
      "        0.0197, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.105 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  154000\n",
      "Loss:  -4.534957139577197\n",
      "Loss_orth:  0.0007248106977702592\n",
      "Loss_ML:  -4.5356819502749675\n",
      "Logits:  tensor([0.0796, 0.4626, 0.0007, 0.0104, 0.2156, 0.0063, 0.0538, 0.1170, 0.0012,\n",
      "        0.0198, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.944 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  155000\n",
      "Loss:  -4.425999397922365\n",
      "Loss_orth:  0.00038898266439365696\n",
      "Loss_ML:  -4.426388380586759\n",
      "Logits:  tensor([0.0808, 0.4610, 0.0007, 0.0110, 0.2133, 0.0063, 0.0540, 0.1182, 0.0012,\n",
      "        0.0198, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.029 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  156000\n",
      "Loss:  -4.308037371832733\n",
      "Loss_orth:  0.0006780336573202105\n",
      "Loss_ML:  -4.308715405490053\n",
      "Logits:  tensor([0.0806, 0.4632, 0.0007, 0.0107, 0.2140, 0.0063, 0.0535, 0.1172, 0.0011,\n",
      "        0.0193, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.403 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  157000\n",
      "Loss:  -4.346608883146541\n",
      "Loss_orth:  0.0010263284447727774\n",
      "Loss_ML:  -4.347635211591314\n",
      "Logits:  tensor([0.0811, 0.4650, 0.0007, 0.0111, 0.2114, 0.0064, 0.0537, 0.1167, 0.0011,\n",
      "        0.0199, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.508 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  158000\n",
      "Loss:  -4.233770933428674\n",
      "Loss_orth:  0.0004977707830295888\n",
      "Loss_ML:  -4.234268704211703\n",
      "Logits:  tensor([0.0802, 0.4640, 0.0007, 0.0104, 0.2142, 0.0061, 0.0539, 0.1166, 0.0011,\n",
      "        0.0191, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.394 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  159000\n",
      "Loss:  -4.394385051383757\n",
      "Loss_orth:  0.0008468751962411928\n",
      "Loss_ML:  -4.3952319265799975\n",
      "Logits:  tensor([0.0799, 0.4634, 0.0007, 0.0104, 0.2133, 0.0063, 0.0537, 0.1171, 0.0011,\n",
      "        0.0201, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.441 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  160000\n",
      "Loss:  -4.312898566854296\n",
      "Loss_orth:  0.0011078241978486523\n",
      "Loss_ML:  -4.3140063910521445\n",
      "Logits:  tensor([0.0814, 0.4603, 0.0007, 0.0107, 0.2136, 0.0062, 0.0548, 0.1173, 0.0011,\n",
      "        0.0203, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.171 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  161000\n",
      "Loss:  -4.5038066193553545\n",
      "Loss_orth:  0.0007311460185059182\n",
      "Loss_ML:  -4.50453776537386\n",
      "Logits:  tensor([0.0800, 0.4654, 0.0007, 0.0102, 0.2144, 0.0063, 0.0535, 0.1168, 0.0011,\n",
      "        0.0188, 0.0327], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.271 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  162000\n",
      "Loss:  -4.675203175205415\n",
      "Loss_orth:  0.0009285341677007483\n",
      "Loss_ML:  -4.676131709373116\n",
      "Logits:  tensor([0.0806, 0.4630, 0.0007, 0.0104, 0.2147, 0.0062, 0.0539, 0.1165, 0.0011,\n",
      "        0.0195, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.316 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  163000\n",
      "Loss:  -4.394852645920293\n",
      "Loss_orth:  0.0007714818964977301\n",
      "Loss_ML:  -4.395624127816791\n",
      "Logits:  tensor([0.0794, 0.4625, 0.0007, 0.0105, 0.2159, 0.0060, 0.0533, 0.1177, 0.0011,\n",
      "        0.0198, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.571 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  164000\n",
      "Loss:  -4.49872025729821\n",
      "Loss_orth:  0.0005184634813940972\n",
      "Loss_ML:  -4.499238720779604\n",
      "Logits:  tensor([0.0807, 0.4604, 0.0007, 0.0109, 0.2145, 0.0063, 0.0541, 0.1180, 0.0012,\n",
      "        0.0200, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.687 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  165000\n",
      "Loss:  -4.575348968629308\n",
      "Loss_orth:  0.001039290034679785\n",
      "Loss_ML:  -4.576388258663988\n",
      "Logits:  tensor([0.0809, 0.4603, 0.0007, 0.0105, 0.2159, 0.0061, 0.0534, 0.1186, 0.0011,\n",
      "        0.0193, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.642 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  166000\n",
      "Loss:  -4.399508549861468\n",
      "Loss_orth:  0.0006575082434870801\n",
      "Loss_ML:  -4.400166058104955\n",
      "Logits:  tensor([0.0813, 0.4598, 0.0007, 0.0108, 0.2147, 0.0065, 0.0541, 0.1172, 0.0012,\n",
      "        0.0201, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.028 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  167000\n",
      "Loss:  -4.403489228595482\n",
      "Loss_orth:  0.00048167205948222936\n",
      "Loss_ML:  -4.403970900654964\n",
      "Logits:  tensor([0.0813, 0.4625, 0.0007, 0.0106, 0.2116, 0.0064, 0.0547, 0.1177, 0.0012,\n",
      "        0.0200, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.033 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  168000\n",
      "Loss:  -4.5560251895012405\n",
      "Loss_orth:  0.000740212899098057\n",
      "Loss_ML:  -4.556765402400338\n",
      "Logits:  tensor([0.0799, 0.4642, 0.0007, 0.0107, 0.2137, 0.0061, 0.0540, 0.1166, 0.0013,\n",
      "        0.0197, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.785 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  169000\n",
      "Loss:  -4.06232739363685\n",
      "Loss_orth:  0.0011556954520109382\n",
      "Loss_ML:  -4.063483089088861\n",
      "Logits:  tensor([0.0804, 0.4634, 0.0007, 0.0107, 0.2137, 0.0061, 0.0537, 0.1174, 0.0012,\n",
      "        0.0196, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.181 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  170000\n",
      "Loss:  -4.749756645166007\n",
      "Loss_orth:  0.0012757839312722348\n",
      "Loss_ML:  -4.75103242909728\n",
      "Logits:  tensor([0.0797, 0.4622, 0.0007, 0.0109, 0.2158, 0.0059, 0.0538, 0.1171, 0.0012,\n",
      "        0.0195, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.353 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  171000\n",
      "Loss:  -4.429730869367579\n",
      "Loss_orth:  0.00036176543733254263\n",
      "Loss_ML:  -4.430092634804912\n",
      "Logits:  tensor([0.0795, 0.4631, 0.0007, 0.0106, 0.2148, 0.0058, 0.0538, 0.1174, 0.0012,\n",
      "        0.0196, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.253 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  172000\n",
      "Loss:  -4.7770377867234615\n",
      "Loss_orth:  0.0013359451022134782\n",
      "Loss_ML:  -4.778373731825675\n",
      "Logits:  tensor([0.0806, 0.4665, 0.0007, 0.0108, 0.2088, 0.0062, 0.0532, 0.1181, 0.0013,\n",
      "        0.0201, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.734 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  173000\n",
      "Loss:  -4.349196882256272\n",
      "Loss_orth:  0.0010922699901341614\n",
      "Loss_ML:  -4.350289152246406\n",
      "Logits:  tensor([0.0803, 0.4616, 0.0007, 0.0106, 0.2151, 0.0064, 0.0530, 0.1181, 0.0013,\n",
      "        0.0193, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.819 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  174000\n",
      "Loss:  -4.232134528419973\n",
      "Loss_orth:  0.0005374221557602928\n",
      "Loss_ML:  -4.2326719505757335\n",
      "Logits:  tensor([0.0810, 0.4607, 0.0007, 0.0106, 0.2136, 0.0067, 0.0534, 0.1188, 0.0013,\n",
      "        0.0196, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.648 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  175000\n",
      "Loss:  -4.371984029258867\n",
      "Loss_orth:  0.0006200348959759343\n",
      "Loss_ML:  -4.372604064154842\n",
      "Logits:  tensor([0.0790, 0.4645, 0.0007, 0.0104, 0.2144, 0.0064, 0.0534, 0.1172, 0.0012,\n",
      "        0.0196, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.523 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  176000\n",
      "Loss:  -4.569760910098009\n",
      "Loss_orth:  0.0006486568487707963\n",
      "Loss_ML:  -4.57040956694678\n",
      "Logits:  tensor([0.0804, 0.4616, 0.0008, 0.0109, 0.2138, 0.0064, 0.0534, 0.1187, 0.0013,\n",
      "        0.0200, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.802 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  177000\n",
      "Loss:  -4.311625930492146\n",
      "Loss_orth:  0.0005718478662089276\n",
      "Loss_ML:  -4.312197778358355\n",
      "Logits:  tensor([0.0799, 0.4636, 0.0007, 0.0105, 0.2134, 0.0062, 0.0536, 0.1175, 0.0013,\n",
      "        0.0198, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.432 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  178000\n",
      "Loss:  -4.331600160497391\n",
      "Loss_orth:  0.001222758226198869\n",
      "Loss_ML:  -4.33282291872359\n",
      "Logits:  tensor([0.0809, 0.4648, 0.0007, 0.0109, 0.2118, 0.0061, 0.0537, 0.1165, 0.0014,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.841 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  179000\n",
      "Loss:  -4.515901556438232\n",
      "Loss_orth:  0.0006974779242814559\n",
      "Loss_ML:  -4.516599034362513\n",
      "Logits:  tensor([0.0795, 0.4655, 0.0007, 0.0105, 0.2141, 0.0062, 0.0535, 0.1162, 0.0014,\n",
      "        0.0193, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.628 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  180000\n",
      "Loss:  -4.482344896993142\n",
      "Loss_orth:  0.0006131753546684263\n",
      "Loss_ML:  -4.48295807234781\n",
      "Logits:  tensor([0.0806, 0.4626, 0.0007, 0.0108, 0.2137, 0.0063, 0.0533, 0.1163, 0.0013,\n",
      "        0.0200, 0.0342], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.359 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  181000\n",
      "Loss:  -4.644440480871247\n",
      "Loss_orth:  0.0007000087639639454\n",
      "Loss_ML:  -4.645140489635211\n",
      "Logits:  tensor([0.0801, 0.4610, 0.0007, 0.0107, 0.2152, 0.0064, 0.0537, 0.1172, 0.0013,\n",
      "        0.0197, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.678 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  182000\n",
      "Loss:  -4.590038042460819\n",
      "Loss_orth:  0.00042558374108456285\n",
      "Loss_ML:  -4.590463626201903\n",
      "Logits:  tensor([0.0803, 0.4644, 0.0007, 0.0107, 0.2132, 0.0063, 0.0533, 0.1170, 0.0014,\n",
      "        0.0195, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.180 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  183000\n",
      "Loss:  -4.70388213465931\n",
      "Loss_orth:  0.0005449078474567167\n",
      "Loss_ML:  -4.704427042506766\n",
      "Logits:  tensor([0.0814, 0.4617, 0.0007, 0.0105, 0.2147, 0.0063, 0.0537, 0.1173, 0.0013,\n",
      "        0.0192, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.752 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  184000\n",
      "Loss:  -4.268120598371681\n",
      "Loss_orth:  0.00025177349547472245\n",
      "Loss_ML:  -4.268372371867155\n",
      "Logits:  tensor([0.0800, 0.4632, 0.0006, 0.0108, 0.2135, 0.0063, 0.0530, 0.1183, 0.0014,\n",
      "        0.0194, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.223 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  185000\n",
      "Loss:  -4.201585730311158\n",
      "Loss_orth:  0.0005574864679385325\n",
      "Loss_ML:  -4.202143216779096\n",
      "Logits:  tensor([0.0804, 0.4628, 0.0006, 0.0109, 0.2133, 0.0065, 0.0536, 0.1176, 0.0014,\n",
      "        0.0198, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.836 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  186000\n",
      "Loss:  -4.37929938141787\n",
      "Loss_orth:  0.00045906657379036375\n",
      "Loss_ML:  -4.3797584479916605\n",
      "Logits:  tensor([0.0798, 0.4622, 0.0006, 0.0109, 0.2142, 0.0065, 0.0538, 0.1171, 0.0014,\n",
      "        0.0198, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.024 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  187000\n",
      "Loss:  -4.245036040616893\n",
      "Loss_orth:  0.000636480871406728\n",
      "Loss_ML:  -4.2456725214882995\n",
      "Logits:  tensor([0.0787, 0.4644, 0.0007, 0.0112, 0.2129, 0.0065, 0.0536, 0.1167, 0.0015,\n",
      "        0.0200, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.224 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  188000\n",
      "Loss:  -4.5252047706014915\n",
      "Loss_orth:  0.0006090013856741115\n",
      "Loss_ML:  -4.525813771987166\n",
      "Logits:  tensor([0.0800, 0.4615, 0.0007, 0.0109, 0.2144, 0.0067, 0.0545, 0.1163, 0.0015,\n",
      "        0.0201, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.788 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  189000\n",
      "Loss:  -4.145380894442253\n",
      "Loss_orth:  0.0003996006452584493\n",
      "Loss_ML:  -4.145780495087512\n",
      "Logits:  tensor([0.0808, 0.4584, 0.0007, 0.0107, 0.2158, 0.0065, 0.0542, 0.1182, 0.0015,\n",
      "        0.0198, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.415 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  190000\n",
      "Loss:  -4.383224494005051\n",
      "Loss_orth:  0.0008218425503524581\n",
      "Loss_ML:  -4.384046336555404\n",
      "Logits:  tensor([0.0793, 0.4636, 0.0007, 0.0104, 0.2155, 0.0064, 0.0527, 0.1171, 0.0014,\n",
      "        0.0196, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.008 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  191000\n",
      "Loss:  -4.233934077484545\n",
      "Loss_orth:  0.0008534333211366722\n",
      "Loss_ML:  -4.234787510805681\n",
      "Logits:  tensor([0.0812, 0.4601, 0.0007, 0.0105, 0.2132, 0.0064, 0.0546, 0.1182, 0.0014,\n",
      "        0.0201, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.103 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  192000\n",
      "Loss:  -4.660223885465008\n",
      "Loss_orth:  0.0005376510242724692\n",
      "Loss_ML:  -4.6607615364892805\n",
      "Logits:  tensor([0.0807, 0.4605, 0.0007, 0.0106, 0.2160, 0.0063, 0.0538, 0.1177, 0.0014,\n",
      "        0.0193, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.836 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  193000\n",
      "Loss:  -4.422363875066159\n",
      "Loss_orth:  0.0005350694007905413\n",
      "Loss_ML:  -4.422898944466949\n",
      "Logits:  tensor([0.0801, 0.4630, 0.0007, 0.0109, 0.2133, 0.0065, 0.0533, 0.1166, 0.0014,\n",
      "        0.0199, 0.0342], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.220 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  194000\n",
      "Loss:  -4.391457297717546\n",
      "Loss_orth:  0.00029512852362127267\n",
      "Loss_ML:  -4.391752426241167\n",
      "Logits:  tensor([0.0802, 0.4609, 0.0007, 0.0110, 0.2135, 0.0066, 0.0542, 0.1172, 0.0015,\n",
      "        0.0199, 0.0344], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.514 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  195000\n",
      "Loss:  -4.460732645295508\n",
      "Loss_orth:  0.00039886389367684125\n",
      "Loss_ML:  -4.461131509189185\n",
      "Logits:  tensor([0.0803, 0.4621, 0.0006, 0.0107, 0.2146, 0.0065, 0.0540, 0.1166, 0.0015,\n",
      "        0.0199, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.866 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  196000\n",
      "Loss:  -4.423381829092851\n",
      "Loss_orth:  0.0011160247254728569\n",
      "Loss_ML:  -4.424497853818324\n",
      "Logits:  tensor([0.0804, 0.4594, 0.0006, 0.0108, 0.2151, 0.0067, 0.0540, 0.1174, 0.0015,\n",
      "        0.0202, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.555 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  197000\n",
      "Loss:  -4.686300733236428\n",
      "Loss_orth:  0.0005259894369839609\n",
      "Loss_ML:  -4.686826722673412\n",
      "Logits:  tensor([0.0799, 0.4607, 0.0006, 0.0107, 0.2165, 0.0066, 0.0537, 0.1170, 0.0015,\n",
      "        0.0195, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.831 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  198000\n",
      "Loss:  -4.221668539659346\n",
      "Loss_orth:  0.0011304828660069924\n",
      "Loss_ML:  -4.222799022525352\n",
      "Logits:  tensor([0.0796, 0.4628, 0.0006, 0.0103, 0.2152, 0.0063, 0.0534, 0.1177, 0.0015,\n",
      "        0.0190, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.506 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  199000\n",
      "Loss:  -4.499352550608424\n",
      "Loss_orth:  0.0006386289863062313\n",
      "Loss_ML:  -4.49999117959473\n",
      "Logits:  tensor([0.0801, 0.4623, 0.0007, 0.0109, 0.2138, 0.0064, 0.0538, 0.1167, 0.0015,\n",
      "        0.0199, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.148 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  200000\n",
      "Loss:  -4.524501161664182\n",
      "Loss_orth:  0.0006497449733900787\n",
      "Loss_ML:  -4.525150906637572\n",
      "Logits:  tensor([0.0802, 0.4624, 0.0007, 0.0107, 0.2142, 0.0062, 0.0541, 0.1171, 0.0015,\n",
      "        0.0197, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.225 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  201000\n",
      "Loss:  -4.4723977871614204\n",
      "Loss_orth:  0.0015291507840387026\n",
      "Loss_ML:  -4.47392693794546\n",
      "Logits:  tensor([0.0794, 0.4635, 0.0007, 0.0111, 0.2143, 0.0062, 0.0530, 0.1163, 0.0015,\n",
      "        0.0203, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.806 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  202000\n",
      "Loss:  -4.43074045761039\n",
      "Loss_orth:  0.0007646818701481148\n",
      "Loss_ML:  -4.431505139480538\n",
      "Logits:  tensor([0.0797, 0.4594, 0.0007, 0.0107, 0.2171, 0.0063, 0.0538, 0.1180, 0.0016,\n",
      "        0.0194, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.699 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  203000\n",
      "Loss:  -4.492196874762189\n",
      "Loss_orth:  0.0003154200131644698\n",
      "Loss_ML:  -4.492512294775353\n",
      "Logits:  tensor([0.0803, 0.4635, 0.0006, 0.0108, 0.2131, 0.0064, 0.0536, 0.1173, 0.0015,\n",
      "        0.0195, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.962 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  204000\n",
      "Loss:  -4.280570569131182\n",
      "Loss_orth:  0.0010505313521570116\n",
      "Loss_ML:  -4.281621100483339\n",
      "Logits:  tensor([0.0799, 0.4617, 0.0006, 0.0108, 0.2140, 0.0064, 0.0544, 0.1177, 0.0016,\n",
      "        0.0198, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.074 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  205000\n",
      "Loss:  -3.9565990194815814\n",
      "Loss_orth:  0.00047093608962844755\n",
      "Loss_ML:  -3.95706995557121\n",
      "Logits:  tensor([0.0793, 0.4641, 0.0006, 0.0109, 0.2135, 0.0065, 0.0537, 0.1168, 0.0016,\n",
      "        0.0195, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.136 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  206000\n",
      "Loss:  -4.098360960183239\n",
      "Loss_orth:  0.0009087598347430634\n",
      "Loss_ML:  -4.099269720017983\n",
      "Logits:  tensor([0.0805, 0.4598, 0.0006, 0.0110, 0.2135, 0.0063, 0.0545, 0.1188, 0.0015,\n",
      "        0.0199, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.670 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  207000\n",
      "Loss:  -4.393502196570497\n",
      "Loss_orth:  0.0005211351970788759\n",
      "Loss_ML:  -4.394023331767576\n",
      "Logits:  tensor([0.0793, 0.4608, 0.0007, 0.0111, 0.2150, 0.0064, 0.0534, 0.1182, 0.0016,\n",
      "        0.0202, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.124 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  208000\n",
      "Loss:  -4.399849671239618\n",
      "Loss_orth:  0.0005211208065705182\n",
      "Loss_ML:  -4.400370792046188\n",
      "Logits:  tensor([0.0792, 0.4626, 0.0006, 0.0107, 0.2150, 0.0063, 0.0535, 0.1169, 0.0016,\n",
      "        0.0204, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.768 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  209000\n",
      "Loss:  -4.271832918169976\n",
      "Loss_orth:  0.00045802459117164963\n",
      "Loss_ML:  -4.272290942761148\n",
      "Logits:  tensor([0.0810, 0.4597, 0.0007, 0.0111, 0.2122, 0.0067, 0.0544, 0.1187, 0.0016,\n",
      "        0.0202, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.606 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  210000\n",
      "Loss:  -4.341321362225727\n",
      "Loss_orth:  0.0005118501485610362\n",
      "Loss_ML:  -4.341833212374288\n",
      "Logits:  tensor([0.0791, 0.4626, 0.0006, 0.0106, 0.2167, 0.0064, 0.0531, 0.1169, 0.0015,\n",
      "        0.0194, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.444 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  211000\n",
      "Loss:  -4.611507170332285\n",
      "Loss_orth:  0.0006021759005084136\n",
      "Loss_ML:  -4.612109346232793\n",
      "Logits:  tensor([0.0806, 0.4626, 0.0007, 0.0111, 0.2119, 0.0065, 0.0540, 0.1174, 0.0015,\n",
      "        0.0199, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.722 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  212000\n",
      "Loss:  -4.444533281738193\n",
      "Loss_orth:  0.0004936881878058116\n",
      "Loss_ML:  -4.4450269699259986\n",
      "Logits:  tensor([0.0805, 0.4624, 0.0007, 0.0105, 0.2155, 0.0064, 0.0535, 0.1166, 0.0016,\n",
      "        0.0193, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.212 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  213000\n",
      "Loss:  -4.472905565567684\n",
      "Loss_orth:  0.0010962157843644735\n",
      "Loss_ML:  -4.474001781352048\n",
      "Logits:  tensor([0.0796, 0.4626, 0.0007, 0.0111, 0.2131, 0.0067, 0.0536, 0.1175, 0.0016,\n",
      "        0.0202, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.087 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  214000\n",
      "Loss:  -4.546344313529422\n",
      "Loss_orth:  0.0006544893281406409\n",
      "Loss_ML:  -4.546998802857563\n",
      "Logits:  tensor([0.0798, 0.4664, 0.0006, 0.0104, 0.2118, 0.0062, 0.0534, 0.1168, 0.0016,\n",
      "        0.0197, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.374 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  215000\n",
      "Loss:  -4.471154359509647\n",
      "Loss_orth:  0.0006049571616453792\n",
      "Loss_ML:  -4.471759316671292\n",
      "Logits:  tensor([0.0792, 0.4661, 0.0006, 0.0108, 0.2141, 0.0065, 0.0529, 0.1159, 0.0017,\n",
      "        0.0193, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.938 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  216000\n",
      "Loss:  -4.624355990222786\n",
      "Loss_orth:  0.0005265765147368381\n",
      "Loss_ML:  -4.624882566737523\n",
      "Logits:  tensor([0.0798, 0.4631, 0.0006, 0.0109, 0.2155, 0.0065, 0.0529, 0.1162, 0.0017,\n",
      "        0.0195, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.772 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  217000\n",
      "Loss:  -4.462554995876226\n",
      "Loss_orth:  0.0003425555507848876\n",
      "Loss_ML:  -4.462897551427011\n",
      "Logits:  tensor([0.0797, 0.4636, 0.0006, 0.0109, 0.2124, 0.0066, 0.0537, 0.1174, 0.0018,\n",
      "        0.0195, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.386 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  218000\n",
      "Loss:  -4.557730136975675\n",
      "Loss_orth:  0.0026374131084177226\n",
      "Loss_ML:  -4.560367550084092\n",
      "Logits:  tensor([0.0796, 0.4592, 0.0006, 0.0109, 0.2175, 0.0068, 0.0531, 0.1174, 0.0019,\n",
      "        0.0196, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.263 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  219000\n",
      "Loss:  -4.420380337089456\n",
      "Loss_orth:  0.0005594679854283163\n",
      "Loss_ML:  -4.420939805074884\n",
      "Logits:  tensor([0.0802, 0.4621, 0.0007, 0.0108, 0.2146, 0.0069, 0.0533, 0.1172, 0.0018,\n",
      "        0.0195, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.538 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  220000\n",
      "Loss:  -4.279490723934629\n",
      "Loss_orth:  0.0009990682902445425\n",
      "Loss_ML:  -4.2804897922248735\n",
      "Logits:  tensor([0.0802, 0.4637, 0.0006, 0.0105, 0.2133, 0.0064, 0.0529, 0.1171, 0.0017,\n",
      "        0.0200, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.190 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  221000\n",
      "Loss:  -4.51946314079803\n",
      "Loss_orth:  0.0009895285329440753\n",
      "Loss_ML:  -4.520452669330974\n",
      "Logits:  tensor([0.0797, 0.4634, 0.0006, 0.0109, 0.2136, 0.0066, 0.0533, 0.1169, 0.0018,\n",
      "        0.0195, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.411 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  222000\n",
      "Loss:  -3.9457909451750206\n",
      "Loss_orth:  0.0007757402062117408\n",
      "Loss_ML:  -3.9465666853812325\n",
      "Logits:  tensor([0.0802, 0.4618, 0.0006, 0.0110, 0.2142, 0.0065, 0.0543, 0.1167, 0.0019,\n",
      "        0.0198, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.223 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  223000\n",
      "Loss:  -4.665867767813148\n",
      "Loss_orth:  0.0007526802562605868\n",
      "Loss_ML:  -4.666620448069408\n",
      "Logits:  tensor([0.0797, 0.4613, 0.0006, 0.0106, 0.2165, 0.0063, 0.0536, 0.1173, 0.0018,\n",
      "        0.0193, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.130 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  224000\n",
      "Loss:  -4.4791513208276745\n",
      "Loss_orth:  0.0006364132580616809\n",
      "Loss_ML:  -4.479787734085736\n",
      "Logits:  tensor([0.0804, 0.4633, 0.0006, 0.0107, 0.2132, 0.0063, 0.0536, 0.1170, 0.0018,\n",
      "        0.0196, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.130 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  225000\n",
      "Loss:  -4.34293203314613\n",
      "Loss_orth:  0.0004975088911929516\n",
      "Loss_ML:  -4.343429542037323\n",
      "Logits:  tensor([0.0794, 0.4623, 0.0006, 0.0108, 0.2132, 0.0064, 0.0548, 0.1173, 0.0018,\n",
      "        0.0200, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.462 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  226000\n",
      "Loss:  -4.2379382431806345\n",
      "Loss_orth:  0.0008619602167135083\n",
      "Loss_ML:  -4.238800203397348\n",
      "Logits:  tensor([0.0804, 0.4605, 0.0006, 0.0112, 0.2135, 0.0064, 0.0537, 0.1184, 0.0019,\n",
      "        0.0200, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.230 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  227000\n",
      "Loss:  -4.318149628856022\n",
      "Loss_orth:  0.0006683583243054053\n",
      "Loss_ML:  -4.318817987180328\n",
      "Logits:  tensor([0.0801, 0.4665, 0.0006, 0.0108, 0.2123, 0.0062, 0.0527, 0.1168, 0.0018,\n",
      "        0.0196, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.149 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  228000\n",
      "Loss:  -4.526706359976007\n",
      "Loss_orth:  0.0005916203834353726\n",
      "Loss_ML:  -4.527297980359442\n",
      "Logits:  tensor([0.0802, 0.4622, 0.0005, 0.0106, 0.2156, 0.0064, 0.0538, 0.1166, 0.0018,\n",
      "        0.0194, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.681 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  229000\n",
      "Loss:  -4.6412785157168654\n",
      "Loss_orth:  0.0006665971546371011\n",
      "Loss_ML:  -4.641945112871502\n",
      "Logits:  tensor([0.0796, 0.4633, 0.0005, 0.0108, 0.2139, 0.0064, 0.0536, 0.1173, 0.0018,\n",
      "        0.0197, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.487 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  230000\n",
      "Loss:  -4.429987315814102\n",
      "Loss_orth:  0.00024944066078718194\n",
      "Loss_ML:  -4.430236756474889\n",
      "Logits:  tensor([0.0795, 0.4633, 0.0006, 0.0110, 0.2122, 0.0066, 0.0539, 0.1173, 0.0019,\n",
      "        0.0201, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.909 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  231000\n",
      "Loss:  -4.449500684875663\n",
      "Loss_orth:  0.0002535494441770581\n",
      "Loss_ML:  -4.44975423431984\n",
      "Logits:  tensor([0.0796, 0.4624, 0.0006, 0.0107, 0.2139, 0.0067, 0.0543, 0.1174, 0.0019,\n",
      "        0.0194, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.221 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  232000\n",
      "Loss:  -4.317438294146344\n",
      "Loss_orth:  0.0008089202692814892\n",
      "Loss_ML:  -4.318247214415625\n",
      "Logits:  tensor([0.0809, 0.4564, 0.0006, 0.0108, 0.2163, 0.0068, 0.0540, 0.1190, 0.0019,\n",
      "        0.0201, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.515 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  233000\n",
      "Loss:  -4.268735304441111\n",
      "Loss_orth:  0.001116077068977474\n",
      "Loss_ML:  -4.2698513815100885\n",
      "Logits:  tensor([0.0797, 0.4608, 0.0006, 0.0109, 0.2154, 0.0065, 0.0536, 0.1178, 0.0018,\n",
      "        0.0197, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.795 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  234000\n",
      "Loss:  -4.480474917888768\n",
      "Loss_orth:  0.0006886571237261309\n",
      "Loss_ML:  -4.481163575012494\n",
      "Logits:  tensor([0.0794, 0.4631, 0.0006, 0.0109, 0.2152, 0.0065, 0.0530, 0.1169, 0.0019,\n",
      "        0.0198, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.706 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  235000\n",
      "Loss:  -4.624491803559019\n",
      "Loss_orth:  0.00046137617482577907\n",
      "Loss_ML:  -4.624953179733845\n",
      "Logits:  tensor([0.0795, 0.4633, 0.0006, 0.0112, 0.2145, 0.0065, 0.0524, 0.1169, 0.0019,\n",
      "        0.0199, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.220 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  236000\n",
      "Loss:  -4.232213039056598\n",
      "Loss_orth:  0.0016590895733858539\n",
      "Loss_ML:  -4.233872128629984\n",
      "Logits:  tensor([0.0803, 0.4597, 0.0006, 0.0117, 0.2130, 0.0065, 0.0540, 0.1178, 0.0021,\n",
      "        0.0204, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.190 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  237000\n",
      "Loss:  -4.925205144770409\n",
      "Loss_orth:  0.001325274989392703\n",
      "Loss_ML:  -4.926530419759802\n",
      "Logits:  tensor([0.0794, 0.4612, 0.0006, 0.0115, 0.2142, 0.0062, 0.0545, 0.1164, 0.0021,\n",
      "        0.0200, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.284 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  238000\n",
      "Loss:  -4.4763855931914485\n",
      "Loss_orth:  0.0005711489366262848\n",
      "Loss_ML:  -4.476956742128075\n",
      "Logits:  tensor([0.0801, 0.4570, 0.0006, 0.0111, 0.2162, 0.0065, 0.0541, 0.1178, 0.0021,\n",
      "        0.0201, 0.0342], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.465 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  239000\n",
      "Loss:  -4.102817289463602\n",
      "Loss_orth:  0.0006508695311422519\n",
      "Loss_ML:  -4.103468158994745\n",
      "Logits:  tensor([0.0810, 0.4623, 0.0006, 0.0109, 0.2117, 0.0064, 0.0541, 0.1173, 0.0022,\n",
      "        0.0196, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.836 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  240000\n",
      "Loss:  -4.473063386859601\n",
      "Loss_orth:  0.0008435083563353738\n",
      "Loss_ML:  -4.473906895215936\n",
      "Logits:  tensor([0.0797, 0.4585, 0.0006, 0.0106, 0.2161, 0.0063, 0.0543, 0.1190, 0.0020,\n",
      "        0.0196, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.644 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  241000\n",
      "Loss:  -4.365602753859515\n",
      "Loss_orth:  0.0003793107566687728\n",
      "Loss_ML:  -4.365982064616184\n",
      "Logits:  tensor([0.0802, 0.4641, 0.0006, 0.0110, 0.2118, 0.0064, 0.0531, 0.1176, 0.0020,\n",
      "        0.0200, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.094 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  242000\n",
      "Loss:  -4.633883230525093\n",
      "Loss_orth:  0.0015170993630614358\n",
      "Loss_ML:  -4.635400329888155\n",
      "Logits:  tensor([0.0794, 0.4616, 0.0007, 0.0112, 0.2146, 0.0065, 0.0539, 0.1168, 0.0021,\n",
      "        0.0198, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.045 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  243000\n",
      "Loss:  -4.655773229807632\n",
      "Loss_orth:  0.0006907127013758307\n",
      "Loss_ML:  -4.656463942509008\n",
      "Logits:  tensor([0.0789, 0.4654, 0.0007, 0.0111, 0.2132, 0.0064, 0.0529, 0.1167, 0.0020,\n",
      "        0.0193, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.045 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  244000\n",
      "Loss:  -4.364593437292372\n",
      "Loss_orth:  0.00130254636268643\n",
      "Loss_ML:  -4.365895983655059\n",
      "Logits:  tensor([0.0801, 0.4665, 0.0007, 0.0110, 0.2129, 0.0064, 0.0527, 0.1150, 0.0020,\n",
      "        0.0194, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.199 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  245000\n",
      "Loss:  -4.278786088244538\n",
      "Loss_orth:  0.001032155355398029\n",
      "Loss_ML:  -4.279818243599936\n",
      "Logits:  tensor([0.0792, 0.4628, 0.0006, 0.0107, 0.2149, 0.0063, 0.0532, 0.1168, 0.0021,\n",
      "        0.0197, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.684 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  246000\n",
      "Loss:  -4.443307476456941\n",
      "Loss_orth:  0.00046783247439871405\n",
      "Loss_ML:  -4.44377530893134\n",
      "Logits:  tensor([0.0803, 0.4635, 0.0006, 0.0110, 0.2124, 0.0064, 0.0543, 0.1165, 0.0021,\n",
      "        0.0195, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.735 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  247000\n",
      "Loss:  -4.500238868443457\n",
      "Loss_orth:  0.0006510746663012002\n",
      "Loss_ML:  -4.500889943109758\n",
      "Logits:  tensor([0.0804, 0.4613, 0.0006, 0.0113, 0.2131, 0.0062, 0.0539, 0.1172, 0.0021,\n",
      "        0.0198, 0.0342], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.447 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  248000\n",
      "Loss:  -4.281665738191279\n",
      "Loss_orth:  0.0005752313148198094\n",
      "Loss_ML:  -4.282240969506099\n",
      "Logits:  tensor([0.0805, 0.4601, 0.0006, 0.0108, 0.2147, 0.0062, 0.0536, 0.1187, 0.0021,\n",
      "        0.0196, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.200 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  249000\n",
      "Loss:  -4.422847177263084\n",
      "Loss_orth:  0.0009210578475463153\n",
      "Loss_ML:  -4.42376823511063\n",
      "Logits:  tensor([0.0805, 0.4599, 0.0006, 0.0107, 0.2144, 0.0062, 0.0541, 0.1176, 0.0022,\n",
      "        0.0196, 0.0342], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.305 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  250000\n",
      "Loss:  -4.661954709713705\n",
      "Loss_orth:  0.0005379686365376109\n",
      "Loss_ML:  -4.662492678350243\n",
      "Logits:  tensor([0.0807, 0.4592, 0.0006, 0.0107, 0.2146, 0.0063, 0.0541, 0.1184, 0.0021,\n",
      "        0.0197, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.176 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  251000\n",
      "Loss:  -4.428451519960351\n",
      "Loss_orth:  0.0012038663744701353\n",
      "Loss_ML:  -4.429655386334821\n",
      "Logits:  tensor([0.0792, 0.4658, 0.0006, 0.0109, 0.2139, 0.0061, 0.0533, 0.1150, 0.0022,\n",
      "        0.0197, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.795 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  252000\n",
      "Loss:  -4.169856683506284\n",
      "Loss_orth:  0.0006515435683400768\n",
      "Loss_ML:  -4.170508227074624\n",
      "Logits:  tensor([0.0799, 0.4614, 0.0006, 0.0109, 0.2141, 0.0062, 0.0531, 0.1179, 0.0022,\n",
      "        0.0200, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.392 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  253000\n",
      "Loss:  -4.535791131233819\n",
      "Loss_orth:  0.00032316290645221986\n",
      "Loss_ML:  -4.536114294140272\n",
      "Logits:  tensor([0.0805, 0.4597, 0.0005, 0.0112, 0.2129, 0.0064, 0.0536, 0.1184, 0.0023,\n",
      "        0.0202, 0.0342], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.017 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  254000\n",
      "Loss:  -4.337152909367366\n",
      "Loss_orth:  0.0004247705404644752\n",
      "Loss_ML:  -4.33757767990783\n",
      "Logits:  tensor([0.0801, 0.4645, 0.0006, 0.0108, 0.2132, 0.0062, 0.0531, 0.1165, 0.0023,\n",
      "        0.0194, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.847 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  255000\n",
      "Loss:  -4.556583430203958\n",
      "Loss_orth:  0.001994594736884682\n",
      "Loss_ML:  -4.558578024940842\n",
      "Logits:  tensor([0.0799, 0.4654, 0.0005, 0.0107, 0.2125, 0.0061, 0.0534, 0.1170, 0.0024,\n",
      "        0.0193, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.882 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  256000\n",
      "Loss:  -4.32309483929709\n",
      "Loss_orth:  0.00045689123353625984\n",
      "Loss_ML:  -4.323551730530626\n",
      "Logits:  tensor([0.0805, 0.4596, 0.0006, 0.0111, 0.2152, 0.0066, 0.0543, 0.1166, 0.0024,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.188 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  257000\n",
      "Loss:  -4.462925810743677\n",
      "Loss_orth:  0.0010550636901460952\n",
      "Loss_ML:  -4.463980874433823\n",
      "Logits:  tensor([0.0788, 0.4637, 0.0006, 0.0110, 0.2139, 0.0066, 0.0531, 0.1166, 0.0024,\n",
      "        0.0198, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.054 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  258000\n",
      "Loss:  -4.269211452695403\n",
      "Loss_orth:  0.0005863924014620995\n",
      "Loss_ML:  -4.269797845096865\n",
      "Logits:  tensor([0.0805, 0.4601, 0.0006, 0.0108, 0.2144, 0.0063, 0.0542, 0.1184, 0.0021,\n",
      "        0.0192, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.217 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  259000\n",
      "Loss:  -4.222372622681245\n",
      "Loss_orth:  0.0014565275438019915\n",
      "Loss_ML:  -4.223829150225047\n",
      "Logits:  tensor([0.0807, 0.4591, 0.0006, 0.0111, 0.2143, 0.0063, 0.0538, 0.1188, 0.0021,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.477 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  260000\n",
      "Loss:  -4.553176806611188\n",
      "Loss_orth:  0.0004820630370744648\n",
      "Loss_ML:  -4.553658869648262\n",
      "Logits:  tensor([0.0800, 0.4643, 0.0006, 0.0107, 0.2124, 0.0062, 0.0535, 0.1176, 0.0021,\n",
      "        0.0196, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.238 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  261000\n",
      "Loss:  -4.606795374120187\n",
      "Loss_orth:  0.0005694955109190552\n",
      "Loss_ML:  -4.607364869631106\n",
      "Logits:  tensor([0.0803, 0.4619, 0.0006, 0.0107, 0.2133, 0.0061, 0.0537, 0.1175, 0.0020,\n",
      "        0.0201, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.888 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  262000\n",
      "Loss:  -4.671396837910577\n",
      "Loss_orth:  0.0005593214477601351\n",
      "Loss_ML:  -4.671956159358337\n",
      "Logits:  tensor([0.0800, 0.4611, 0.0006, 0.0108, 0.2158, 0.0061, 0.0538, 0.1171, 0.0020,\n",
      "        0.0196, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.612 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  263000\n",
      "Loss:  -4.6375221871206636\n",
      "Loss_orth:  0.0009585755429179229\n",
      "Loss_ML:  -4.638480762663582\n",
      "Logits:  tensor([0.0802, 0.4657, 0.0006, 0.0107, 0.2122, 0.0061, 0.0535, 0.1159, 0.0021,\n",
      "        0.0195, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.065 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  264000\n",
      "Loss:  -4.134909095849304\n",
      "Loss_orth:  0.0011094627356445918\n",
      "Loss_ML:  -4.136018558584949\n",
      "Logits:  tensor([0.0793, 0.4592, 0.0006, 0.0113, 0.2168, 0.0062, 0.0540, 0.1173, 0.0022,\n",
      "        0.0196, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.903 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  265000\n",
      "Loss:  -4.291963443885251\n",
      "Loss_orth:  0.0005035703558930413\n",
      "Loss_ML:  -4.2924670142411445\n",
      "Logits:  tensor([0.0793, 0.4637, 0.0006, 0.0108, 0.2135, 0.0063, 0.0524, 0.1182, 0.0022,\n",
      "        0.0200, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.135 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  266000\n",
      "Loss:  -4.267334922641771\n",
      "Loss_orth:  0.0002973029630279917\n",
      "Loss_ML:  -4.267632225604799\n",
      "Logits:  tensor([0.0799, 0.4642, 0.0006, 0.0108, 0.2151, 0.0066, 0.0528, 0.1160, 0.0022,\n",
      "        0.0192, 0.0327], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.266 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  267000\n",
      "Loss:  -4.344102455548438\n",
      "Loss_orth:  0.0006016014024457666\n",
      "Loss_ML:  -4.344704056950884\n",
      "Logits:  tensor([0.0795, 0.4597, 0.0006, 0.0110, 0.2154, 0.0066, 0.0530, 0.1185, 0.0022,\n",
      "        0.0199, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.319 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  268000\n",
      "Loss:  -4.4443581443602325\n",
      "Loss_orth:  0.0006133951560068416\n",
      "Loss_ML:  -4.4449715395162395\n",
      "Logits:  tensor([0.0806, 0.4609, 0.0006, 0.0110, 0.2150, 0.0064, 0.0535, 0.1171, 0.0021,\n",
      "        0.0196, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.418 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  269000\n",
      "Loss:  -4.013241006942589\n",
      "Loss_orth:  0.000562621589307513\n",
      "Loss_ML:  -4.013803628531896\n",
      "Logits:  tensor([0.0805, 0.4609, 0.0006, 0.0110, 0.2136, 0.0062, 0.0539, 0.1175, 0.0022,\n",
      "        0.0200, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.327 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  270000\n",
      "Loss:  -4.479347791686354\n",
      "Loss_orth:  0.000585052186430432\n",
      "Loss_ML:  -4.479932843872785\n",
      "Logits:  tensor([0.0795, 0.4633, 0.0006, 0.0112, 0.2142, 0.0065, 0.0531, 0.1158, 0.0022,\n",
      "        0.0199, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.099 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  271000\n",
      "Loss:  -4.295854402206145\n",
      "Loss_orth:  0.0003153992961489349\n",
      "Loss_ML:  -4.296169801502294\n",
      "Logits:  tensor([0.0799, 0.4635, 0.0007, 0.0114, 0.2111, 0.0064, 0.0538, 0.1166, 0.0024,\n",
      "        0.0202, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.462 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  272000\n",
      "Loss:  -4.388619912490667\n",
      "Loss_orth:  0.0010942077753449434\n",
      "Loss_ML:  -4.389714120266012\n",
      "Logits:  tensor([0.0797, 0.4644, 0.0006, 0.0109, 0.2136, 0.0060, 0.0532, 0.1169, 0.0023,\n",
      "        0.0194, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.562 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  273000\n",
      "Loss:  -4.48613347892309\n",
      "Loss_orth:  0.0006874928589729816\n",
      "Loss_ML:  -4.4868209717820635\n",
      "Logits:  tensor([0.0799, 0.4608, 0.0006, 0.0112, 0.2122, 0.0064, 0.0545, 0.1182, 0.0023,\n",
      "        0.0202, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.915 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  274000\n",
      "Loss:  -4.557995405939471\n",
      "Loss_orth:  0.0006092085660561143\n",
      "Loss_ML:  -4.558604614505527\n",
      "Logits:  tensor([0.0793, 0.4620, 0.0006, 0.0109, 0.2152, 0.0066, 0.0530, 0.1174, 0.0023,\n",
      "        0.0194, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.274 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  275000\n",
      "Loss:  -4.289294411852449\n",
      "Loss_orth:  0.0003955143856308252\n",
      "Loss_ML:  -4.28968992623808\n",
      "Logits:  tensor([0.0796, 0.4649, 0.0006, 0.0106, 0.2119, 0.0064, 0.0536, 0.1170, 0.0023,\n",
      "        0.0197, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.091 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  276000\n",
      "Loss:  -4.508376428981064\n",
      "Loss_orth:  0.0005614095959395513\n",
      "Loss_ML:  -4.508937838577004\n",
      "Logits:  tensor([0.0805, 0.4593, 0.0006, 0.0111, 0.2146, 0.0062, 0.0536, 0.1186, 0.0022,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.672 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  277000\n",
      "Loss:  -4.449130880707219\n",
      "Loss_orth:  0.0003915900752792688\n",
      "Loss_ML:  -4.449522470782498\n",
      "Logits:  tensor([0.0803, 0.4606, 0.0006, 0.0109, 0.2139, 0.0063, 0.0543, 0.1175, 0.0024,\n",
      "        0.0195, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.216 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  278000\n",
      "Loss:  -4.1293878730333455\n",
      "Loss_orth:  0.00045441957303903285\n",
      "Loss_ML:  -4.1298422926063845\n",
      "Logits:  tensor([0.0814, 0.4598, 0.0006, 0.0111, 0.2131, 0.0062, 0.0537, 0.1182, 0.0024,\n",
      "        0.0200, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.700 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  279000\n",
      "Loss:  -4.4477956720523455\n",
      "Loss_orth:  0.000974539792761986\n",
      "Loss_ML:  -4.448770211845107\n",
      "Logits:  tensor([0.0803, 0.4636, 0.0006, 0.0108, 0.2130, 0.0060, 0.0536, 0.1169, 0.0024,\n",
      "        0.0196, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.289 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  280000\n",
      "Loss:  -4.251229115981946\n",
      "Loss_orth:  0.0007140703036679591\n",
      "Loss_ML:  -4.251943186285614\n",
      "Logits:  tensor([0.0798, 0.4629, 0.0006, 0.0112, 0.2127, 0.0062, 0.0536, 0.1180, 0.0023,\n",
      "        0.0194, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.113 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  281000\n",
      "Loss:  -4.365006141434606\n",
      "Loss_orth:  0.0004367724875730657\n",
      "Loss_ML:  -4.3654429139221795\n",
      "Logits:  tensor([0.0794, 0.4635, 0.0006, 0.0110, 0.2163, 0.0061, 0.0531, 0.1165, 0.0022,\n",
      "        0.0189, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.280 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  282000\n",
      "Loss:  -4.463349074274757\n",
      "Loss_orth:  0.0012879247602463491\n",
      "Loss_ML:  -4.464636999035004\n",
      "Logits:  tensor([0.0803, 0.4638, 0.0006, 0.0113, 0.2123, 0.0060, 0.0540, 0.1156, 0.0021,\n",
      "        0.0200, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.092 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  283000\n",
      "Loss:  -4.585751071803163\n",
      "Loss_orth:  0.0007301754607666859\n",
      "Loss_ML:  -4.586481247263929\n",
      "Logits:  tensor([0.0795, 0.4601, 0.0006, 0.0111, 0.2149, 0.0060, 0.0539, 0.1185, 0.0021,\n",
      "        0.0197, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.718 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  284000\n",
      "Loss:  -4.370922773612699\n",
      "Loss_orth:  0.00032539184897625487\n",
      "Loss_ML:  -4.371248165461676\n",
      "Logits:  tensor([0.0794, 0.4618, 0.0006, 0.0113, 0.2143, 0.0063, 0.0542, 0.1172, 0.0022,\n",
      "        0.0198, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.816 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  285000\n",
      "Loss:  -4.203637977037623\n",
      "Loss_orth:  0.0007100003480019628\n",
      "Loss_ML:  -4.204347977385625\n",
      "Logits:  tensor([0.0805, 0.4607, 0.0006, 0.0110, 0.2133, 0.0062, 0.0537, 0.1179, 0.0021,\n",
      "        0.0199, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.729 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  286000\n",
      "Loss:  -4.4026065980880675\n",
      "Loss_orth:  0.0006715252088028479\n",
      "Loss_ML:  -4.403278123296871\n",
      "Logits:  tensor([0.0817, 0.4608, 0.0006, 0.0112, 0.2121, 0.0064, 0.0537, 0.1175, 0.0022,\n",
      "        0.0198, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.440 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  287000\n",
      "Loss:  -4.521070089721614\n",
      "Loss_orth:  0.000954659502116642\n",
      "Loss_ML:  -4.522024749223731\n",
      "Logits:  tensor([0.0802, 0.4632, 0.0006, 0.0110, 0.2139, 0.0064, 0.0532, 0.1169, 0.0021,\n",
      "        0.0196, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.452 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  288000\n",
      "Loss:  -4.601623292036537\n",
      "Loss_orth:  0.0004933103496140194\n",
      "Loss_ML:  -4.602116602386151\n",
      "Logits:  tensor([0.0795, 0.4600, 0.0006, 0.0112, 0.2153, 0.0065, 0.0542, 0.1172, 0.0022,\n",
      "        0.0197, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.822 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  289000\n",
      "Loss:  -4.482294299932871\n",
      "Loss_orth:  0.0010685473695277734\n",
      "Loss_ML:  -4.4833628473023985\n",
      "Logits:  tensor([0.0802, 0.4616, 0.0006, 0.0111, 0.2132, 0.0063, 0.0538, 0.1193, 0.0021,\n",
      "        0.0187, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.120 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  290000\n",
      "Loss:  -4.2607861585823885\n",
      "Loss_orth:  0.0005910496153101468\n",
      "Loss_ML:  -4.261377208197699\n",
      "Logits:  tensor([0.0793, 0.4611, 0.0006, 0.0109, 0.2170, 0.0059, 0.0530, 0.1177, 0.0022,\n",
      "        0.0196, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.832 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  291000\n",
      "Loss:  -4.522959342425985\n",
      "Loss_orth:  0.0002961775415932439\n",
      "Loss_ML:  -4.523255519967578\n",
      "Logits:  tensor([0.0793, 0.4619, 0.0006, 0.0111, 0.2145, 0.0061, 0.0536, 0.1180, 0.0022,\n",
      "        0.0198, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.720 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  292000\n",
      "Loss:  -4.186691219307574\n",
      "Loss_orth:  0.0006927955935299761\n",
      "Loss_ML:  -4.187384014901103\n",
      "Logits:  tensor([0.0810, 0.4630, 0.0006, 0.0113, 0.2127, 0.0061, 0.0537, 0.1166, 0.0023,\n",
      "        0.0196, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.818 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  293000\n",
      "Loss:  -4.047762407741868\n",
      "Loss_orth:  0.0009006731526766297\n",
      "Loss_ML:  -4.048663080894545\n",
      "Logits:  tensor([0.0803, 0.4589, 0.0006, 0.0107, 0.2155, 0.0060, 0.0542, 0.1185, 0.0022,\n",
      "        0.0191, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.532 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  294000\n",
      "Loss:  -4.408851221969318\n",
      "Loss_orth:  0.0013061571997377004\n",
      "Loss_ML:  -4.410157379169055\n",
      "Logits:  tensor([0.0800, 0.4641, 0.0006, 0.0113, 0.2111, 0.0063, 0.0547, 0.1166, 0.0022,\n",
      "        0.0194, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.474 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  295000\n",
      "Loss:  -4.759499310696632\n",
      "Loss_orth:  0.0012243875718618844\n",
      "Loss_ML:  -4.760723698268494\n",
      "Logits:  tensor([0.0802, 0.4591, 0.0006, 0.0114, 0.2148, 0.0064, 0.0538, 0.1167, 0.0024,\n",
      "        0.0201, 0.0345], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.716 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  296000\n",
      "Loss:  -4.405057484243145\n",
      "Loss_orth:  0.00047865598670278884\n",
      "Loss_ML:  -4.405536140229848\n",
      "Logits:  tensor([0.0803, 0.4613, 0.0006, 0.0114, 0.2117, 0.0065, 0.0544, 0.1176, 0.0024,\n",
      "        0.0199, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.860 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  297000\n",
      "Loss:  -4.61438847468359\n",
      "Loss_orth:  0.0005135647635272491\n",
      "Loss_ML:  -4.614902039447117\n",
      "Logits:  tensor([0.0802, 0.4624, 0.0006, 0.0113, 0.2101, 0.0066, 0.0538, 0.1189, 0.0024,\n",
      "        0.0199, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.117 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  298000\n",
      "Loss:  -4.413895836030376\n",
      "Loss_orth:  0.0010070109758396953\n",
      "Loss_ML:  -4.414902847006215\n",
      "Logits:  tensor([0.0796, 0.4619, 0.0006, 0.0110, 0.2150, 0.0064, 0.0531, 0.1161, 0.0025,\n",
      "        0.0197, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.427 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  299000\n",
      "Loss:  -4.686132151711758\n",
      "Loss_orth:  0.0007253909628179163\n",
      "Loss_ML:  -4.686857542674575\n",
      "Logits:  tensor([0.0797, 0.4626, 0.0006, 0.0110, 0.2140, 0.0062, 0.0541, 0.1170, 0.0026,\n",
      "        0.0192, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.430 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  300000\n",
      "Loss:  -4.4434822967692975\n",
      "Loss_orth:  0.0010104582719963927\n",
      "Loss_ML:  -4.444492755041294\n",
      "Logits:  tensor([0.0803, 0.4614, 0.0006, 0.0111, 0.2126, 0.0061, 0.0538, 0.1191, 0.0026,\n",
      "        0.0197, 0.0327], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.096 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  301000\n",
      "Loss:  -4.316546224470671\n",
      "Loss_orth:  0.00042356669351361525\n",
      "Loss_ML:  -4.316969791164185\n",
      "Logits:  tensor([0.0798, 0.4631, 0.0007, 0.0112, 0.2130, 0.0063, 0.0529, 0.1174, 0.0027,\n",
      "        0.0196, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.959 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  302000\n",
      "Loss:  -4.801521975744025\n",
      "Loss_orth:  0.0013182140492694757\n",
      "Loss_ML:  -4.802840189793295\n",
      "Logits:  tensor([0.0815, 0.4583, 0.0007, 0.0116, 0.2123, 0.0064, 0.0549, 0.1176, 0.0027,\n",
      "        0.0199, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.184 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  303000\n",
      "Loss:  -4.448012856511767\n",
      "Loss_orth:  0.0006305467118448461\n",
      "Loss_ML:  -4.4486434032236115\n",
      "Logits:  tensor([0.0799, 0.4605, 0.0007, 0.0113, 0.2127, 0.0063, 0.0542, 0.1178, 0.0028,\n",
      "        0.0198, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.697 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  304000\n",
      "Loss:  -4.275895999164041\n",
      "Loss_orth:  0.0006136473968032481\n",
      "Loss_ML:  -4.276509646560844\n",
      "Logits:  tensor([0.0798, 0.4644, 0.0007, 0.0109, 0.2146, 0.0061, 0.0532, 0.1166, 0.0027,\n",
      "        0.0189, 0.0321], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.882 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  305000\n",
      "Loss:  -4.2726464931485175\n",
      "Loss_orth:  0.00042652977335937413\n",
      "Loss_ML:  -4.273073022921877\n",
      "Logits:  tensor([0.0804, 0.4569, 0.0007, 0.0108, 0.2173, 0.0061, 0.0545, 0.1180, 0.0027,\n",
      "        0.0192, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.517 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  306000\n",
      "Loss:  -4.5922887961928645\n",
      "Loss_orth:  0.001144917628389885\n",
      "Loss_ML:  -4.593433713821255\n",
      "Logits:  tensor([0.0803, 0.4572, 0.0007, 0.0111, 0.2137, 0.0067, 0.0546, 0.1190, 0.0027,\n",
      "        0.0197, 0.0343], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.309 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  307000\n",
      "Loss:  -4.452245830523635\n",
      "Loss_orth:  0.0010851125821610126\n",
      "Loss_ML:  -4.453330943105796\n",
      "Logits:  tensor([0.0795, 0.4637, 0.0007, 0.0113, 0.2115, 0.0066, 0.0541, 0.1170, 0.0027,\n",
      "        0.0197, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.884 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  308000\n",
      "Loss:  -4.5565653123977174\n",
      "Loss_orth:  0.0006115093494511187\n",
      "Loss_ML:  -4.557176821747168\n",
      "Logits:  tensor([0.0799, 0.4607, 0.0008, 0.0114, 0.2133, 0.0065, 0.0534, 0.1182, 0.0026,\n",
      "        0.0198, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.264 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  309000\n",
      "Loss:  -4.567113915508062\n",
      "Loss_orth:  0.00032852632649445\n",
      "Loss_ML:  -4.567442441834556\n",
      "Logits:  tensor([0.0805, 0.4629, 0.0008, 0.0111, 0.2109, 0.0064, 0.0542, 0.1173, 0.0027,\n",
      "        0.0199, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.315 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  310000\n",
      "Loss:  -4.471549089580553\n",
      "Loss_orth:  0.0003297923366537187\n",
      "Loss_ML:  -4.471878881917207\n",
      "Logits:  tensor([0.0796, 0.4600, 0.0008, 0.0112, 0.2146, 0.0062, 0.0538, 0.1178, 0.0027,\n",
      "        0.0196, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.437 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  311000\n",
      "Loss:  -4.587512331504645\n",
      "Loss_orth:  0.0005215457400672401\n",
      "Loss_ML:  -4.588033877244713\n",
      "Logits:  tensor([0.0801, 0.4626, 0.0007, 0.0110, 0.2130, 0.0061, 0.0534, 0.1174, 0.0027,\n",
      "        0.0195, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.034 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  312000\n",
      "Loss:  -4.297678988635775\n",
      "Loss_orth:  0.0005607516226305048\n",
      "Loss_ML:  -4.298239740258406\n",
      "Logits:  tensor([0.0800, 0.4614, 0.0007, 0.0112, 0.2145, 0.0062, 0.0538, 0.1168, 0.0027,\n",
      "        0.0196, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.448 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  313000\n",
      "Loss:  -4.164152444455891\n",
      "Loss_orth:  0.00028986848018205247\n",
      "Loss_ML:  -4.164442312936074\n",
      "Logits:  tensor([0.0790, 0.4638, 0.0007, 0.0110, 0.2125, 0.0062, 0.0540, 0.1177, 0.0026,\n",
      "        0.0195, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.021 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  314000\n",
      "Loss:  -4.351529847882889\n",
      "Loss_orth:  0.00033510245049766623\n",
      "Loss_ML:  -4.351864950333387\n",
      "Logits:  tensor([0.0796, 0.4651, 0.0007, 0.0107, 0.2136, 0.0062, 0.0528, 0.1166, 0.0025,\n",
      "        0.0190, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.924 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  315000\n",
      "Loss:  -4.298746089996633\n",
      "Loss_orth:  0.0007333360586776083\n",
      "Loss_ML:  -4.29947942605531\n",
      "Logits:  tensor([0.0804, 0.4639, 0.0007, 0.0112, 0.2116, 0.0062, 0.0534, 0.1165, 0.0027,\n",
      "        0.0198, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.455 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  316000\n",
      "Loss:  -4.273065199046605\n",
      "Loss_orth:  0.0006762064898319408\n",
      "Loss_ML:  -4.273741405536437\n",
      "Logits:  tensor([0.0803, 0.4615, 0.0007, 0.0114, 0.2120, 0.0063, 0.0544, 0.1171, 0.0027,\n",
      "        0.0198, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.317 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  317000\n",
      "Loss:  -4.645359123023589\n",
      "Loss_orth:  0.0005117925684446893\n",
      "Loss_ML:  -4.645870915592034\n",
      "Logits:  tensor([0.0805, 0.4624, 0.0007, 0.0109, 0.2127, 0.0063, 0.0539, 0.1175, 0.0026,\n",
      "        0.0196, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.175 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  318000\n",
      "Loss:  -4.405249813075653\n",
      "Loss_orth:  0.000534357744275322\n",
      "Loss_ML:  -4.405784170819929\n",
      "Logits:  tensor([0.0788, 0.4647, 0.0007, 0.0114, 0.2123, 0.0061, 0.0533, 0.1168, 0.0026,\n",
      "        0.0200, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.511 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  319000\n",
      "Loss:  -4.534490312562754\n",
      "Loss_orth:  0.0007400515514997899\n",
      "Loss_ML:  -4.535230364114254\n",
      "Logits:  tensor([0.0801, 0.4614, 0.0007, 0.0111, 0.2127, 0.0064, 0.0544, 0.1176, 0.0025,\n",
      "        0.0196, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.175 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  320000\n",
      "Loss:  -4.346747662457781\n",
      "Loss_orth:  0.00036877232604354607\n",
      "Loss_ML:  -4.347116434783825\n",
      "Logits:  tensor([0.0798, 0.4633, 0.0007, 0.0110, 0.2128, 0.0063, 0.0538, 0.1167, 0.0026,\n",
      "        0.0198, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.649 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  321000\n",
      "Loss:  -4.414618897518687\n",
      "Loss_orth:  0.0005170550621680073\n",
      "Loss_ML:  -4.4151359525808545\n",
      "Logits:  tensor([0.0802, 0.4587, 0.0007, 0.0116, 0.2149, 0.0065, 0.0538, 0.1173, 0.0028,\n",
      "        0.0200, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.518 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  322000\n",
      "Loss:  -4.1310633320167165\n",
      "Loss_orth:  0.0007241672071597867\n",
      "Loss_ML:  -4.131787499223877\n",
      "Logits:  tensor([0.0802, 0.4626, 0.0007, 0.0114, 0.2115, 0.0067, 0.0533, 0.1172, 0.0030,\n",
      "        0.0199, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.410 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  323000\n",
      "Loss:  -4.5993323634310075\n",
      "Loss_orth:  0.0007686930525484856\n",
      "Loss_ML:  -4.600101056483556\n",
      "Logits:  tensor([0.0799, 0.4625, 0.0007, 0.0114, 0.2127, 0.0067, 0.0531, 0.1169, 0.0029,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.846 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  324000\n",
      "Loss:  -4.446754165514773\n",
      "Loss_orth:  0.0008070551757542633\n",
      "Loss_ML:  -4.4475612206905275\n",
      "Logits:  tensor([0.0792, 0.4632, 0.0007, 0.0111, 0.2140, 0.0064, 0.0529, 0.1170, 0.0030,\n",
      "        0.0196, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.728 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  325000\n",
      "Loss:  -4.3965227471483725\n",
      "Loss_orth:  0.0006592514769063573\n",
      "Loss_ML:  -4.397181998625279\n",
      "Logits:  tensor([0.0798, 0.4575, 0.0007, 0.0114, 0.2157, 0.0060, 0.0538, 0.1195, 0.0029,\n",
      "        0.0196, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.699 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  326000\n",
      "Loss:  -4.491577633042799\n",
      "Loss_orth:  0.0004981284387200339\n",
      "Loss_ML:  -4.492075761481519\n",
      "Logits:  tensor([0.0808, 0.4605, 0.0007, 0.0111, 0.2121, 0.0062, 0.0542, 0.1175, 0.0028,\n",
      "        0.0199, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.181 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  327000\n",
      "Loss:  -4.525706695746489\n",
      "Loss_orth:  0.0005969951402353834\n",
      "Loss_ML:  -4.526303690886725\n",
      "Logits:  tensor([0.0783, 0.4635, 0.0007, 0.0113, 0.2135, 0.0062, 0.0538, 0.1164, 0.0028,\n",
      "        0.0197, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.577 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  328000\n",
      "Loss:  -4.251622837375183\n",
      "Loss_orth:  0.0006163338008590377\n",
      "Loss_ML:  -4.252239171176042\n",
      "Logits:  tensor([0.0802, 0.4604, 0.0007, 0.0110, 0.2136, 0.0061, 0.0547, 0.1169, 0.0027,\n",
      "        0.0197, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.515 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  329000\n",
      "Loss:  -4.735502161671663\n",
      "Loss_orth:  0.00034350390249374667\n",
      "Loss_ML:  -4.735845665574157\n",
      "Logits:  tensor([0.0796, 0.4605, 0.0008, 0.0112, 0.2147, 0.0062, 0.0536, 0.1166, 0.0027,\n",
      "        0.0198, 0.0344], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.121 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  330000\n",
      "Loss:  -4.434785367732023\n",
      "Loss_orth:  0.0005589169809990282\n",
      "Loss_ML:  -4.435344284713023\n",
      "Logits:  tensor([0.0801, 0.4581, 0.0008, 0.0114, 0.2143, 0.0064, 0.0540, 0.1180, 0.0029,\n",
      "        0.0201, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.799 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  331000\n",
      "Loss:  -4.449277769621436\n",
      "Loss_orth:  0.0010743288417758732\n",
      "Loss_ML:  -4.450352098463212\n",
      "Logits:  tensor([0.0786, 0.4623, 0.0008, 0.0113, 0.2127, 0.0064, 0.0534, 0.1175, 0.0029,\n",
      "        0.0204, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.731 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  332000\n",
      "Loss:  -4.280570817066516\n",
      "Loss_orth:  0.0005924056558398954\n",
      "Loss_ML:  -4.2811632227223555\n",
      "Logits:  tensor([0.0799, 0.4601, 0.0008, 0.0113, 0.2137, 0.0063, 0.0535, 0.1175, 0.0027,\n",
      "        0.0201, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.530 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  333000\n",
      "Loss:  -4.437710016153729\n",
      "Loss_orth:  0.0006738676515274537\n",
      "Loss_ML:  -4.4383838838052565\n",
      "Logits:  tensor([0.0807, 0.4585, 0.0008, 0.0111, 0.2135, 0.0062, 0.0537, 0.1192, 0.0027,\n",
      "        0.0196, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.376 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  334000\n",
      "Loss:  -4.252878240558661\n",
      "Loss_orth:  0.0008116399918149561\n",
      "Loss_ML:  -4.253689880550476\n",
      "Logits:  tensor([0.0800, 0.4622, 0.0009, 0.0115, 0.2122, 0.0063, 0.0538, 0.1169, 0.0027,\n",
      "        0.0197, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.620 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  335000\n",
      "Loss:  -4.293305239545572\n",
      "Loss_orth:  0.0007466370758602963\n",
      "Loss_ML:  -4.294051876621432\n",
      "Logits:  tensor([0.0792, 0.4644, 0.0008, 0.0110, 0.2135, 0.0060, 0.0533, 0.1161, 0.0026,\n",
      "        0.0197, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.672 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  336000\n",
      "Loss:  -4.819315574609555\n",
      "Loss_orth:  0.00048654353362929703\n",
      "Loss_ML:  -4.819802118143184\n",
      "Logits:  tensor([0.0815, 0.4595, 0.0008, 0.0109, 0.2137, 0.0060, 0.0544, 0.1178, 0.0026,\n",
      "        0.0194, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.484 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  337000\n",
      "Loss:  -4.59138540979779\n",
      "Loss_orth:  0.0006862645086977243\n",
      "Loss_ML:  -4.592071674306488\n",
      "Logits:  tensor([0.0802, 0.4602, 0.0008, 0.0114, 0.2136, 0.0062, 0.0539, 0.1175, 0.0026,\n",
      "        0.0197, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.586 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  338000\n",
      "Loss:  -4.399795754056615\n",
      "Loss_orth:  0.0008611680087727068\n",
      "Loss_ML:  -4.400656922065387\n",
      "Logits:  tensor([0.0811, 0.4582, 0.0009, 0.0119, 0.2124, 0.0065, 0.0540, 0.1178, 0.0027,\n",
      "        0.0207, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.358 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  339000\n",
      "Loss:  -4.357215102076037\n",
      "Loss_orth:  0.00042430616279468127\n",
      "Loss_ML:  -4.357639408238831\n",
      "Logits:  tensor([0.0795, 0.4624, 0.0009, 0.0114, 0.2110, 0.0066, 0.0544, 0.1171, 0.0026,\n",
      "        0.0200, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.950 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  340000\n",
      "Loss:  -4.309944606118059\n",
      "Loss_orth:  0.00036458374672010104\n",
      "Loss_ML:  -4.310309189864778\n",
      "Logits:  tensor([0.0803, 0.4633, 0.0009, 0.0109, 0.2125, 0.0064, 0.0541, 0.1160, 0.0027,\n",
      "        0.0193, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.833 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  341000\n",
      "Loss:  -4.730102818271172\n",
      "Loss_orth:  0.0006913709570956732\n",
      "Loss_ML:  -4.730794189228268\n",
      "Logits:  tensor([0.0790, 0.4654, 0.0008, 0.0109, 0.2135, 0.0061, 0.0529, 0.1166, 0.0027,\n",
      "        0.0192, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.594 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  342000\n",
      "Loss:  -4.23570813569311\n",
      "Loss_orth:  0.0005424215316567639\n",
      "Loss_ML:  -4.236250557224767\n",
      "Logits:  tensor([0.0798, 0.4626, 0.0008, 0.0111, 0.2136, 0.0060, 0.0529, 0.1183, 0.0026,\n",
      "        0.0192, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.627 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  343000\n",
      "Loss:  -4.420674687448662\n",
      "Loss_orth:  0.0007145688944335594\n",
      "Loss_ML:  -4.421389256343096\n",
      "Logits:  tensor([0.0794, 0.4605, 0.0008, 0.0114, 0.2147, 0.0064, 0.0537, 0.1169, 0.0027,\n",
      "        0.0196, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.616 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  344000\n",
      "Loss:  -4.679780442270859\n",
      "Loss_orth:  0.0008133779681394618\n",
      "Loss_ML:  -4.6805938202389985\n",
      "Logits:  tensor([0.0798, 0.4625, 0.0008, 0.0115, 0.2132, 0.0065, 0.0534, 0.1163, 0.0029,\n",
      "        0.0196, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.798 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  345000\n",
      "Loss:  -4.437166791787808\n",
      "Loss_orth:  0.0009016992341155958\n",
      "Loss_ML:  -4.438068491021924\n",
      "Logits:  tensor([0.0801, 0.4594, 0.0008, 0.0113, 0.2156, 0.0065, 0.0539, 0.1162, 0.0028,\n",
      "        0.0198, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.723 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  346000\n",
      "Loss:  -4.273087415716759\n",
      "Loss_orth:  0.0003072238779534675\n",
      "Loss_ML:  -4.273394639594713\n",
      "Logits:  tensor([0.0811, 0.4596, 0.0009, 0.0113, 0.2134, 0.0068, 0.0532, 0.1182, 0.0028,\n",
      "        0.0196, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 58.427 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  347000\n",
      "Loss:  -4.344935737950932\n",
      "Loss_orth:  0.0007401089160480812\n",
      "Loss_ML:  -4.34567584686698\n",
      "Logits:  tensor([0.0792, 0.4620, 0.0008, 0.0108, 0.2132, 0.0064, 0.0536, 0.1176, 0.0027,\n",
      "        0.0197, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.623 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  348000\n",
      "Loss:  -4.529895652063245\n",
      "Loss_orth:  0.00029172307328810976\n",
      "Loss_ML:  -4.530187375136533\n",
      "Logits:  tensor([0.0792, 0.4638, 0.0008, 0.0110, 0.2142, 0.0065, 0.0528, 0.1165, 0.0026,\n",
      "        0.0195, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.920 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  349000\n",
      "Loss:  -4.63948367366549\n",
      "Loss_orth:  0.0010194621557011005\n",
      "Loss_ML:  -4.640503135821191\n",
      "Logits:  tensor([0.0800, 0.4643, 0.0009, 0.0113, 0.2099, 0.0064, 0.0538, 0.1174, 0.0028,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.560 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  350000\n",
      "Loss:  -4.572589429310072\n",
      "Loss_orth:  0.0004913067523361341\n",
      "Loss_ML:  -4.5730807360624075\n",
      "Logits:  tensor([0.0804, 0.4632, 0.0009, 0.0109, 0.2124, 0.0060, 0.0533, 0.1173, 0.0026,\n",
      "        0.0196, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.005 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  351000\n",
      "Loss:  -4.530537839556213\n",
      "Loss_orth:  0.0010840537604378565\n",
      "Loss_ML:  -4.53162189331665\n",
      "Logits:  tensor([0.0812, 0.4599, 0.0009, 0.0111, 0.2134, 0.0061, 0.0538, 0.1182, 0.0025,\n",
      "        0.0195, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.679 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  352000\n",
      "Loss:  -4.1230012240365586\n",
      "Loss_orth:  0.000703166997263857\n",
      "Loss_ML:  -4.123704391033822\n",
      "Logits:  tensor([0.0808, 0.4591, 0.0009, 0.0111, 0.2153, 0.0062, 0.0529, 0.1186, 0.0027,\n",
      "        0.0194, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.891 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  353000\n",
      "Loss:  -3.9957238494364256\n",
      "Loss_orth:  0.0004177958983386736\n",
      "Loss_ML:  -3.996141645334764\n",
      "Logits:  tensor([0.0800, 0.4616, 0.0009, 0.0115, 0.2119, 0.0065, 0.0537, 0.1169, 0.0027,\n",
      "        0.0200, 0.0344], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.365 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  354000\n",
      "Loss:  -4.4940450199003825\n",
      "Loss_orth:  0.0007739154076846299\n",
      "Loss_ML:  -4.494818935308067\n",
      "Logits:  tensor([0.0787, 0.4617, 0.0009, 0.0109, 0.2141, 0.0062, 0.0535, 0.1180, 0.0026,\n",
      "        0.0197, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.999 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  355000\n",
      "Loss:  -4.178526271337795\n",
      "Loss_orth:  0.0006825103738036277\n",
      "Loss_ML:  -4.179208781711599\n",
      "Logits:  tensor([0.0806, 0.4613, 0.0008, 0.0107, 0.2149, 0.0059, 0.0534, 0.1179, 0.0026,\n",
      "        0.0193, 0.0326], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.286 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  356000\n",
      "Loss:  -3.958453886678293\n",
      "Loss_orth:  0.0011845721383535296\n",
      "Loss_ML:  -3.9596384588166464\n",
      "Logits:  tensor([0.0800, 0.4632, 0.0009, 0.0110, 0.2129, 0.0060, 0.0535, 0.1169, 0.0025,\n",
      "        0.0195, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.487 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  357000\n",
      "Loss:  -4.517164583125061\n",
      "Loss_orth:  0.0005436470934469796\n",
      "Loss_ML:  -4.517708230218508\n",
      "Logits:  tensor([0.0809, 0.4600, 0.0009, 0.0115, 0.2141, 0.0063, 0.0535, 0.1172, 0.0025,\n",
      "        0.0197, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.863 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  358000\n",
      "Loss:  -4.381444081757352\n",
      "Loss_orth:  0.001393771100272656\n",
      "Loss_ML:  -4.382837852857625\n",
      "Logits:  tensor([0.0804, 0.4630, 0.0009, 0.0112, 0.2134, 0.0062, 0.0526, 0.1168, 0.0026,\n",
      "        0.0195, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.262 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  359000\n",
      "Loss:  -4.414245209931507\n",
      "Loss_orth:  0.0011410186428619416\n",
      "Loss_ML:  -4.415386228574369\n",
      "Logits:  tensor([0.0798, 0.4609, 0.0009, 0.0112, 0.2127, 0.0061, 0.0534, 0.1188, 0.0027,\n",
      "        0.0195, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.254 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  360000\n",
      "Loss:  -4.349399222590695\n",
      "Loss_orth:  0.0005375355146806498\n",
      "Loss_ML:  -4.349936758105376\n",
      "Logits:  tensor([0.0800, 0.4607, 0.0009, 0.0109, 0.2159, 0.0064, 0.0536, 0.1174, 0.0025,\n",
      "        0.0186, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.831 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  361000\n",
      "Loss:  -4.249642344772358\n",
      "Loss_orth:  0.0006053390977054913\n",
      "Loss_ML:  -4.250247683870064\n",
      "Logits:  tensor([0.0789, 0.4611, 0.0009, 0.0114, 0.2159, 0.0061, 0.0534, 0.1167, 0.0025,\n",
      "        0.0197, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.455 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  362000\n",
      "Loss:  -4.561438785866858\n",
      "Loss_orth:  0.0005178775806093365\n",
      "Loss_ML:  -4.561956663447467\n",
      "Logits:  tensor([0.0804, 0.4630, 0.0009, 0.0113, 0.2109, 0.0064, 0.0533, 0.1179, 0.0026,\n",
      "        0.0196, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.017 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  363000\n",
      "Loss:  -4.313528772356908\n",
      "Loss_orth:  0.0013643669258051694\n",
      "Loss_ML:  -4.314893139282713\n",
      "Logits:  tensor([0.0798, 0.4638, 0.0009, 0.0110, 0.2120, 0.0063, 0.0536, 0.1167, 0.0026,\n",
      "        0.0197, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.044 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  364000\n",
      "Loss:  -4.378090817014133\n",
      "Loss_orth:  0.0004209886148108904\n",
      "Loss_ML:  -4.378511805628944\n",
      "Logits:  tensor([0.0793, 0.4624, 0.0009, 0.0111, 0.2132, 0.0064, 0.0529, 0.1179, 0.0027,\n",
      "        0.0197, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.457 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  365000\n",
      "Loss:  -4.140360173096294\n",
      "Loss_orth:  0.0004825869073045218\n",
      "Loss_ML:  -4.140842760003599\n",
      "Logits:  tensor([0.0792, 0.4622, 0.0009, 0.0114, 0.2133, 0.0064, 0.0533, 0.1174, 0.0026,\n",
      "        0.0200, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.233 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  366000\n",
      "Loss:  -4.3390024584672835\n",
      "Loss_orth:  0.0009298839028626124\n",
      "Loss_ML:  -4.339932342370146\n",
      "Logits:  tensor([0.0811, 0.4610, 0.0009, 0.0115, 0.2134, 0.0063, 0.0531, 0.1173, 0.0026,\n",
      "        0.0197, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.577 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  367000\n",
      "Loss:  -4.494035600000651\n",
      "Loss_orth:  0.0005431036369664418\n",
      "Loss_ML:  -4.494578703637617\n",
      "Logits:  tensor([0.0800, 0.4607, 0.0009, 0.0112, 0.2140, 0.0064, 0.0536, 0.1177, 0.0027,\n",
      "        0.0196, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.325 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  368000\n",
      "Loss:  -4.559386270042042\n",
      "Loss_orth:  0.00045372985997481704\n",
      "Loss_ML:  -4.5598399999020165\n",
      "Logits:  tensor([0.0801, 0.4657, 0.0009, 0.0107, 0.2119, 0.0060, 0.0527, 0.1175, 0.0025,\n",
      "        0.0190, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.549 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  369000\n",
      "Loss:  -4.4705472364786205\n",
      "Loss_orth:  0.0006339736302735619\n",
      "Loss_ML:  -4.471181210108894\n",
      "Logits:  tensor([0.0798, 0.4626, 0.0009, 0.0112, 0.2138, 0.0063, 0.0538, 0.1165, 0.0025,\n",
      "        0.0195, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.200 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  370000\n",
      "Loss:  -4.2734334644706164\n",
      "Loss_orth:  0.0008449567189962551\n",
      "Loss_ML:  -4.274278421189613\n",
      "Logits:  tensor([0.0797, 0.4605, 0.0009, 0.0112, 0.2144, 0.0061, 0.0533, 0.1182, 0.0026,\n",
      "        0.0197, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.162 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  371000\n",
      "Loss:  -4.497934459478027\n",
      "Loss_orth:  0.0006334457993808242\n",
      "Loss_ML:  -4.498567905277408\n",
      "Logits:  tensor([0.0790, 0.4585, 0.0009, 0.0111, 0.2150, 0.0064, 0.0539, 0.1189, 0.0026,\n",
      "        0.0198, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.629 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  372000\n",
      "Loss:  -4.550201800701704\n",
      "Loss_orth:  0.0005471373888396125\n",
      "Loss_ML:  -4.550748938090544\n",
      "Logits:  tensor([0.0798, 0.4601, 0.0009, 0.0115, 0.2154, 0.0064, 0.0527, 0.1172, 0.0026,\n",
      "        0.0202, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.323 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  373000\n",
      "Loss:  -4.519240311590334\n",
      "Loss_orth:  0.0011382017586090028\n",
      "Loss_ML:  -4.520378513348943\n",
      "Logits:  tensor([0.0800, 0.4642, 0.0009, 0.0113, 0.2123, 0.0063, 0.0536, 0.1161, 0.0027,\n",
      "        0.0197, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.380 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  374000\n",
      "Loss:  -4.352521912398142\n",
      "Loss_orth:  0.0009506566493973595\n",
      "Loss_ML:  -4.35347256904754\n",
      "Logits:  tensor([0.0799, 0.4598, 0.0008, 0.0110, 0.2148, 0.0059, 0.0538, 0.1183, 0.0026,\n",
      "        0.0196, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.064 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  375000\n",
      "Loss:  -4.194222361279022\n",
      "Loss_orth:  0.0011444340566834506\n",
      "Loss_ML:  -4.195366795335705\n",
      "Logits:  tensor([0.0789, 0.4631, 0.0009, 0.0108, 0.2148, 0.0061, 0.0529, 0.1165, 0.0027,\n",
      "        0.0198, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.135 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  376000\n",
      "Loss:  -4.702361515180616\n",
      "Loss_orth:  0.000587741602657764\n",
      "Loss_ML:  -4.702949256783274\n",
      "Logits:  tensor([0.0799, 0.4617, 0.0009, 0.0110, 0.2139, 0.0061, 0.0532, 0.1181, 0.0026,\n",
      "        0.0194, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.087 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  377000\n",
      "Loss:  -4.295270291706069\n",
      "Loss_orth:  0.0022763737421435206\n",
      "Loss_ML:  -4.297546665448213\n",
      "Logits:  tensor([0.0802, 0.4589, 0.0009, 0.0114, 0.2138, 0.0063, 0.0544, 0.1181, 0.0026,\n",
      "        0.0197, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.042 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  378000\n",
      "Loss:  -4.306537354608811\n",
      "Loss_orth:  0.0005393686033251674\n",
      "Loss_ML:  -4.307076723212137\n",
      "Logits:  tensor([0.0802, 0.4614, 0.0009, 0.0114, 0.2133, 0.0064, 0.0528, 0.1183, 0.0026,\n",
      "        0.0197, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.051 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  379000\n",
      "Loss:  -4.220346386632906\n",
      "Loss_orth:  0.000532745948771249\n",
      "Loss_ML:  -4.220879132581677\n",
      "Logits:  tensor([0.0795, 0.4648, 0.0009, 0.0113, 0.2113, 0.0062, 0.0539, 0.1165, 0.0026,\n",
      "        0.0198, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.981 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  380000\n",
      "Loss:  -4.49772953105964\n",
      "Loss_orth:  0.0007065891720207478\n",
      "Loss_ML:  -4.498436120231661\n",
      "Logits:  tensor([0.0806, 0.4627, 0.0009, 0.0112, 0.2128, 0.0059, 0.0532, 0.1170, 0.0027,\n",
      "        0.0196, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.386 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  381000\n",
      "Loss:  -4.13692709393326\n",
      "Loss_orth:  0.0005322890978445501\n",
      "Loss_ML:  -4.137459383031105\n",
      "Logits:  tensor([0.0787, 0.4658, 0.0009, 0.0106, 0.2148, 0.0058, 0.0524, 0.1165, 0.0025,\n",
      "        0.0192, 0.0327], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.166 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  382000\n",
      "Loss:  -4.645704399009647\n",
      "Loss_orth:  0.0009587122153787537\n",
      "Loss_ML:  -4.646663111225026\n",
      "Logits:  tensor([0.0800, 0.4610, 0.0009, 0.0109, 0.2156, 0.0060, 0.0536, 0.1170, 0.0025,\n",
      "        0.0195, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.990 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  383000\n",
      "Loss:  -4.672808761307601\n",
      "Loss_orth:  0.0005465196901912236\n",
      "Loss_ML:  -4.673355280997792\n",
      "Logits:  tensor([0.0792, 0.4626, 0.0009, 0.0112, 0.2141, 0.0062, 0.0532, 0.1173, 0.0025,\n",
      "        0.0193, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.238 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  384000\n",
      "Loss:  -4.160443972375066\n",
      "Loss_orth:  0.0007526686954890766\n",
      "Loss_ML:  -4.161196641070555\n",
      "Logits:  tensor([0.0813, 0.4600, 0.0009, 0.0111, 0.2129, 0.0060, 0.0535, 0.1178, 0.0025,\n",
      "        0.0204, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.053 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  385000\n",
      "Loss:  -4.090352157369775\n",
      "Loss_orth:  0.0004492088490411452\n",
      "Loss_ML:  -4.090801366218816\n",
      "Logits:  tensor([0.0800, 0.4629, 0.0009, 0.0108, 0.2128, 0.0058, 0.0537, 0.1181, 0.0025,\n",
      "        0.0192, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.485 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  386000\n",
      "Loss:  -4.48072900790052\n",
      "Loss_orth:  0.00033780443807661647\n",
      "Loss_ML:  -4.481066812338597\n",
      "Logits:  tensor([0.0791, 0.4607, 0.0009, 0.0109, 0.2144, 0.0060, 0.0536, 0.1180, 0.0026,\n",
      "        0.0201, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.588 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  387000\n",
      "Loss:  -4.493571941399402\n",
      "Loss_orth:  0.0006213806531064119\n",
      "Loss_ML:  -4.494193322052508\n",
      "Logits:  tensor([0.0796, 0.4614, 0.0009, 0.0110, 0.2140, 0.0060, 0.0538, 0.1173, 0.0027,\n",
      "        0.0195, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.709 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  388000\n",
      "Loss:  -4.675743441726724\n",
      "Loss_orth:  0.0007070077076640145\n",
      "Loss_ML:  -4.676450449434388\n",
      "Logits:  tensor([0.0795, 0.4595, 0.0009, 0.0114, 0.2146, 0.0060, 0.0536, 0.1179, 0.0029,\n",
      "        0.0201, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.011 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  389000\n",
      "Loss:  -4.360803523348576\n",
      "Loss_orth:  0.00035644767566237704\n",
      "Loss_ML:  -4.361159971024239\n",
      "Logits:  tensor([0.0794, 0.4634, 0.0010, 0.0109, 0.2134, 0.0061, 0.0530, 0.1168, 0.0029,\n",
      "        0.0197, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.546 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  390000\n",
      "Loss:  -4.3763584555163755\n",
      "Loss_orth:  0.0019451251027905584\n",
      "Loss_ML:  -4.378303580619166\n",
      "Logits:  tensor([0.0798, 0.4606, 0.0010, 0.0112, 0.2136, 0.0062, 0.0539, 0.1165, 0.0030,\n",
      "        0.0201, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.074 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  391000\n",
      "Loss:  -4.204263576431116\n",
      "Loss_orth:  0.00024972381861148804\n",
      "Loss_ML:  -4.204513300249728\n",
      "Logits:  tensor([0.0792, 0.4628, 0.0010, 0.0112, 0.2136, 0.0061, 0.0536, 0.1164, 0.0029,\n",
      "        0.0196, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.706 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  392000\n",
      "Loss:  -4.283510331665076\n",
      "Loss_orth:  0.0004021964768409924\n",
      "Loss_ML:  -4.283912528141918\n",
      "Logits:  tensor([0.0792, 0.4616, 0.0010, 0.0114, 0.2121, 0.0063, 0.0539, 0.1179, 0.0031,\n",
      "        0.0198, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.393 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  393000\n",
      "Loss:  -4.85924487572561\n",
      "Loss_orth:  0.00041559410672409016\n",
      "Loss_ML:  -4.859660469832334\n",
      "Logits:  tensor([0.0795, 0.4631, 0.0010, 0.0114, 0.2123, 0.0063, 0.0531, 0.1174, 0.0030,\n",
      "        0.0195, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.131 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  394000\n",
      "Loss:  -4.6435169284378786\n",
      "Loss_orth:  0.00050332718960588\n",
      "Loss_ML:  -4.644020255627485\n",
      "Logits:  tensor([0.0809, 0.4575, 0.0010, 0.0111, 0.2143, 0.0064, 0.0539, 0.1188, 0.0030,\n",
      "        0.0198, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.244 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  395000\n",
      "Loss:  -4.870650114496586\n",
      "Loss_orth:  0.00029822548563082174\n",
      "Loss_ML:  -4.870948339982217\n",
      "Logits:  tensor([0.0802, 0.4640, 0.0010, 0.0107, 0.2123, 0.0060, 0.0530, 0.1168, 0.0029,\n",
      "        0.0198, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.147 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  396000\n",
      "Loss:  -4.328828487381819\n",
      "Loss_orth:  0.000503540934336124\n",
      "Loss_ML:  -4.329332028316155\n",
      "Logits:  tensor([0.0795, 0.4642, 0.0009, 0.0111, 0.2126, 0.0058, 0.0532, 0.1169, 0.0029,\n",
      "        0.0197, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.894 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  397000\n",
      "Loss:  -4.2228376054172365\n",
      "Loss_orth:  0.0004085216031871541\n",
      "Loss_ML:  -4.223246127020424\n",
      "Logits:  tensor([0.0806, 0.4589, 0.0009, 0.0111, 0.2147, 0.0061, 0.0535, 0.1181, 0.0028,\n",
      "        0.0200, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.414 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  398000\n",
      "Loss:  -4.622397572278323\n",
      "Loss_orth:  0.0006100210080350314\n",
      "Loss_ML:  -4.623007593286358\n",
      "Logits:  tensor([0.0794, 0.4650, 0.0009, 0.0110, 0.2129, 0.0060, 0.0536, 0.1162, 0.0028,\n",
      "        0.0193, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.790 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  399000\n",
      "Loss:  -4.227144722613801\n",
      "Loss_orth:  0.0006809899953730946\n",
      "Loss_ML:  -4.227825712609174\n",
      "Logits:  tensor([0.0796, 0.4622, 0.0009, 0.0112, 0.2135, 0.0061, 0.0540, 0.1166, 0.0027,\n",
      "        0.0197, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.134 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  400000\n",
      "Loss:  -4.456058962977015\n",
      "Loss_orth:  0.0008256636889738981\n",
      "Loss_ML:  -4.456884626665989\n",
      "Logits:  tensor([0.0802, 0.4616, 0.0009, 0.0110, 0.2131, 0.0061, 0.0531, 0.1180, 0.0026,\n",
      "        0.0199, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.918 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  401000\n",
      "Loss:  -4.487181183821517\n",
      "Loss_orth:  0.0006014074232022305\n",
      "Loss_ML:  -4.487782591244719\n",
      "Logits:  tensor([0.0790, 0.4646, 0.0008, 0.0111, 0.2133, 0.0061, 0.0532, 0.1173, 0.0026,\n",
      "        0.0194, 0.0327], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.293 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  402000\n",
      "Loss:  -4.378980364986816\n",
      "Loss_orth:  0.0007476435582549067\n",
      "Loss_ML:  -4.379728008545071\n",
      "Logits:  tensor([0.0788, 0.4626, 0.0009, 0.0113, 0.2152, 0.0062, 0.0528, 0.1167, 0.0027,\n",
      "        0.0196, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.982 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  403000\n",
      "Loss:  -4.466016202287447\n",
      "Loss_orth:  0.000519643949775996\n",
      "Loss_ML:  -4.466535846237223\n",
      "Logits:  tensor([0.0800, 0.4620, 0.0009, 0.0114, 0.2123, 0.0065, 0.0537, 0.1172, 0.0027,\n",
      "        0.0194, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.068 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  404000\n",
      "Loss:  -4.77168472951299\n",
      "Loss_orth:  0.00059961819800048\n",
      "Loss_ML:  -4.772284347710991\n",
      "Logits:  tensor([0.0803, 0.4584, 0.0009, 0.0111, 0.2152, 0.0066, 0.0542, 0.1168, 0.0027,\n",
      "        0.0199, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.356 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  405000\n",
      "Loss:  -4.3572528795871985\n",
      "Loss_orth:  0.00047373573695667643\n",
      "Loss_ML:  -4.357726615324156\n",
      "Logits:  tensor([0.0785, 0.4626, 0.0010, 0.0116, 0.2148, 0.0067, 0.0528, 0.1164, 0.0028,\n",
      "        0.0199, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.993 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  406000\n",
      "Loss:  -4.63444684523262\n",
      "Loss_orth:  0.0008469992580358007\n",
      "Loss_ML:  -4.635293844490656\n",
      "Logits:  tensor([0.0796, 0.4598, 0.0010, 0.0116, 0.2152, 0.0066, 0.0537, 0.1165, 0.0028,\n",
      "        0.0197, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.355 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  407000\n",
      "Loss:  -4.833741097431821\n",
      "Loss_orth:  0.0008139278665741669\n",
      "Loss_ML:  -4.834555025298394\n",
      "Logits:  tensor([0.0806, 0.4634, 0.0010, 0.0114, 0.2120, 0.0064, 0.0536, 0.1158, 0.0028,\n",
      "        0.0196, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.634 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  408000\n",
      "Loss:  -4.455910836755624\n",
      "Loss_orth:  0.00033740042062070023\n",
      "Loss_ML:  -4.456248237176245\n",
      "Logits:  tensor([0.0805, 0.4590, 0.0010, 0.0115, 0.2144, 0.0064, 0.0538, 0.1183, 0.0028,\n",
      "        0.0194, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.155 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  409000\n",
      "Loss:  -4.720041884717361\n",
      "Loss_orth:  0.0003226884373154983\n",
      "Loss_ML:  -4.720364573154677\n",
      "Logits:  tensor([0.0789, 0.4637, 0.0009, 0.0107, 0.2143, 0.0063, 0.0533, 0.1176, 0.0027,\n",
      "        0.0191, 0.0326], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.249 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  410000\n",
      "Loss:  -4.6067118545809125\n",
      "Loss_orth:  0.0005516799832998426\n",
      "Loss_ML:  -4.607263534564212\n",
      "Logits:  tensor([0.0804, 0.4619, 0.0009, 0.0109, 0.2150, 0.0063, 0.0530, 0.1164, 0.0027,\n",
      "        0.0196, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.889 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  411000\n",
      "Loss:  -4.4152603475144145\n",
      "Loss_orth:  0.0004642787012272506\n",
      "Loss_ML:  -4.415724626215642\n",
      "Logits:  tensor([0.0783, 0.4665, 0.0009, 0.0111, 0.2142, 0.0062, 0.0526, 0.1152, 0.0029,\n",
      "        0.0194, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.280 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  412000\n",
      "Loss:  -3.9369408755772692\n",
      "Loss_orth:  0.0006877754919739306\n",
      "Loss_ML:  -3.937628651069243\n",
      "Logits:  tensor([0.0792, 0.4643, 0.0009, 0.0111, 0.2143, 0.0059, 0.0527, 0.1163, 0.0029,\n",
      "        0.0195, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.644 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  413000\n",
      "Loss:  -4.792722841967643\n",
      "Loss_orth:  0.0005972644479480612\n",
      "Loss_ML:  -4.793320106415591\n",
      "Logits:  tensor([0.0787, 0.4641, 0.0009, 0.0114, 0.2141, 0.0062, 0.0533, 0.1156, 0.0030,\n",
      "        0.0194, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.762 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  414000\n",
      "Loss:  -4.38350354246271\n",
      "Loss_orth:  0.0007945989593992988\n",
      "Loss_ML:  -4.384298141422109\n",
      "Logits:  tensor([0.0793, 0.4616, 0.0009, 0.0110, 0.2142, 0.0061, 0.0542, 0.1178, 0.0029,\n",
      "        0.0193, 0.0327], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.876 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  415000\n",
      "Loss:  -4.698058836755515\n",
      "Loss_orth:  0.0003267061752071122\n",
      "Loss_ML:  -4.698385542930723\n",
      "Logits:  tensor([0.0806, 0.4571, 0.0009, 0.0115, 0.2145, 0.0065, 0.0545, 0.1181, 0.0029,\n",
      "        0.0201, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.047 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  416000\n",
      "Loss:  -4.390231810962512\n",
      "Loss_orth:  0.001243940534046448\n",
      "Loss_ML:  -4.391475751496559\n",
      "Logits:  tensor([0.0790, 0.4609, 0.0009, 0.0113, 0.2151, 0.0063, 0.0533, 0.1174, 0.0030,\n",
      "        0.0197, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.303 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  417000\n",
      "Loss:  -4.286793017288533\n",
      "Loss_orth:  0.0009129770728510612\n",
      "Loss_ML:  -4.287705994361383\n",
      "Logits:  tensor([0.0795, 0.4653, 0.0009, 0.0110, 0.2111, 0.0060, 0.0538, 0.1167, 0.0029,\n",
      "        0.0194, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.936 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  418000\n",
      "Loss:  -4.5924967533097565\n",
      "Loss_orth:  0.0002809479223860517\n",
      "Loss_ML:  -4.5927777012321425\n",
      "Logits:  tensor([0.0809, 0.4620, 0.0009, 0.0109, 0.2139, 0.0059, 0.0533, 0.1170, 0.0028,\n",
      "        0.0196, 0.0327], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.518 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  419000\n",
      "Loss:  -4.546618104982723\n",
      "Loss_orth:  0.0002725873212936199\n",
      "Loss_ML:  -4.546890692304016\n",
      "Logits:  tensor([0.0799, 0.4596, 0.0009, 0.0116, 0.2145, 0.0060, 0.0536, 0.1170, 0.0028,\n",
      "        0.0199, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.665 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  420000\n",
      "Loss:  -4.327284945738861\n",
      "Loss_orth:  0.0006840042015392758\n",
      "Loss_ML:  -4.3279689499404\n",
      "Logits:  tensor([0.0798, 0.4612, 0.0009, 0.0113, 0.2136, 0.0061, 0.0543, 0.1168, 0.0029,\n",
      "        0.0196, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.196 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  421000\n",
      "Loss:  -4.542194559439381\n",
      "Loss_orth:  0.0007895231719640125\n",
      "Loss_ML:  -4.542984082611345\n",
      "Logits:  tensor([0.0808, 0.4579, 0.0009, 0.0115, 0.2131, 0.0063, 0.0545, 0.1178, 0.0030,\n",
      "        0.0201, 0.0342], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.114 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  422000\n",
      "Loss:  -4.317825870083089\n",
      "Loss_orth:  0.0005878081607727685\n",
      "Loss_ML:  -4.318413678243862\n",
      "Logits:  tensor([0.0789, 0.4641, 0.0009, 0.0113, 0.2120, 0.0063, 0.0536, 0.1172, 0.0028,\n",
      "        0.0198, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.304 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  423000\n",
      "Loss:  -4.497267433897109\n",
      "Loss_orth:  0.0003998097682856532\n",
      "Loss_ML:  -4.497667243665395\n",
      "Logits:  tensor([0.0800, 0.4632, 0.0009, 0.0116, 0.2123, 0.0065, 0.0533, 0.1167, 0.0028,\n",
      "        0.0194, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.274 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  424000\n",
      "Loss:  -4.660664652760451\n",
      "Loss_orth:  0.0006993812417763792\n",
      "Loss_ML:  -4.6613640340022275\n",
      "Logits:  tensor([0.0797, 0.4592, 0.0009, 0.0114, 0.2144, 0.0062, 0.0536, 0.1196, 0.0029,\n",
      "        0.0191, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.826 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  425000\n",
      "Loss:  -4.585550736075238\n",
      "Loss_orth:  0.0008045226414199854\n",
      "Loss_ML:  -4.586355258716658\n",
      "Logits:  tensor([0.0797, 0.4620, 0.0010, 0.0115, 0.2118, 0.0063, 0.0538, 0.1171, 0.0029,\n",
      "        0.0197, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.993 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  426000\n",
      "Loss:  -4.306331750315546\n",
      "Loss_orth:  0.0007613642762524927\n",
      "Loss_ML:  -4.307093114591798\n",
      "Logits:  tensor([0.0798, 0.4626, 0.0010, 0.0111, 0.2145, 0.0062, 0.0527, 0.1166, 0.0030,\n",
      "        0.0197, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.855 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  427000\n",
      "Loss:  -4.309224163655495\n",
      "Loss_orth:  0.0003554625325324618\n",
      "Loss_ML:  -4.309579626188027\n",
      "Logits:  tensor([0.0793, 0.4614, 0.0009, 0.0113, 0.2148, 0.0060, 0.0528, 0.1175, 0.0029,\n",
      "        0.0198, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 50.484 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  428000\n",
      "Loss:  -4.4481542530038976\n",
      "Loss_orth:  0.0010929953445786653\n",
      "Loss_ML:  -4.449247248348477\n",
      "Logits:  tensor([0.0795, 0.4600, 0.0010, 0.0117, 0.2150, 0.0063, 0.0530, 0.1176, 0.0030,\n",
      "        0.0197, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 50.555 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  429000\n",
      "Loss:  -4.582193431874555\n",
      "Loss_orth:  0.00024337502756581258\n",
      "Loss_ML:  -4.582436806902121\n",
      "Logits:  tensor([0.0793, 0.4622, 0.0010, 0.0113, 0.2132, 0.0063, 0.0538, 0.1168, 0.0029,\n",
      "        0.0192, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.407 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  430000\n",
      "Loss:  -4.529183535099757\n",
      "Loss_orth:  0.000523771669508024\n",
      "Loss_ML:  -4.529707306769265\n",
      "Logits:  tensor([0.0800, 0.4592, 0.0010, 0.0112, 0.2134, 0.0062, 0.0543, 0.1179, 0.0028,\n",
      "        0.0200, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.834 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  431000\n",
      "Loss:  -4.319231251522398\n",
      "Loss_orth:  0.0003772854137648376\n",
      "Loss_ML:  -4.319608536936163\n",
      "Logits:  tensor([0.0779, 0.4639, 0.0010, 0.0109, 0.2148, 0.0062, 0.0532, 0.1171, 0.0029,\n",
      "        0.0191, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.102 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  432000\n",
      "Loss:  -4.303551198576508\n",
      "Loss_orth:  0.0005225441518722804\n",
      "Loss_ML:  -4.30407374272838\n",
      "Logits:  tensor([0.0800, 0.4620, 0.0010, 0.0114, 0.2128, 0.0061, 0.0528, 0.1180, 0.0027,\n",
      "        0.0199, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.142 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  433000\n",
      "Loss:  -4.158445084682611\n",
      "Loss_orth:  0.00034882174047018536\n",
      "Loss_ML:  -4.158793906423081\n",
      "Logits:  tensor([0.0796, 0.4618, 0.0010, 0.0113, 0.2130, 0.0062, 0.0528, 0.1174, 0.0030,\n",
      "        0.0201, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.626 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  434000\n",
      "Loss:  -4.365647794376436\n",
      "Loss_orth:  0.0009437301337102177\n",
      "Loss_ML:  -4.366591524510146\n",
      "Logits:  tensor([0.0802, 0.4600, 0.0009, 0.0114, 0.2151, 0.0061, 0.0537, 0.1176, 0.0029,\n",
      "        0.0191, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.314 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  435000\n",
      "Loss:  -4.5730715235805715\n",
      "Loss_orth:  0.0010132010009263628\n",
      "Loss_ML:  -4.574084724581498\n",
      "Logits:  tensor([0.0781, 0.4638, 0.0010, 0.0111, 0.2142, 0.0063, 0.0525, 0.1165, 0.0029,\n",
      "        0.0198, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.526 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  436000\n",
      "Loss:  -4.750242211727461\n",
      "Loss_orth:  0.0004821457843318047\n",
      "Loss_ML:  -4.7507243575117934\n",
      "Logits:  tensor([0.0796, 0.4579, 0.0010, 0.0114, 0.2153, 0.0064, 0.0537, 0.1172, 0.0031,\n",
      "        0.0202, 0.0343], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.167 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  437000\n",
      "Loss:  -4.243509847887387\n",
      "Loss_orth:  0.00046857246093560885\n",
      "Loss_ML:  -4.243978420348323\n",
      "Logits:  tensor([0.0809, 0.4600, 0.0010, 0.0113, 0.2122, 0.0063, 0.0536, 0.1182, 0.0028,\n",
      "        0.0201, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.231 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  438000\n",
      "Loss:  -4.39080687014595\n",
      "Loss_orth:  0.0005984971440799536\n",
      "Loss_ML:  -4.39140536729003\n",
      "Logits:  tensor([0.0790, 0.4622, 0.0010, 0.0112, 0.2136, 0.0063, 0.0533, 0.1174, 0.0029,\n",
      "        0.0199, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.017 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  439000\n",
      "Loss:  -4.691300115837223\n",
      "Loss_orth:  0.0012802779961260077\n",
      "Loss_ML:  -4.6925803938333495\n",
      "Logits:  tensor([0.0800, 0.4639, 0.0010, 0.0109, 0.2121, 0.0061, 0.0528, 0.1176, 0.0028,\n",
      "        0.0194, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.473 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  440000\n",
      "Loss:  -4.40769480895294\n",
      "Loss_orth:  0.0005393960088814034\n",
      "Loss_ML:  -4.408234204961822\n",
      "Logits:  tensor([0.0797, 0.4612, 0.0010, 0.0113, 0.2134, 0.0063, 0.0535, 0.1178, 0.0028,\n",
      "        0.0202, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.013 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  441000\n",
      "Loss:  -4.433747410214519\n",
      "Loss_orth:  0.0012722045024374622\n",
      "Loss_ML:  -4.435019614716956\n",
      "Logits:  tensor([0.0802, 0.4635, 0.0010, 0.0111, 0.2127, 0.0063, 0.0534, 0.1164, 0.0029,\n",
      "        0.0194, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.863 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  442000\n",
      "Loss:  -4.540411240669519\n",
      "Loss_orth:  0.00047208924210663853\n",
      "Loss_ML:  -4.540883329911625\n",
      "Logits:  tensor([0.0795, 0.4630, 0.0010, 0.0112, 0.2127, 0.0062, 0.0540, 0.1160, 0.0029,\n",
      "        0.0196, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.683 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  443000\n",
      "Loss:  -4.34907586760453\n",
      "Loss_orth:  0.0007487116760667182\n",
      "Loss_ML:  -4.349824579280597\n",
      "Logits:  tensor([0.0801, 0.4617, 0.0010, 0.0114, 0.2143, 0.0061, 0.0531, 0.1165, 0.0029,\n",
      "        0.0198, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.238 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  444000\n",
      "Loss:  -4.405304740729391\n",
      "Loss_orth:  0.0013517388662531876\n",
      "Loss_ML:  -4.406656479595644\n",
      "Logits:  tensor([0.0801, 0.4588, 0.0010, 0.0114, 0.2132, 0.0060, 0.0538, 0.1183, 0.0030,\n",
      "        0.0202, 0.0342], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.967 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  445000\n",
      "Loss:  -4.487078148393922\n",
      "Loss_orth:  0.0004835821893083762\n",
      "Loss_ML:  -4.487561730583231\n",
      "Logits:  tensor([0.0788, 0.4627, 0.0010, 0.0110, 0.2160, 0.0060, 0.0533, 0.1150, 0.0031,\n",
      "        0.0198, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.109 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  446000\n",
      "Loss:  -4.5182458865745625\n",
      "Loss_orth:  0.00036140250872118603\n",
      "Loss_ML:  -4.518607289083284\n",
      "Logits:  tensor([0.0800, 0.4624, 0.0009, 0.0111, 0.2129, 0.0061, 0.0534, 0.1172, 0.0030,\n",
      "        0.0198, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.248 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  447000\n",
      "Loss:  -4.375595080617556\n",
      "Loss_orth:  0.00066737124935968\n",
      "Loss_ML:  -4.376262451866916\n",
      "Logits:  tensor([0.0806, 0.4611, 0.0009, 0.0112, 0.2130, 0.0060, 0.0539, 0.1176, 0.0028,\n",
      "        0.0196, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.344 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  448000\n",
      "Loss:  -4.1989075423068885\n",
      "Loss_orth:  0.0008498618265131978\n",
      "Loss_ML:  -4.199757404133401\n",
      "Logits:  tensor([0.0792, 0.4651, 0.0009, 0.0110, 0.2130, 0.0059, 0.0531, 0.1164, 0.0027,\n",
      "        0.0192, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.799 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  449000\n",
      "Loss:  -4.4850786038947765\n",
      "Loss_orth:  0.0005515873502072425\n",
      "Loss_ML:  -4.485630191244984\n",
      "Logits:  tensor([0.0800, 0.4603, 0.0009, 0.0112, 0.2146, 0.0060, 0.0535, 0.1176, 0.0026,\n",
      "        0.0200, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.581 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  450000\n",
      "Loss:  -4.708393475209083\n",
      "Loss_orth:  0.00048311776514909364\n",
      "Loss_ML:  -4.708876592974232\n",
      "Logits:  tensor([0.0792, 0.4673, 0.0009, 0.0112, 0.2133, 0.0058, 0.0533, 0.1146, 0.0025,\n",
      "        0.0190, 0.0327], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.245 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  451000\n",
      "Loss:  -4.502828635398559\n",
      "Loss_orth:  0.0007396641858641228\n",
      "Loss_ML:  -4.503568299584423\n",
      "Logits:  tensor([0.0794, 0.4632, 0.0009, 0.0109, 0.2146, 0.0059, 0.0533, 0.1163, 0.0025,\n",
      "        0.0195, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.779 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  452000\n",
      "Loss:  -4.035341728674274\n",
      "Loss_orth:  0.0005899452973267142\n",
      "Loss_ML:  -4.0359316739716\n",
      "Logits:  tensor([0.0793, 0.4610, 0.0009, 0.0117, 0.2134, 0.0060, 0.0536, 0.1176, 0.0025,\n",
      "        0.0201, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.866 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  453000\n",
      "Loss:  -4.269359097113668\n",
      "Loss_orth:  0.00044321471259398186\n",
      "Loss_ML:  -4.269802311826262\n",
      "Logits:  tensor([0.0800, 0.4648, 0.0009, 0.0110, 0.2133, 0.0058, 0.0530, 0.1172, 0.0023,\n",
      "        0.0191, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.257 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  454000\n",
      "Loss:  -4.527404982724161\n",
      "Loss_orth:  0.0004671638182249787\n",
      "Loss_ML:  -4.527872146542387\n",
      "Logits:  tensor([0.0801, 0.4615, 0.0009, 0.0116, 0.2134, 0.0062, 0.0533, 0.1170, 0.0026,\n",
      "        0.0196, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.882 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  455000\n",
      "Loss:  -4.206213447102115\n",
      "Loss_orth:  0.0004935131962583742\n",
      "Loss_ML:  -4.206706960298374\n",
      "Logits:  tensor([0.0797, 0.4618, 0.0009, 0.0117, 0.2129, 0.0063, 0.0535, 0.1174, 0.0027,\n",
      "        0.0199, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.883 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  456000\n",
      "Loss:  -4.512860202855538\n",
      "Loss_orth:  0.0007040592896989365\n",
      "Loss_ML:  -4.513564262145237\n",
      "Logits:  tensor([0.0796, 0.4601, 0.0009, 0.0112, 0.2148, 0.0060, 0.0540, 0.1170, 0.0026,\n",
      "        0.0200, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.483 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  457000\n",
      "Loss:  -4.669973004892576\n",
      "Loss_orth:  0.0003836560716185762\n",
      "Loss_ML:  -4.670356660964194\n",
      "Logits:  tensor([0.0794, 0.4622, 0.0009, 0.0112, 0.2148, 0.0062, 0.0536, 0.1165, 0.0027,\n",
      "        0.0193, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.485 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  458000\n",
      "Loss:  -4.304901568805491\n",
      "Loss_orth:  0.00048085965271759285\n",
      "Loss_ML:  -4.305382428458208\n",
      "Logits:  tensor([0.0797, 0.4604, 0.0009, 0.0115, 0.2145, 0.0065, 0.0532, 0.1163, 0.0029,\n",
      "        0.0200, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.047 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  459000\n",
      "Loss:  -4.211997412450772\n",
      "Loss_orth:  0.0003969770408885585\n",
      "Loss_ML:  -4.212394389491661\n",
      "Logits:  tensor([0.0789, 0.4603, 0.0009, 0.0116, 0.2137, 0.0065, 0.0539, 0.1177, 0.0029,\n",
      "        0.0198, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.509 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  460000\n",
      "Loss:  -4.291159112030049\n",
      "Loss_orth:  0.001101710113738374\n",
      "Loss_ML:  -4.2922608221437875\n",
      "Logits:  tensor([0.0799, 0.4580, 0.0009, 0.0115, 0.2142, 0.0065, 0.0539, 0.1170, 0.0032,\n",
      "        0.0205, 0.0344], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.321 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  461000\n",
      "Loss:  -4.790001061977609\n",
      "Loss_orth:  0.0004062572724011386\n",
      "Loss_ML:  -4.7904073192500105\n",
      "Logits:  tensor([0.0797, 0.4609, 0.0009, 0.0117, 0.2122, 0.0064, 0.0535, 0.1182, 0.0033,\n",
      "        0.0200, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.408 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  462000\n",
      "Loss:  -4.239341654361618\n",
      "Loss_orth:  0.0011700629577779506\n",
      "Loss_ML:  -4.240511717319396\n",
      "Logits:  tensor([0.0809, 0.4606, 0.0009, 0.0116, 0.2133, 0.0062, 0.0535, 0.1165, 0.0032,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.180 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  463000\n",
      "Loss:  -4.3368144828856545\n",
      "Loss_orth:  0.00035061527878019156\n",
      "Loss_ML:  -4.3371650981644345\n",
      "Logits:  tensor([0.0799, 0.4628, 0.0009, 0.0112, 0.2122, 0.0062, 0.0536, 0.1175, 0.0031,\n",
      "        0.0195, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.315 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  464000\n",
      "Loss:  -4.477044539594684\n",
      "Loss_orth:  0.0014214188338340541\n",
      "Loss_ML:  -4.478465958428518\n",
      "Logits:  tensor([0.0795, 0.4625, 0.0009, 0.0111, 0.2142, 0.0059, 0.0526, 0.1173, 0.0030,\n",
      "        0.0199, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.316 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  465000\n",
      "Loss:  -4.887868150462405\n",
      "Loss_orth:  0.0006115907036267521\n",
      "Loss_ML:  -4.888479741166032\n",
      "Logits:  tensor([0.0790, 0.4632, 0.0008, 0.0110, 0.2160, 0.0057, 0.0521, 0.1168, 0.0029,\n",
      "        0.0194, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.852 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  466000\n",
      "Loss:  -4.288972660651531\n",
      "Loss_orth:  0.0004380372021397415\n",
      "Loss_ML:  -4.289410697853671\n",
      "Logits:  tensor([0.0792, 0.4615, 0.0008, 0.0114, 0.2132, 0.0062, 0.0538, 0.1176, 0.0029,\n",
      "        0.0201, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.169 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  467000\n",
      "Loss:  -4.024900587735366\n",
      "Loss_orth:  0.001063717569311264\n",
      "Loss_ML:  -4.025964305304677\n",
      "Logits:  tensor([0.0807, 0.4601, 0.0009, 0.0114, 0.2124, 0.0062, 0.0541, 0.1177, 0.0030,\n",
      "        0.0198, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.288 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  468000\n",
      "Loss:  -4.258974027094588\n",
      "Loss_orth:  0.0004720018525064591\n",
      "Loss_ML:  -4.259446028947095\n",
      "Logits:  tensor([0.0793, 0.4634, 0.0009, 0.0109, 0.2128, 0.0061, 0.0535, 0.1169, 0.0029,\n",
      "        0.0195, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.761 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  469000\n",
      "Loss:  -4.42010711347439\n",
      "Loss_orth:  0.0005111378460452271\n",
      "Loss_ML:  -4.420618251320435\n",
      "Logits:  tensor([0.0807, 0.4599, 0.0009, 0.0116, 0.2134, 0.0060, 0.0535, 0.1177, 0.0029,\n",
      "        0.0199, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.102 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  470000\n",
      "Loss:  -4.6297255327228495\n",
      "Loss_orth:  0.0004754915423613271\n",
      "Loss_ML:  -4.630201024265211\n",
      "Logits:  tensor([0.0804, 0.4601, 0.0009, 0.0112, 0.2134, 0.0060, 0.0543, 0.1170, 0.0029,\n",
      "        0.0200, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.133 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  471000\n",
      "Loss:  -4.448597579801532\n",
      "Loss_orth:  0.0006228565398507897\n",
      "Loss_ML:  -4.449220436341382\n",
      "Logits:  tensor([0.0794, 0.4622, 0.0009, 0.0110, 0.2155, 0.0059, 0.0533, 0.1165, 0.0028,\n",
      "        0.0196, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.379 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  472000\n",
      "Loss:  -4.308517825916666\n",
      "Loss_orth:  0.0006173325502112557\n",
      "Loss_ML:  -4.309135158466877\n",
      "Logits:  tensor([0.0801, 0.4613, 0.0009, 0.0111, 0.2135, 0.0059, 0.0537, 0.1166, 0.0028,\n",
      "        0.0197, 0.0345], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.006 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  473000\n",
      "Loss:  -4.161497259823631\n",
      "Loss_orth:  0.0015552333590389063\n",
      "Loss_ML:  -4.163052493182669\n",
      "Logits:  tensor([0.0806, 0.4631, 0.0009, 0.0112, 0.2121, 0.0061, 0.0531, 0.1168, 0.0029,\n",
      "        0.0198, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.838 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  474000\n",
      "Loss:  -4.3174841930589665\n",
      "Loss_orth:  0.0007084723039349923\n",
      "Loss_ML:  -4.3181926653629015\n",
      "Logits:  tensor([0.0791, 0.4635, 0.0009, 0.0111, 0.2138, 0.0060, 0.0535, 0.1164, 0.0029,\n",
      "        0.0196, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.227 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  475000\n",
      "Loss:  -4.357309724125719\n",
      "Loss_orth:  0.00023246556246815417\n",
      "Loss_ML:  -4.357542189688187\n",
      "Logits:  tensor([0.0800, 0.4611, 0.0009, 0.0112, 0.2142, 0.0061, 0.0538, 0.1173, 0.0029,\n",
      "        0.0192, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.125 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  476000\n",
      "Loss:  -4.412356458030909\n",
      "Loss_orth:  0.0006914178347425515\n",
      "Loss_ML:  -4.413047875865652\n",
      "Logits:  tensor([0.0805, 0.4628, 0.0009, 0.0112, 0.2125, 0.0061, 0.0535, 0.1163, 0.0029,\n",
      "        0.0196, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.988 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  477000\n",
      "Loss:  -4.361564478787897\n",
      "Loss_orth:  0.0005436010802262724\n",
      "Loss_ML:  -4.362108079868123\n",
      "Logits:  tensor([0.0793, 0.4630, 0.0009, 0.0111, 0.2138, 0.0061, 0.0534, 0.1169, 0.0029,\n",
      "        0.0195, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.302 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  478000\n",
      "Loss:  -4.504385430846148\n",
      "Loss_orth:  0.0005616474947184154\n",
      "Loss_ML:  -4.504947078340867\n",
      "Logits:  tensor([0.0799, 0.4610, 0.0009, 0.0112, 0.2135, 0.0062, 0.0531, 0.1184, 0.0030,\n",
      "        0.0196, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.953 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  479000\n",
      "Loss:  -4.552429765778464\n",
      "Loss_orth:  0.0005019185078776806\n",
      "Loss_ML:  -4.552931684286341\n",
      "Logits:  tensor([0.0799, 0.4631, 0.0010, 0.0115, 0.2108, 0.0064, 0.0540, 0.1175, 0.0031,\n",
      "        0.0197, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.364 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  480000\n",
      "Loss:  -4.452857306932664\n",
      "Loss_orth:  0.00068042384613447\n",
      "Loss_ML:  -4.453537730778798\n",
      "Logits:  tensor([0.0785, 0.4647, 0.0010, 0.0112, 0.2129, 0.0066, 0.0531, 0.1156, 0.0031,\n",
      "        0.0198, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.460 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  481000\n",
      "Loss:  -4.349973349555157\n",
      "Loss_orth:  0.0004440069458825992\n",
      "Loss_ML:  -4.35041735650104\n",
      "Logits:  tensor([0.0799, 0.4623, 0.0010, 0.0112, 0.2123, 0.0064, 0.0540, 0.1158, 0.0031,\n",
      "        0.0200, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.204 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  482000\n",
      "Loss:  -4.517082218724376\n",
      "Loss_orth:  0.0002822198363883655\n",
      "Loss_ML:  -4.517364438560764\n",
      "Logits:  tensor([0.0799, 0.4593, 0.0010, 0.0114, 0.2152, 0.0063, 0.0537, 0.1165, 0.0030,\n",
      "        0.0200, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.130 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  483000\n",
      "Loss:  -4.7945815132604555\n",
      "Loss_orth:  0.0005067870386815109\n",
      "Loss_ML:  -4.795088300299137\n",
      "Logits:  tensor([0.0806, 0.4593, 0.0010, 0.0114, 0.2124, 0.0062, 0.0545, 0.1177, 0.0029,\n",
      "        0.0199, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.933 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  484000\n",
      "Loss:  -4.852914978954708\n",
      "Loss_orth:  0.0008717706508041864\n",
      "Loss_ML:  -4.853786749605512\n",
      "Logits:  tensor([0.0810, 0.4609, 0.0010, 0.0112, 0.2133, 0.0061, 0.0533, 0.1173, 0.0029,\n",
      "        0.0197, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.577 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  485000\n",
      "Loss:  -4.488312196706673\n",
      "Loss_orth:  0.0004762712086357038\n",
      "Loss_ML:  -4.488788467915309\n",
      "Logits:  tensor([0.0787, 0.4620, 0.0010, 0.0116, 0.2153, 0.0063, 0.0527, 0.1164, 0.0028,\n",
      "        0.0198, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.817 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  486000\n",
      "Loss:  -4.6932536794743385\n",
      "Loss_orth:  0.0007527744162875333\n",
      "Loss_ML:  -4.694006453890626\n",
      "Logits:  tensor([0.0804, 0.4624, 0.0010, 0.0117, 0.2114, 0.0062, 0.0533, 0.1176, 0.0028,\n",
      "        0.0197, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.260 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  487000\n",
      "Loss:  -4.616043245370755\n",
      "Loss_orth:  0.0007463969538560156\n",
      "Loss_ML:  -4.616789642324611\n",
      "Logits:  tensor([0.0799, 0.4615, 0.0010, 0.0114, 0.2132, 0.0062, 0.0538, 0.1168, 0.0029,\n",
      "        0.0196, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.796 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  488000\n",
      "Loss:  -4.634107148438888\n",
      "Loss_orth:  0.0005563803185518659\n",
      "Loss_ML:  -4.63466352875744\n",
      "Logits:  tensor([0.0797, 0.4635, 0.0010, 0.0113, 0.2120, 0.0060, 0.0530, 0.1169, 0.0028,\n",
      "        0.0197, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.377 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  489000\n",
      "Loss:  -4.657708289985562\n",
      "Loss_orth:  0.0006910297954753088\n",
      "Loss_ML:  -4.658399319781037\n",
      "Logits:  tensor([0.0799, 0.4616, 0.0011, 0.0110, 0.2155, 0.0062, 0.0526, 0.1168, 0.0029,\n",
      "        0.0191, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.379 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  490000\n",
      "Loss:  -4.230005661623475\n",
      "Loss_orth:  0.0006563555528143963\n",
      "Loss_ML:  -4.230662017176289\n",
      "Logits:  tensor([0.0784, 0.4651, 0.0010, 0.0106, 0.2146, 0.0057, 0.0531, 0.1163, 0.0027,\n",
      "        0.0192, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.877 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  491000\n",
      "Loss:  -4.172756403560292\n",
      "Loss_orth:  0.0003850305396217354\n",
      "Loss_ML:  -4.1731414340999144\n",
      "Logits:  tensor([0.0804, 0.4588, 0.0010, 0.0115, 0.2130, 0.0059, 0.0545, 0.1182, 0.0028,\n",
      "        0.0196, 0.0344], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.602 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  492000\n",
      "Loss:  -4.2456445532685185\n",
      "Loss_orth:  0.0006422237910761058\n",
      "Loss_ML:  -4.246286777059595\n",
      "Logits:  tensor([0.0797, 0.4649, 0.0009, 0.0110, 0.2126, 0.0058, 0.0529, 0.1167, 0.0029,\n",
      "        0.0196, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.971 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  493000\n",
      "Loss:  -4.741069502567553\n",
      "Loss_orth:  0.0004222268558717057\n",
      "Loss_ML:  -4.741491729423425\n",
      "Logits:  tensor([0.0804, 0.4573, 0.0009, 0.0110, 0.2154, 0.0058, 0.0545, 0.1189, 0.0029,\n",
      "        0.0195, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.282 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  494000\n",
      "Loss:  -4.51819014514542\n",
      "Loss_orth:  0.000878569779815335\n",
      "Loss_ML:  -4.519068714925235\n",
      "Logits:  tensor([0.0799, 0.4608, 0.0009, 0.0114, 0.2130, 0.0058, 0.0537, 0.1180, 0.0030,\n",
      "        0.0201, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.984 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  495000\n",
      "Loss:  -4.254976725153137\n",
      "Loss_orth:  0.0010362061487841263\n",
      "Loss_ML:  -4.256012931301921\n",
      "Logits:  tensor([0.0797, 0.4585, 0.0009, 0.0114, 0.2145, 0.0061, 0.0538, 0.1185, 0.0030,\n",
      "        0.0199, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.849 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  496000\n",
      "Loss:  -4.3849936924876785\n",
      "Loss_orth:  0.0007165465632454677\n",
      "Loss_ML:  -4.3857102390509235\n",
      "Logits:  tensor([0.0791, 0.4620, 0.0010, 0.0112, 0.2141, 0.0061, 0.0533, 0.1169, 0.0029,\n",
      "        0.0200, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.365 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  497000\n",
      "Loss:  -4.585616828318619\n",
      "Loss_orth:  0.0014685085225609024\n",
      "Loss_ML:  -4.58708533684118\n",
      "Logits:  tensor([0.0800, 0.4622, 0.0010, 0.0114, 0.2123, 0.0063, 0.0531, 0.1174, 0.0030,\n",
      "        0.0201, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.138 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  498000\n",
      "Loss:  -4.492092527019496\n",
      "Loss_orth:  0.0006686135788594802\n",
      "Loss_ML:  -4.492761140598356\n",
      "Logits:  tensor([0.0797, 0.4626, 0.0009, 0.0109, 0.2134, 0.0059, 0.0540, 0.1170, 0.0030,\n",
      "        0.0193, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.750 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  499000\n",
      "Loss:  -4.460701610105607\n",
      "Loss_orth:  0.0004292133908585899\n",
      "Loss_ML:  -4.4611308234964655\n",
      "Logits:  tensor([0.0802, 0.4625, 0.0010, 0.0112, 0.2120, 0.0060, 0.0539, 0.1171, 0.0029,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.071 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  500000\n",
      "Loss:  -4.233132543360589\n",
      "Loss_orth:  0.000775879248743077\n",
      "Loss_ML:  -4.233908422609332\n",
      "Logits:  tensor([0.0802, 0.4594, 0.0009, 0.0112, 0.2149, 0.0060, 0.0537, 0.1180, 0.0028,\n",
      "        0.0197, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.758 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  501000\n",
      "Loss:  -4.3900319532527865\n",
      "Loss_orth:  0.0009970561205095419\n",
      "Loss_ML:  -4.391029009373296\n",
      "Logits:  tensor([0.0796, 0.4594, 0.0009, 0.0111, 0.2146, 0.0060, 0.0537, 0.1186, 0.0028,\n",
      "        0.0196, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.193 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  502000\n",
      "Loss:  -4.299992781237234\n",
      "Loss_orth:  0.00048180257606429065\n",
      "Loss_ML:  -4.300474583813298\n",
      "Logits:  tensor([0.0798, 0.4610, 0.0009, 0.0113, 0.2154, 0.0061, 0.0532, 0.1169, 0.0028,\n",
      "        0.0195, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.847 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  503000\n",
      "Loss:  -4.072508707584846\n",
      "Loss_orth:  0.0008965107937774742\n",
      "Loss_ML:  -4.073405218378623\n",
      "Logits:  tensor([0.0794, 0.4614, 0.0009, 0.0113, 0.2131, 0.0062, 0.0538, 0.1173, 0.0030,\n",
      "        0.0196, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.323 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  504000\n",
      "Loss:  -4.813238702722483\n",
      "Loss_orth:  0.0002199884968827855\n",
      "Loss_ML:  -4.813458691219366\n",
      "Logits:  tensor([0.0803, 0.4607, 0.0009, 0.0113, 0.2138, 0.0065, 0.0535, 0.1171, 0.0030,\n",
      "        0.0194, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.568 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  505000\n",
      "Loss:  -4.522777282091152\n",
      "Loss_orth:  0.0006090081350214284\n",
      "Loss_ML:  -4.523386290226173\n",
      "Logits:  tensor([0.0795, 0.4575, 0.0009, 0.0113, 0.2159, 0.0066, 0.0540, 0.1168, 0.0033,\n",
      "        0.0201, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.057 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  506000\n",
      "Loss:  -4.409272292737857\n",
      "Loss_orth:  0.0006965643576459803\n",
      "Loss_ML:  -4.409968857095503\n",
      "Logits:  tensor([0.0791, 0.4635, 0.0009, 0.0113, 0.2123, 0.0062, 0.0537, 0.1167, 0.0031,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.541 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  507000\n",
      "Loss:  -4.612256053522421\n",
      "Loss_orth:  0.000783908559618413\n",
      "Loss_ML:  -4.6130399620820395\n",
      "Logits:  tensor([0.0800, 0.4591, 0.0009, 0.0116, 0.2139, 0.0063, 0.0538, 0.1178, 0.0031,\n",
      "        0.0197, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.125 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  508000\n",
      "Loss:  -4.532426374183034\n",
      "Loss_orth:  0.001650554615245848\n",
      "Loss_ML:  -4.53407692879828\n",
      "Logits:  tensor([0.0795, 0.4604, 0.0009, 0.0112, 0.2151, 0.0062, 0.0530, 0.1170, 0.0032,\n",
      "        0.0197, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.490 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  509000\n",
      "Loss:  -4.325461263464268\n",
      "Loss_orth:  0.0004266131027881183\n",
      "Loss_ML:  -4.325887876567056\n",
      "Logits:  tensor([0.0807, 0.4632, 0.0010, 0.0112, 0.2116, 0.0062, 0.0531, 0.1167, 0.0032,\n",
      "        0.0194, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.999 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  510000\n",
      "Loss:  -4.614351927894152\n",
      "Loss_orth:  0.0003913679211318661\n",
      "Loss_ML:  -4.614743295815284\n",
      "Logits:  tensor([0.0802, 0.4639, 0.0010, 0.0109, 0.2143, 0.0059, 0.0527, 0.1161, 0.0031,\n",
      "        0.0193, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.126 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  511000\n",
      "Loss:  -4.4813491578327485\n",
      "Loss_orth:  0.00029221285379919093\n",
      "Loss_ML:  -4.481641370686548\n",
      "Logits:  tensor([0.0792, 0.4637, 0.0009, 0.0108, 0.2140, 0.0057, 0.0533, 0.1167, 0.0030,\n",
      "        0.0198, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.930 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  512000\n",
      "Loss:  -4.392583512374362\n",
      "Loss_orth:  0.0004897054297672976\n",
      "Loss_ML:  -4.393073217804129\n",
      "Logits:  tensor([0.0803, 0.4602, 0.0009, 0.0110, 0.2151, 0.0059, 0.0539, 0.1165, 0.0029,\n",
      "        0.0196, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.533 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  513000\n",
      "Loss:  -4.321922159660349\n",
      "Loss_orth:  0.0005179197214199931\n",
      "Loss_ML:  -4.322440079381769\n",
      "Logits:  tensor([0.0800, 0.4614, 0.0009, 0.0114, 0.2136, 0.0062, 0.0530, 0.1179, 0.0028,\n",
      "        0.0197, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.553 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  514000\n",
      "Loss:  -4.365593505797578\n",
      "Loss_orth:  0.00025976286098505373\n",
      "Loss_ML:  -4.3658532686585625\n",
      "Logits:  tensor([0.0796, 0.4641, 0.0009, 0.0112, 0.2134, 0.0062, 0.0531, 0.1164, 0.0026,\n",
      "        0.0194, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.811 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  515000\n",
      "Loss:  -4.450750902080869\n",
      "Loss_orth:  0.0004225125054817958\n",
      "Loss_ML:  -4.451173414586351\n",
      "Logits:  tensor([0.0796, 0.4612, 0.0010, 0.0117, 0.2125, 0.0063, 0.0541, 0.1171, 0.0027,\n",
      "        0.0200, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.065 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  516000\n",
      "Loss:  -4.6333329385611135\n",
      "Loss_orth:  0.0008165504860211931\n",
      "Loss_ML:  -4.634149489047135\n",
      "Logits:  tensor([0.0804, 0.4619, 0.0011, 0.0115, 0.2130, 0.0061, 0.0537, 0.1170, 0.0028,\n",
      "        0.0199, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.370 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  517000\n",
      "Loss:  -4.464445988209238\n",
      "Loss_orth:  0.00038061290600437147\n",
      "Loss_ML:  -4.464826601115242\n",
      "Logits:  tensor([0.0807, 0.4615, 0.0011, 0.0115, 0.2126, 0.0063, 0.0537, 0.1168, 0.0030,\n",
      "        0.0195, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.375 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  518000\n",
      "Loss:  -4.265965627154645\n",
      "Loss_orth:  0.0015477529194949547\n",
      "Loss_ML:  -4.26751338007414\n",
      "Logits:  tensor([0.0798, 0.4619, 0.0011, 0.0113, 0.2139, 0.0061, 0.0534, 0.1163, 0.0032,\n",
      "        0.0197, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.105 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  519000\n",
      "Loss:  -4.564864242977404\n",
      "Loss_orth:  0.00048655402972591806\n",
      "Loss_ML:  -4.565350797007129\n",
      "Logits:  tensor([0.0796, 0.4635, 0.0011, 0.0111, 0.2127, 0.0062, 0.0530, 0.1169, 0.0031,\n",
      "        0.0194, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.141 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  520000\n",
      "Loss:  -4.3998364274519774\n",
      "Loss_orth:  0.0003670538126555172\n",
      "Loss_ML:  -4.400203481264633\n",
      "Logits:  tensor([0.0801, 0.4613, 0.0011, 0.0113, 0.2118, 0.0061, 0.0544, 0.1174, 0.0031,\n",
      "        0.0198, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.934 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  521000\n",
      "Loss:  -4.4986420278222745\n",
      "Loss_orth:  0.0006395959234810977\n",
      "Loss_ML:  -4.499281623745755\n",
      "Logits:  tensor([0.0800, 0.4626, 0.0011, 0.0112, 0.2119, 0.0059, 0.0539, 0.1168, 0.0032,\n",
      "        0.0196, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.258 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  522000\n",
      "Loss:  -4.541838560004665\n",
      "Loss_orth:  0.0009691793977300527\n",
      "Loss_ML:  -4.542807739402395\n",
      "Logits:  tensor([0.0800, 0.4618, 0.0011, 0.0112, 0.2130, 0.0060, 0.0530, 0.1173, 0.0030,\n",
      "        0.0200, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.481 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  523000\n",
      "Loss:  -4.370986929092231\n",
      "Loss_orth:  0.00036575276167773873\n",
      "Loss_ML:  -4.371352681853908\n",
      "Logits:  tensor([0.0784, 0.4611, 0.0011, 0.0115, 0.2139, 0.0062, 0.0539, 0.1176, 0.0032,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.822 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  524000\n",
      "Loss:  -4.399139504014048\n",
      "Loss_orth:  0.0006672559988990686\n",
      "Loss_ML:  -4.399806760012948\n",
      "Logits:  tensor([0.0796, 0.4594, 0.0011, 0.0113, 0.2152, 0.0064, 0.0538, 0.1172, 0.0031,\n",
      "        0.0199, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.135 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  525000\n",
      "Loss:  -4.36403071480341\n",
      "Loss_orth:  0.0008137422694704108\n",
      "Loss_ML:  -4.364844457072881\n",
      "Logits:  tensor([0.0806, 0.4607, 0.0011, 0.0113, 0.2109, 0.0063, 0.0541, 0.1183, 0.0032,\n",
      "        0.0201, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.803 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  526000\n",
      "Loss:  -4.340071005623122\n",
      "Loss_orth:  0.00033314526716488\n",
      "Loss_ML:  -4.340404150890287\n",
      "Logits:  tensor([0.0796, 0.4597, 0.0011, 0.0113, 0.2149, 0.0061, 0.0532, 0.1176, 0.0030,\n",
      "        0.0197, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.833 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  527000\n",
      "Loss:  -4.4539265833406425\n",
      "Loss_orth:  0.0003361468366287846\n",
      "Loss_ML:  -4.4542627301772715\n",
      "Logits:  tensor([0.0802, 0.4620, 0.0011, 0.0112, 0.2135, 0.0059, 0.0530, 0.1175, 0.0029,\n",
      "        0.0195, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.755 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  528000\n",
      "Loss:  -4.279137377333617\n",
      "Loss_orth:  0.0005445257725645679\n",
      "Loss_ML:  -4.279681903106182\n",
      "Logits:  tensor([0.0796, 0.4612, 0.0011, 0.0111, 0.2150, 0.0060, 0.0532, 0.1179, 0.0029,\n",
      "        0.0192, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.654 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  529000\n",
      "Loss:  -4.6215503701373795\n",
      "Loss_orth:  0.0006173665355921454\n",
      "Loss_ML:  -4.622167736672972\n",
      "Logits:  tensor([0.0805, 0.4627, 0.0011, 0.0112, 0.2124, 0.0061, 0.0538, 0.1168, 0.0029,\n",
      "        0.0194, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.049 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  530000\n",
      "Loss:  -4.6704639601023\n",
      "Loss_orth:  0.0009755089634457914\n",
      "Loss_ML:  -4.671439469065746\n",
      "Logits:  tensor([0.0792, 0.4636, 0.0011, 0.0114, 0.2112, 0.0063, 0.0535, 0.1176, 0.0030,\n",
      "        0.0200, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.676 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  531000\n",
      "Loss:  -4.491420699681132\n",
      "Loss_orth:  0.00029942664075283956\n",
      "Loss_ML:  -4.491720126321885\n",
      "Logits:  tensor([0.0805, 0.4578, 0.0012, 0.0113, 0.2132, 0.0064, 0.0540, 0.1181, 0.0031,\n",
      "        0.0201, 0.0344], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.473 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  532000\n",
      "Loss:  -4.690246064813948\n",
      "Loss_orth:  0.00030996313376065366\n",
      "Loss_ML:  -4.690556027947709\n",
      "Logits:  tensor([0.0799, 0.4617, 0.0011, 0.0112, 0.2143, 0.0063, 0.0530, 0.1165, 0.0031,\n",
      "        0.0195, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.418 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  533000\n",
      "Loss:  -4.393965509315281\n",
      "Loss_orth:  0.0006756019116909635\n",
      "Loss_ML:  -4.3946411112269725\n",
      "Logits:  tensor([0.0804, 0.4617, 0.0012, 0.0113, 0.2134, 0.0061, 0.0539, 0.1160, 0.0031,\n",
      "        0.0197, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.898 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  534000\n",
      "Loss:  -4.136592051245212\n",
      "Loss_orth:  0.0007498547073834723\n",
      "Loss_ML:  -4.137341905952596\n",
      "Logits:  tensor([0.0803, 0.4621, 0.0011, 0.0112, 0.2134, 0.0060, 0.0530, 0.1182, 0.0030,\n",
      "        0.0193, 0.0324], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.577 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  535000\n",
      "Loss:  -4.1065100086273185\n",
      "Loss_orth:  0.00042182354431093827\n",
      "Loss_ML:  -4.10693183217163\n",
      "Logits:  tensor([0.0806, 0.4603, 0.0011, 0.0113, 0.2139, 0.0062, 0.0538, 0.1171, 0.0029,\n",
      "        0.0198, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.244 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  536000\n",
      "Loss:  -4.295633693387397\n",
      "Loss_orth:  0.0005321796192489731\n",
      "Loss_ML:  -4.296165873006646\n",
      "Logits:  tensor([0.0791, 0.4638, 0.0012, 0.0115, 0.2128, 0.0061, 0.0526, 0.1174, 0.0030,\n",
      "        0.0200, 0.0326], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.186 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  537000\n",
      "Loss:  -4.649592395565179\n",
      "Loss_orth:  0.00036956885639205576\n",
      "Loss_ML:  -4.649961964421571\n",
      "Logits:  tensor([0.0792, 0.4620, 0.0012, 0.0115, 0.2133, 0.0062, 0.0534, 0.1165, 0.0029,\n",
      "        0.0200, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.909 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  538000\n",
      "Loss:  -4.314347930304855\n",
      "Loss_orth:  0.00046447349096234654\n",
      "Loss_ML:  -4.314812403795817\n",
      "Logits:  tensor([0.0789, 0.4616, 0.0012, 0.0114, 0.2148, 0.0060, 0.0531, 0.1162, 0.0028,\n",
      "        0.0201, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.018 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  539000\n",
      "Loss:  -4.461285293653849\n",
      "Loss_orth:  0.00065808344035428\n",
      "Loss_ML:  -4.461943377094204\n",
      "Logits:  tensor([0.0797, 0.4582, 0.0012, 0.0116, 0.2143, 0.0059, 0.0533, 0.1195, 0.0028,\n",
      "        0.0200, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.559 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  540000\n",
      "Loss:  -4.630417249858938\n",
      "Loss_orth:  0.00044335408586527883\n",
      "Loss_ML:  -4.630860603944804\n",
      "Logits:  tensor([0.0805, 0.4617, 0.0012, 0.0110, 0.2131, 0.0057, 0.0530, 0.1175, 0.0029,\n",
      "        0.0199, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.052 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  541000\n",
      "Loss:  -4.505993161853928\n",
      "Loss_orth:  0.0004587636896526038\n",
      "Loss_ML:  -4.506451925543581\n",
      "Logits:  tensor([0.0785, 0.4653, 0.0012, 0.0112, 0.2117, 0.0062, 0.0531, 0.1164, 0.0031,\n",
      "        0.0200, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.753 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  542000\n",
      "Loss:  -4.261497090561695\n",
      "Loss_orth:  0.0007115264917647071\n",
      "Loss_ML:  -4.26220861705346\n",
      "Logits:  tensor([0.0792, 0.4613, 0.0012, 0.0112, 0.2145, 0.0062, 0.0535, 0.1163, 0.0030,\n",
      "        0.0198, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.799 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  543000\n",
      "Loss:  -4.331162578515856\n",
      "Loss_orth:  0.00040832989489721945\n",
      "Loss_ML:  -4.331570908410753\n",
      "Logits:  tensor([0.0804, 0.4553, 0.0012, 0.0119, 0.2128, 0.0065, 0.0551, 0.1181, 0.0032,\n",
      "        0.0206, 0.0348], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.860 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  544000\n",
      "Loss:  -4.363235401019018\n",
      "Loss_orth:  0.000669994321649112\n",
      "Loss_ML:  -4.363905395340668\n",
      "Logits:  tensor([0.0796, 0.4666, 0.0012, 0.0113, 0.2118, 0.0059, 0.0522, 0.1171, 0.0029,\n",
      "        0.0188, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.117 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  545000\n",
      "Loss:  -4.3465358652292005\n",
      "Loss_orth:  0.0007141481142418835\n",
      "Loss_ML:  -4.347250013343443\n",
      "Logits:  tensor([0.0799, 0.4603, 0.0013, 0.0120, 0.2129, 0.0065, 0.0539, 0.1167, 0.0030,\n",
      "        0.0201, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.496 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  546000\n",
      "Loss:  -4.3320780808172605\n",
      "Loss_orth:  0.00048143793993539545\n",
      "Loss_ML:  -4.332559518757196\n",
      "Logits:  tensor([0.0791, 0.4646, 0.0013, 0.0113, 0.2129, 0.0065, 0.0525, 0.1167, 0.0029,\n",
      "        0.0192, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.322 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  547000\n",
      "Loss:  -4.777740266463501\n",
      "Loss_orth:  0.0004856492031223845\n",
      "Loss_ML:  -4.778225915666623\n",
      "Logits:  tensor([0.0801, 0.4605, 0.0013, 0.0113, 0.2124, 0.0063, 0.0545, 0.1169, 0.0030,\n",
      "        0.0199, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.602 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  548000\n",
      "Loss:  -4.3325800404344035\n",
      "Loss_orth:  0.0006737315726298753\n",
      "Loss_ML:  -4.333253772007033\n",
      "Logits:  tensor([0.0805, 0.4601, 0.0013, 0.0116, 0.2128, 0.0060, 0.0542, 0.1173, 0.0030,\n",
      "        0.0195, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.486 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  549000\n",
      "Loss:  -4.3941049290538325\n",
      "Loss_orth:  0.0003904678823723081\n",
      "Loss_ML:  -4.394495396936205\n",
      "Logits:  tensor([0.0797, 0.4581, 0.0013, 0.0117, 0.2126, 0.0064, 0.0543, 0.1186, 0.0031,\n",
      "        0.0199, 0.0342], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.372 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  550000\n",
      "Loss:  -4.679926695155141\n",
      "Loss_orth:  0.0004197998450828902\n",
      "Loss_ML:  -4.680346495000223\n",
      "Logits:  tensor([0.0802, 0.4621, 0.0012, 0.0111, 0.2133, 0.0064, 0.0529, 0.1170, 0.0031,\n",
      "        0.0194, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.104 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  551000\n",
      "Loss:  -4.25597785534745\n",
      "Loss_orth:  0.0004058329631177855\n",
      "Loss_ML:  -4.256383688310568\n",
      "Logits:  tensor([0.0791, 0.4617, 0.0012, 0.0110, 0.2140, 0.0063, 0.0536, 0.1174, 0.0028,\n",
      "        0.0196, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.196 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  552000\n",
      "Loss:  -4.237259588588135\n",
      "Loss_orth:  0.000407919640220077\n",
      "Loss_ML:  -4.237667508228355\n",
      "Logits:  tensor([0.0789, 0.4639, 0.0012, 0.0110, 0.2127, 0.0062, 0.0535, 0.1168, 0.0029,\n",
      "        0.0198, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.590 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  553000\n",
      "Loss:  -4.159753162477426\n",
      "Loss_orth:  0.0005073214789115149\n",
      "Loss_ML:  -4.160260483956338\n",
      "Logits:  tensor([0.0797, 0.4628, 0.0011, 0.0109, 0.2127, 0.0060, 0.0533, 0.1175, 0.0029,\n",
      "        0.0196, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.183 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  554000\n",
      "Loss:  -4.560847311829373\n",
      "Loss_orth:  0.0005123541555595334\n",
      "Loss_ML:  -4.5613596659849325\n",
      "Logits:  tensor([0.0793, 0.4610, 0.0011, 0.0111, 0.2137, 0.0061, 0.0550, 0.1163, 0.0030,\n",
      "        0.0198, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.663 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  555000\n",
      "Loss:  -4.580209429821907\n",
      "Loss_orth:  0.0005490082424243977\n",
      "Loss_ML:  -4.580758438064331\n",
      "Logits:  tensor([0.0801, 0.4606, 0.0011, 0.0112, 0.2128, 0.0062, 0.0539, 0.1169, 0.0030,\n",
      "        0.0203, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.895 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  556000\n",
      "Loss:  -4.332708858283967\n",
      "Loss_orth:  0.0012160563010781232\n",
      "Loss_ML:  -4.333924914585045\n",
      "Logits:  tensor([0.0784, 0.4663, 0.0011, 0.0114, 0.2143, 0.0062, 0.0525, 0.1154, 0.0029,\n",
      "        0.0193, 0.0322], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.908 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  557000\n",
      "Loss:  -4.410316420605269\n",
      "Loss_orth:  0.0004820472244072927\n",
      "Loss_ML:  -4.410798467829676\n",
      "Logits:  tensor([0.0798, 0.4601, 0.0011, 0.0118, 0.2132, 0.0060, 0.0533, 0.1184, 0.0031,\n",
      "        0.0200, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.086 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  558000\n",
      "Loss:  -4.261570709957632\n",
      "Loss_orth:  0.0008790295014964332\n",
      "Loss_ML:  -4.262449739459129\n",
      "Logits:  tensor([0.0797, 0.4596, 0.0011, 0.0113, 0.2142, 0.0060, 0.0538, 0.1179, 0.0031,\n",
      "        0.0198, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.075 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  559000\n",
      "Loss:  -4.3261194826180605\n",
      "Loss_orth:  0.0005163082844241573\n",
      "Loss_ML:  -4.326635790902484\n",
      "Logits:  tensor([0.0798, 0.4631, 0.0012, 0.0113, 0.2125, 0.0064, 0.0534, 0.1165, 0.0031,\n",
      "        0.0193, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.322 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  560000\n",
      "Loss:  -4.5013839959664415\n",
      "Loss_orth:  0.000675335216456825\n",
      "Loss_ML:  -4.502059331182898\n",
      "Logits:  tensor([0.0790, 0.4651, 0.0011, 0.0111, 0.2136, 0.0062, 0.0531, 0.1161, 0.0031,\n",
      "        0.0190, 0.0327], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.981 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  561000\n",
      "Loss:  -4.275634907887913\n",
      "Loss_orth:  0.0005757635080050037\n",
      "Loss_ML:  -4.276210671395917\n",
      "Logits:  tensor([0.0808, 0.4598, 0.0011, 0.0113, 0.2143, 0.0062, 0.0538, 0.1172, 0.0030,\n",
      "        0.0194, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.582 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  562000\n",
      "Loss:  -4.222704976620599\n",
      "Loss_orth:  0.0005033753389749852\n",
      "Loss_ML:  -4.223208351959574\n",
      "Logits:  tensor([0.0793, 0.4626, 0.0011, 0.0114, 0.2129, 0.0063, 0.0533, 0.1177, 0.0029,\n",
      "        0.0196, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.545 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  563000\n",
      "Loss:  -4.6227534613798795\n",
      "Loss_orth:  0.0004521429801052388\n",
      "Loss_ML:  -4.623205604359985\n",
      "Logits:  tensor([0.0798, 0.4605, 0.0011, 0.0111, 0.2153, 0.0061, 0.0532, 0.1170, 0.0028,\n",
      "        0.0195, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.363 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  564000\n",
      "Loss:  -4.662528081571893\n",
      "Loss_orth:  0.0004135815171442093\n",
      "Loss_ML:  -4.662941663089037\n",
      "Logits:  tensor([0.0795, 0.4640, 0.0011, 0.0114, 0.2124, 0.0061, 0.0534, 0.1168, 0.0029,\n",
      "        0.0196, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.819 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  565000\n",
      "Loss:  -4.159369065069882\n",
      "Loss_orth:  0.00036173308101361193\n",
      "Loss_ML:  -4.159730798150895\n",
      "Logits:  tensor([0.0800, 0.4601, 0.0011, 0.0117, 0.2134, 0.0064, 0.0535, 0.1171, 0.0031,\n",
      "        0.0199, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.197 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  566000\n",
      "Loss:  -4.675079060356811\n",
      "Loss_orth:  0.0007188013179773246\n",
      "Loss_ML:  -4.675797861674789\n",
      "Logits:  tensor([0.0806, 0.4642, 0.0010, 0.0109, 0.2127, 0.0062, 0.0537, 0.1159, 0.0030,\n",
      "        0.0192, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.555 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  567000\n",
      "Loss:  -4.2831726738863045\n",
      "Loss_orth:  0.000950297723530481\n",
      "Loss_ML:  -4.284122971609835\n",
      "Logits:  tensor([0.0796, 0.4634, 0.0010, 0.0112, 0.2140, 0.0060, 0.0530, 0.1163, 0.0031,\n",
      "        0.0195, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.621 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  568000\n",
      "Loss:  -4.419986798140243\n",
      "Loss_orth:  0.0003851888616803805\n",
      "Loss_ML:  -4.420371987001924\n",
      "Logits:  tensor([0.0804, 0.4613, 0.0010, 0.0115, 0.2109, 0.0061, 0.0540, 0.1176, 0.0031,\n",
      "        0.0201, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.242 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  569000\n",
      "Loss:  -4.417896181942412\n",
      "Loss_orth:  0.0005618254555380998\n",
      "Loss_ML:  -4.41845800739795\n",
      "Logits:  tensor([0.0798, 0.4590, 0.0011, 0.0115, 0.2157, 0.0062, 0.0533, 0.1172, 0.0030,\n",
      "        0.0199, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.476 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  570000\n",
      "Loss:  -4.381922007751047\n",
      "Loss_orth:  0.000751274760935459\n",
      "Loss_ML:  -4.382673282511982\n",
      "Logits:  tensor([0.0793, 0.4614, 0.0011, 0.0114, 0.2140, 0.0062, 0.0533, 0.1171, 0.0029,\n",
      "        0.0198, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.451 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  571000\n",
      "Loss:  -4.5017437530443525\n",
      "Loss_orth:  0.0007487670930395\n",
      "Loss_ML:  -4.502492520137392\n",
      "Logits:  tensor([0.0801, 0.4604, 0.0010, 0.0112, 0.2143, 0.0060, 0.0531, 0.1171, 0.0030,\n",
      "        0.0198, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.370 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  572000\n",
      "Loss:  -4.5286217549143055\n",
      "Loss_orth:  0.00026198424551180445\n",
      "Loss_ML:  -4.528883739159817\n",
      "Logits:  tensor([0.0790, 0.4644, 0.0010, 0.0110, 0.2139, 0.0057, 0.0533, 0.1160, 0.0029,\n",
      "        0.0192, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.634 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  573000\n",
      "Loss:  -4.7337702498351275\n",
      "Loss_orth:  0.0002322391900973374\n",
      "Loss_ML:  -4.734002489025225\n",
      "Logits:  tensor([0.0808, 0.4609, 0.0010, 0.0114, 0.2145, 0.0058, 0.0529, 0.1178, 0.0029,\n",
      "        0.0189, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.303 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  574000\n",
      "Loss:  -4.582988333542415\n",
      "Loss_orth:  0.0011122196517441424\n",
      "Loss_ML:  -4.584100553194159\n",
      "Logits:  tensor([0.0791, 0.4654, 0.0010, 0.0115, 0.2130, 0.0061, 0.0527, 0.1155, 0.0028,\n",
      "        0.0196, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.679 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  575000\n",
      "Loss:  -4.664313256530444\n",
      "Loss_orth:  0.0004305431024113073\n",
      "Loss_ML:  -4.664743799632856\n",
      "Logits:  tensor([0.0796, 0.4625, 0.0010, 0.0113, 0.2133, 0.0061, 0.0530, 0.1179, 0.0028,\n",
      "        0.0194, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.296 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  576000\n",
      "Loss:  -4.7289472105712544\n",
      "Loss_orth:  0.0005129107858003284\n",
      "Loss_ML:  -4.729460121357055\n",
      "Logits:  tensor([0.0794, 0.4589, 0.0010, 0.0114, 0.2157, 0.0060, 0.0543, 0.1178, 0.0028,\n",
      "        0.0195, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.410 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  577000\n",
      "Loss:  -4.611452421470457\n",
      "Loss_orth:  0.00044167040745516246\n",
      "Loss_ML:  -4.611894091877912\n",
      "Logits:  tensor([0.0782, 0.4648, 0.0010, 0.0116, 0.2127, 0.0062, 0.0530, 0.1165, 0.0030,\n",
      "        0.0200, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.939 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  578000\n",
      "Loss:  -4.444133989476341\n",
      "Loss_orth:  0.001038189944066491\n",
      "Loss_ML:  -4.445172179420407\n",
      "Logits:  tensor([0.0790, 0.4618, 0.0011, 0.0113, 0.2137, 0.0060, 0.0537, 0.1173, 0.0031,\n",
      "        0.0196, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.862 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  579000\n",
      "Loss:  -4.534475473009695\n",
      "Loss_orth:  0.00033126567736735564\n",
      "Loss_ML:  -4.534806738687062\n",
      "Logits:  tensor([0.0802, 0.4605, 0.0011, 0.0111, 0.2134, 0.0062, 0.0538, 0.1170, 0.0030,\n",
      "        0.0202, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 50.068 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  580000\n",
      "Loss:  -4.4995814103370195\n",
      "Loss_orth:  0.0005649512284274783\n",
      "Loss_ML:  -4.500146361565447\n",
      "Logits:  tensor([0.0813, 0.4608, 0.0011, 0.0109, 0.2123, 0.0059, 0.0542, 0.1173, 0.0030,\n",
      "        0.0195, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.265 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  581000\n",
      "Loss:  -4.135074879135214\n",
      "Loss_orth:  0.0002619053400623576\n",
      "Loss_ML:  -4.135336784475276\n",
      "Logits:  tensor([0.0799, 0.4592, 0.0011, 0.0110, 0.2145, 0.0062, 0.0531, 0.1186, 0.0030,\n",
      "        0.0198, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.950 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  582000\n",
      "Loss:  -4.410282171157293\n",
      "Loss_orth:  0.0003521103131716088\n",
      "Loss_ML:  -4.410634281470465\n",
      "Logits:  tensor([0.0800, 0.4593, 0.0011, 0.0119, 0.2143, 0.0064, 0.0532, 0.1171, 0.0031,\n",
      "        0.0201, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.818 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  583000\n",
      "Loss:  -4.5701631931639914\n",
      "Loss_orth:  0.000451496405950732\n",
      "Loss_ML:  -4.570614689569942\n",
      "Logits:  tensor([0.0783, 0.4631, 0.0011, 0.0118, 0.2121, 0.0063, 0.0538, 0.1167, 0.0030,\n",
      "        0.0200, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.376 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  584000\n",
      "Loss:  -4.5170823952691315\n",
      "Loss_orth:  0.0009911237357432719\n",
      "Loss_ML:  -4.518073519004875\n",
      "Logits:  tensor([0.0802, 0.4618, 0.0011, 0.0113, 0.2128, 0.0064, 0.0526, 0.1173, 0.0031,\n",
      "        0.0197, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.114 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  585000\n",
      "Loss:  -4.205086199915199\n",
      "Loss_orth:  0.0007151995894885999\n",
      "Loss_ML:  -4.205801399504687\n",
      "Logits:  tensor([0.0792, 0.4600, 0.0011, 0.0111, 0.2163, 0.0062, 0.0535, 0.1178, 0.0031,\n",
      "        0.0193, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.588 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  586000\n",
      "Loss:  -4.142018050332612\n",
      "Loss_orth:  0.00034091821943544665\n",
      "Loss_ML:  -4.142358968552047\n",
      "Logits:  tensor([0.0803, 0.4624, 0.0011, 0.0109, 0.2136, 0.0061, 0.0536, 0.1172, 0.0029,\n",
      "        0.0191, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.728 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  587000\n",
      "Loss:  -4.538472576536105\n",
      "Loss_orth:  0.0006780354671160472\n",
      "Loss_ML:  -4.539150612003221\n",
      "Logits:  tensor([0.0795, 0.4626, 0.0010, 0.0108, 0.2144, 0.0059, 0.0537, 0.1167, 0.0029,\n",
      "        0.0195, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.682 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  588000\n",
      "Loss:  -4.393722118853852\n",
      "Loss_orth:  0.0005943084936824216\n",
      "Loss_ML:  -4.394316427347535\n",
      "Logits:  tensor([0.0790, 0.4621, 0.0010, 0.0112, 0.2134, 0.0059, 0.0538, 0.1174, 0.0028,\n",
      "        0.0198, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.799 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  589000\n",
      "Loss:  -4.279365502214784\n",
      "Loss_orth:  0.0005938929028367661\n",
      "Loss_ML:  -4.27995939511762\n",
      "Logits:  tensor([0.0799, 0.4609, 0.0010, 0.0113, 0.2145, 0.0058, 0.0528, 0.1175, 0.0026,\n",
      "        0.0200, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.950 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  590000\n",
      "Loss:  -4.364697721353216\n",
      "Loss_orth:  0.0006831974473134561\n",
      "Loss_ML:  -4.365380918800529\n",
      "Logits:  tensor([0.0793, 0.4625, 0.0010, 0.0108, 0.2144, 0.0056, 0.0533, 0.1174, 0.0027,\n",
      "        0.0199, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.692 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  591000\n",
      "Loss:  -4.460476782807785\n",
      "Loss_orth:  0.000612285373189206\n",
      "Loss_ML:  -4.461089068180974\n",
      "Logits:  tensor([0.0808, 0.4597, 0.0010, 0.0113, 0.2142, 0.0059, 0.0538, 0.1173, 0.0028,\n",
      "        0.0199, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.088 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  592000\n",
      "Loss:  -4.561836941897424\n",
      "Loss_orth:  0.00040340145356324464\n",
      "Loss_ML:  -4.562240343350987\n",
      "Logits:  tensor([0.0790, 0.4629, 0.0010, 0.0110, 0.2142, 0.0059, 0.0536, 0.1162, 0.0029,\n",
      "        0.0196, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.511 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  593000\n",
      "Loss:  -4.350744552542235\n",
      "Loss_orth:  0.00041484843371921153\n",
      "Loss_ML:  -4.351159400975954\n",
      "Logits:  tensor([0.0785, 0.4588, 0.0010, 0.0113, 0.2153, 0.0060, 0.0542, 0.1173, 0.0030,\n",
      "        0.0205, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.728 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  594000\n",
      "Loss:  -4.541554176539571\n",
      "Loss_orth:  0.00035495407629719967\n",
      "Loss_ML:  -4.541909130615868\n",
      "Logits:  tensor([0.0787, 0.4674, 0.0010, 0.0107, 0.2143, 0.0059, 0.0523, 0.1161, 0.0028,\n",
      "        0.0188, 0.0319], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.748 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  595000\n",
      "Loss:  -4.486173821158429\n",
      "Loss_orth:  0.0006848520785811978\n",
      "Loss_ML:  -4.486858673237011\n",
      "Logits:  tensor([0.0800, 0.4594, 0.0010, 0.0116, 0.2128, 0.0061, 0.0541, 0.1182, 0.0030,\n",
      "        0.0201, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.367 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  596000\n",
      "Loss:  -4.46962275466654\n",
      "Loss_orth:  0.0003990736050794875\n",
      "Loss_ML:  -4.470021828271619\n",
      "Logits:  tensor([0.0802, 0.4603, 0.0009, 0.0115, 0.2139, 0.0059, 0.0538, 0.1177, 0.0030,\n",
      "        0.0197, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.047 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  597000\n",
      "Loss:  -4.656722405795103\n",
      "Loss_orth:  0.0004114823970330438\n",
      "Loss_ML:  -4.657133888192136\n",
      "Logits:  tensor([0.0805, 0.4619, 0.0010, 0.0113, 0.2119, 0.0060, 0.0542, 0.1168, 0.0030,\n",
      "        0.0196, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.181 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  598000\n",
      "Loss:  -4.588470608396005\n",
      "Loss_orth:  0.00033841586534733297\n",
      "Loss_ML:  -4.588809024261352\n",
      "Logits:  tensor([0.0790, 0.4665, 0.0010, 0.0110, 0.2114, 0.0059, 0.0533, 0.1166, 0.0030,\n",
      "        0.0195, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.535 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  599000\n",
      "Loss:  -4.337571864168192\n",
      "Loss_orth:  0.0009846112427932324\n",
      "Loss_ML:  -4.338556475410985\n",
      "Logits:  tensor([0.0805, 0.4578, 0.0010, 0.0116, 0.2124, 0.0061, 0.0543, 0.1185, 0.0031,\n",
      "        0.0202, 0.0345], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.147 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  600000\n",
      "Loss:  -4.263411999139\n",
      "Loss_orth:  0.0003460876566437812\n",
      "Loss_ML:  -4.263758086795644\n",
      "Logits:  tensor([0.0795, 0.4632, 0.0010, 0.0110, 0.2135, 0.0058, 0.0527, 0.1175, 0.0029,\n",
      "        0.0198, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.155 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  601000\n",
      "Loss:  -4.332609709471951\n",
      "Loss_orth:  0.00033597567863945417\n",
      "Loss_ML:  -4.332945685150591\n",
      "Logits:  tensor([0.0787, 0.4656, 0.0009, 0.0109, 0.2132, 0.0057, 0.0527, 0.1173, 0.0027,\n",
      "        0.0195, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.381 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  602000\n",
      "Loss:  -4.142753981531568\n",
      "Loss_orth:  0.0002622864904558331\n",
      "Loss_ML:  -4.1430162680220235\n",
      "Logits:  tensor([0.0800, 0.4625, 0.0009, 0.0110, 0.2130, 0.0058, 0.0534, 0.1169, 0.0028,\n",
      "        0.0198, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.378 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  603000\n",
      "Loss:  -4.507777250984875\n",
      "Loss_orth:  0.0007183307446013641\n",
      "Loss_ML:  -4.508495581729476\n",
      "Logits:  tensor([0.0792, 0.4647, 0.0009, 0.0107, 0.2127, 0.0058, 0.0528, 0.1178, 0.0029,\n",
      "        0.0194, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.040 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  604000\n",
      "Loss:  -4.43537496290248\n",
      "Loss_orth:  0.00030666122685894196\n",
      "Loss_ML:  -4.435681624129339\n",
      "Logits:  tensor([0.0793, 0.4629, 0.0009, 0.0108, 0.2147, 0.0060, 0.0526, 0.1179, 0.0029,\n",
      "        0.0191, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.615 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  605000\n",
      "Loss:  -4.440368502650753\n",
      "Loss_orth:  0.001032852948602\n",
      "Loss_ML:  -4.441401355599355\n",
      "Logits:  tensor([0.0801, 0.4612, 0.0009, 0.0109, 0.2144, 0.0060, 0.0533, 0.1174, 0.0029,\n",
      "        0.0192, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.445 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  606000\n",
      "Loss:  -4.5865242351676505\n",
      "Loss_orth:  0.0006963950624611308\n",
      "Loss_ML:  -4.587220630230112\n",
      "Logits:  tensor([0.0789, 0.4611, 0.0010, 0.0117, 0.2142, 0.0064, 0.0531, 0.1171, 0.0030,\n",
      "        0.0200, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.301 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  607000\n",
      "Loss:  -4.291233844504127\n",
      "Loss_orth:  0.0005188315950268876\n",
      "Loss_ML:  -4.291752676099154\n",
      "Logits:  tensor([0.0797, 0.4632, 0.0011, 0.0117, 0.2136, 0.0064, 0.0524, 0.1165, 0.0030,\n",
      "        0.0194, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.027 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  608000\n",
      "Loss:  -4.514121660305243\n",
      "Loss_orth:  0.0007857564323866231\n",
      "Loss_ML:  -4.514907416737629\n",
      "Logits:  tensor([0.0789, 0.4625, 0.0010, 0.0110, 0.2142, 0.0061, 0.0536, 0.1168, 0.0030,\n",
      "        0.0193, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.324 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  609000\n",
      "Loss:  -4.134797485337308\n",
      "Loss_orth:  0.0009670384041591077\n",
      "Loss_ML:  -4.135764523741467\n",
      "Logits:  tensor([0.0796, 0.4622, 0.0010, 0.0115, 0.2128, 0.0059, 0.0531, 0.1179, 0.0030,\n",
      "        0.0195, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.367 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  610000\n",
      "Loss:  -4.364573143547791\n",
      "Loss_orth:  0.0011050095828607379\n",
      "Loss_ML:  -4.365678153130651\n",
      "Logits:  tensor([0.0796, 0.4632, 0.0010, 0.0112, 0.2146, 0.0060, 0.0526, 0.1170, 0.0030,\n",
      "        0.0193, 0.0326], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.218 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  611000\n",
      "Loss:  -4.384774895757413\n",
      "Loss_orth:  0.00047596148402141735\n",
      "Loss_ML:  -4.385250857241434\n",
      "Logits:  tensor([0.0791, 0.4627, 0.0011, 0.0113, 0.2126, 0.0062, 0.0544, 0.1168, 0.0029,\n",
      "        0.0196, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.795 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  612000\n",
      "Loss:  -4.566291965953062\n",
      "Loss_orth:  0.0008358570092739367\n",
      "Loss_ML:  -4.567127822962336\n",
      "Logits:  tensor([0.0802, 0.4593, 0.0011, 0.0115, 0.2139, 0.0060, 0.0540, 0.1174, 0.0029,\n",
      "        0.0198, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.710 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  613000\n",
      "Loss:  -4.644443474726071\n",
      "Loss_orth:  0.0008619729096803304\n",
      "Loss_ML:  -4.645305447635751\n",
      "Logits:  tensor([0.0801, 0.4601, 0.0010, 0.0113, 0.2129, 0.0063, 0.0541, 0.1176, 0.0030,\n",
      "        0.0200, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.335 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  614000\n",
      "Loss:  -4.412601737642528\n",
      "Loss_orth:  0.0005610773031631982\n",
      "Loss_ML:  -4.413162814945691\n",
      "Logits:  tensor([0.0800, 0.4616, 0.0011, 0.0112, 0.2125, 0.0062, 0.0539, 0.1172, 0.0031,\n",
      "        0.0199, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.490 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  615000\n",
      "Loss:  -4.571895658860887\n",
      "Loss_orth:  0.00032258048689521695\n",
      "Loss_ML:  -4.572218239347783\n",
      "Logits:  tensor([0.0794, 0.4615, 0.0011, 0.0117, 0.2144, 0.0062, 0.0531, 0.1158, 0.0031,\n",
      "        0.0203, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.667 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  616000\n",
      "Loss:  -4.407857897874763\n",
      "Loss_orth:  0.0006543047401242685\n",
      "Loss_ML:  -4.4085122026148875\n",
      "Logits:  tensor([0.0787, 0.4623, 0.0011, 0.0114, 0.2153, 0.0060, 0.0532, 0.1165, 0.0031,\n",
      "        0.0192, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.956 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  617000\n",
      "Loss:  -4.299892567345854\n",
      "Loss_orth:  0.0003207261024511389\n",
      "Loss_ML:  -4.300213293448305\n",
      "Logits:  tensor([0.0802, 0.4630, 0.0010, 0.0113, 0.2140, 0.0059, 0.0533, 0.1162, 0.0030,\n",
      "        0.0192, 0.0327], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.364 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  618000\n",
      "Loss:  -4.413912393690197\n",
      "Loss_orth:  0.0007822485047257652\n",
      "Loss_ML:  -4.414694642194923\n",
      "Logits:  tensor([0.0805, 0.4628, 0.0009, 0.0109, 0.2136, 0.0059, 0.0537, 0.1165, 0.0031,\n",
      "        0.0190, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 50.651 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  619000\n",
      "Loss:  -4.505798553452261\n",
      "Loss_orth:  0.0003887510029867885\n",
      "Loss_ML:  -4.506187304455248\n",
      "Logits:  tensor([0.0803, 0.4628, 0.0009, 0.0108, 0.2137, 0.0058, 0.0527, 0.1179, 0.0030,\n",
      "        0.0191, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.842 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  620000\n",
      "Loss:  -4.592188359401915\n",
      "Loss_orth:  0.0003511075184635456\n",
      "Loss_ML:  -4.592539466920378\n",
      "Logits:  tensor([0.0805, 0.4623, 0.0010, 0.0114, 0.2108, 0.0058, 0.0540, 0.1180, 0.0030,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.814 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  621000\n",
      "Loss:  -4.239060762787014\n",
      "Loss_orth:  0.0007775947804356939\n",
      "Loss_ML:  -4.23983835756745\n",
      "Logits:  tensor([0.0793, 0.4629, 0.0010, 0.0112, 0.2147, 0.0061, 0.0539, 0.1153, 0.0032,\n",
      "        0.0193, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.546 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  622000\n",
      "Loss:  -4.5968170566595346\n",
      "Loss_orth:  0.0005633203832787824\n",
      "Loss_ML:  -4.597380377042813\n",
      "Logits:  tensor([0.0808, 0.4566, 0.0010, 0.0113, 0.2126, 0.0061, 0.0546, 0.1190, 0.0033,\n",
      "        0.0199, 0.0349], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.002 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  623000\n",
      "Loss:  -4.457792020441097\n",
      "Loss_orth:  0.0005865628857609879\n",
      "Loss_ML:  -4.4583785833268585\n",
      "Logits:  tensor([0.0797, 0.4625, 0.0009, 0.0113, 0.2129, 0.0060, 0.0530, 0.1180, 0.0032,\n",
      "        0.0194, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.823 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  624000\n",
      "Loss:  -4.857873854339549\n",
      "Loss_orth:  0.0004026925720593618\n",
      "Loss_ML:  -4.8582765469116085\n",
      "Logits:  tensor([0.0798, 0.4612, 0.0010, 0.0115, 0.2124, 0.0062, 0.0537, 0.1179, 0.0032,\n",
      "        0.0196, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.192 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  625000\n",
      "Loss:  -4.223189517662477\n",
      "Loss_orth:  0.0017868439360936167\n",
      "Loss_ML:  -4.2249763615985705\n",
      "Logits:  tensor([0.0798, 0.4574, 0.0010, 0.0114, 0.2149, 0.0063, 0.0544, 0.1182, 0.0033,\n",
      "        0.0198, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.713 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  626000\n",
      "Loss:  -4.57002370120356\n",
      "Loss_orth:  0.0004178884724969088\n",
      "Loss_ML:  -4.570441589676057\n",
      "Logits:  tensor([0.0794, 0.4604, 0.0010, 0.0114, 0.2137, 0.0065, 0.0540, 0.1168, 0.0034,\n",
      "        0.0199, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.242 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  627000\n",
      "Loss:  -4.198847331618675\n",
      "Loss_orth:  0.0007831322397445321\n",
      "Loss_ML:  -4.19963046385842\n",
      "Logits:  tensor([0.0800, 0.4615, 0.0010, 0.0109, 0.2117, 0.0059, 0.0543, 0.1184, 0.0032,\n",
      "        0.0196, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.124 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  628000\n",
      "Loss:  -4.423781071181365\n",
      "Loss_orth:  0.0014993753645435779\n",
      "Loss_ML:  -4.425280446545909\n",
      "Logits:  tensor([0.0800, 0.4604, 0.0009, 0.0109, 0.2138, 0.0059, 0.0539, 0.1176, 0.0032,\n",
      "        0.0196, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.944 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  629000\n",
      "Loss:  -4.216981066937456\n",
      "Loss_orth:  0.0005366441738944125\n",
      "Loss_ML:  -4.21751771111135\n",
      "Logits:  tensor([0.0796, 0.4622, 0.0009, 0.0109, 0.2134, 0.0062, 0.0534, 0.1173, 0.0031,\n",
      "        0.0192, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.695 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  630000\n",
      "Loss:  -4.476611521620252\n",
      "Loss_orth:  0.0005128844253829396\n",
      "Loss_ML:  -4.477124406045635\n",
      "Logits:  tensor([0.0795, 0.4626, 0.0009, 0.0108, 0.2158, 0.0062, 0.0533, 0.1157, 0.0031,\n",
      "        0.0190, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.234 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  631000\n",
      "Loss:  -4.645205454689526\n",
      "Loss_orth:  0.0006914307979707439\n",
      "Loss_ML:  -4.645896885487496\n",
      "Logits:  tensor([0.0795, 0.4622, 0.0009, 0.0110, 0.2155, 0.0059, 0.0533, 0.1163, 0.0031,\n",
      "        0.0192, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.899 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  632000\n",
      "Loss:  -4.183298362306491\n",
      "Loss_orth:  0.00070252916437073\n",
      "Loss_ML:  -4.184000891470862\n",
      "Logits:  tensor([0.0793, 0.4591, 0.0010, 0.0112, 0.2143, 0.0059, 0.0537, 0.1190, 0.0030,\n",
      "        0.0200, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.040 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  633000\n",
      "Loss:  -4.316599280551186\n",
      "Loss_orth:  0.00033021253874992046\n",
      "Loss_ML:  -4.316929493089936\n",
      "Logits:  tensor([0.0795, 0.4596, 0.0010, 0.0110, 0.2153, 0.0059, 0.0539, 0.1172, 0.0031,\n",
      "        0.0198, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.922 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  634000\n",
      "Loss:  -4.461366160300796\n",
      "Loss_orth:  0.00040282781267842404\n",
      "Loss_ML:  -4.461768988113474\n",
      "Logits:  tensor([0.0800, 0.4612, 0.0010, 0.0113, 0.2123, 0.0060, 0.0537, 0.1172, 0.0031,\n",
      "        0.0199, 0.0343], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.607 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  635000\n",
      "Loss:  -4.1938619784204665\n",
      "Loss_orth:  0.00033958051352879243\n",
      "Loss_ML:  -4.194201558933996\n",
      "Logits:  tensor([0.0805, 0.4620, 0.0010, 0.0115, 0.2116, 0.0061, 0.0539, 0.1168, 0.0031,\n",
      "        0.0205, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 53.328 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  636000\n",
      "Loss:  -4.5294969479498235\n",
      "Loss_orth:  0.00046954100652219524\n",
      "Loss_ML:  -4.529966488956346\n",
      "Logits:  tensor([0.0798, 0.4615, 0.0011, 0.0112, 0.2123, 0.0060, 0.0529, 0.1183, 0.0032,\n",
      "        0.0199, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.284 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  637000\n",
      "Loss:  -4.199855983538233\n",
      "Loss_orth:  0.000471510114773993\n",
      "Loss_ML:  -4.200327493653007\n",
      "Logits:  tensor([0.0801, 0.4614, 0.0010, 0.0110, 0.2135, 0.0059, 0.0534, 0.1178, 0.0030,\n",
      "        0.0197, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.437 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  638000\n",
      "Loss:  -4.500402748766451\n",
      "Loss_orth:  0.0011763059719829775\n",
      "Loss_ML:  -4.501579054738434\n",
      "Logits:  tensor([0.0801, 0.4621, 0.0010, 0.0114, 0.2124, 0.0061, 0.0534, 0.1169, 0.0031,\n",
      "        0.0199, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.166 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  639000\n",
      "Loss:  -4.469659960695006\n",
      "Loss_orth:  0.00035104500576828653\n",
      "Loss_ML:  -4.4700110057007745\n",
      "Logits:  tensor([0.0800, 0.4603, 0.0011, 0.0112, 0.2128, 0.0059, 0.0535, 0.1183, 0.0031,\n",
      "        0.0200, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.222 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  640000\n",
      "Loss:  -4.189679874756151\n",
      "Loss_orth:  0.0002725121089766933\n",
      "Loss_ML:  -4.189952386865127\n",
      "Logits:  tensor([0.0804, 0.4609, 0.0010, 0.0116, 0.2126, 0.0059, 0.0532, 0.1173, 0.0032,\n",
      "        0.0199, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.485 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  641000\n",
      "Loss:  -4.567181835347691\n",
      "Loss_orth:  0.0005261760869442485\n",
      "Loss_ML:  -4.567708011434635\n",
      "Logits:  tensor([0.0804, 0.4622, 0.0011, 0.0116, 0.2117, 0.0062, 0.0537, 0.1166, 0.0033,\n",
      "        0.0194, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.242 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  642000\n",
      "Loss:  -4.247984054135889\n",
      "Loss_orth:  0.00019893334438085582\n",
      "Loss_ML:  -4.24818298748027\n",
      "Logits:  tensor([0.0802, 0.4621, 0.0011, 0.0110, 0.2140, 0.0059, 0.0533, 0.1168, 0.0030,\n",
      "        0.0194, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.522 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  643000\n",
      "Loss:  -4.70075169927198\n",
      "Loss_orth:  0.000234799702412207\n",
      "Loss_ML:  -4.700986498974393\n",
      "Logits:  tensor([0.0800, 0.4608, 0.0011, 0.0113, 0.2136, 0.0060, 0.0536, 0.1177, 0.0030,\n",
      "        0.0198, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.679 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  644000\n",
      "Loss:  -4.434303801899837\n",
      "Loss_orth:  0.0008065252262381316\n",
      "Loss_ML:  -4.4351103271260754\n",
      "Logits:  tensor([0.0793, 0.4605, 0.0011, 0.0113, 0.2151, 0.0060, 0.0533, 0.1172, 0.0031,\n",
      "        0.0200, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.677 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  645000\n",
      "Loss:  -4.306626927117264\n",
      "Loss_orth:  0.00031540725234449363\n",
      "Loss_ML:  -4.306942334369609\n",
      "Logits:  tensor([0.0801, 0.4618, 0.0010, 0.0112, 0.2120, 0.0061, 0.0535, 0.1179, 0.0032,\n",
      "        0.0196, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.524 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  646000\n",
      "Loss:  -4.824786922643078\n",
      "Loss_orth:  0.0005729029552298295\n",
      "Loss_ML:  -4.825359825598308\n",
      "Logits:  tensor([0.0796, 0.4645, 0.0010, 0.0112, 0.2134, 0.0060, 0.0529, 0.1166, 0.0031,\n",
      "        0.0191, 0.0326], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.220 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  647000\n",
      "Loss:  -4.7846355500998845\n",
      "Loss_orth:  0.000565399284815679\n",
      "Loss_ML:  -4.7852009493847\n",
      "Logits:  tensor([0.0789, 0.4660, 0.0011, 0.0111, 0.2136, 0.0061, 0.0526, 0.1147, 0.0030,\n",
      "        0.0193, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.675 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  648000\n",
      "Loss:  -4.367901281410968\n",
      "Loss_orth:  0.0006352731350291121\n",
      "Loss_ML:  -4.368536554545997\n",
      "Logits:  tensor([0.0798, 0.4637, 0.0010, 0.0111, 0.2121, 0.0060, 0.0536, 0.1169, 0.0031,\n",
      "        0.0192, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.969 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  649000\n",
      "Loss:  -4.310237641084825\n",
      "Loss_orth:  0.00038055744584802485\n",
      "Loss_ML:  -4.3106181985306735\n",
      "Logits:  tensor([0.0800, 0.4600, 0.0011, 0.0116, 0.2113, 0.0063, 0.0540, 0.1180, 0.0033,\n",
      "        0.0200, 0.0343], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.280 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  650000\n",
      "Loss:  -4.388633237624066\n",
      "Loss_orth:  0.0006863197920997234\n",
      "Loss_ML:  -4.389319557416165\n",
      "Logits:  tensor([0.0802, 0.4602, 0.0011, 0.0112, 0.2130, 0.0062, 0.0537, 0.1179, 0.0033,\n",
      "        0.0197, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.733 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  651000\n",
      "Loss:  -4.460255968265829\n",
      "Loss_orth:  0.0002889606226854332\n",
      "Loss_ML:  -4.460544928888515\n",
      "Logits:  tensor([0.0788, 0.4620, 0.0011, 0.0112, 0.2148, 0.0060, 0.0525, 0.1174, 0.0033,\n",
      "        0.0196, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.041 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  652000\n",
      "Loss:  -4.266594504768921\n",
      "Loss_orth:  0.0008594398307313295\n",
      "Loss_ML:  -4.267453944599652\n",
      "Logits:  tensor([0.0789, 0.4601, 0.0012, 0.0116, 0.2134, 0.0062, 0.0539, 0.1179, 0.0032,\n",
      "        0.0198, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.190 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  653000\n",
      "Loss:  -4.516983629154544\n",
      "Loss_orth:  0.0006167559491742018\n",
      "Loss_ML:  -4.5176003851037185\n",
      "Logits:  tensor([0.0793, 0.4657, 0.0012, 0.0110, 0.2132, 0.0056, 0.0524, 0.1164, 0.0030,\n",
      "        0.0194, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.011 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  654000\n",
      "Loss:  -4.236648314647542\n",
      "Loss_orth:  0.0006902424197234113\n",
      "Loss_ML:  -4.2373385570672655\n",
      "Logits:  tensor([0.0802, 0.4605, 0.0012, 0.0114, 0.2140, 0.0058, 0.0533, 0.1177, 0.0030,\n",
      "        0.0194, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.756 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  655000\n",
      "Loss:  -4.61218837890916\n",
      "Loss_orth:  0.0004445779620283523\n",
      "Loss_ML:  -4.612632956871188\n",
      "Logits:  tensor([0.0803, 0.4606, 0.0012, 0.0112, 0.2142, 0.0061, 0.0533, 0.1169, 0.0030,\n",
      "        0.0197, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.292 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  656000\n",
      "Loss:  -4.227700393701514\n",
      "Loss_orth:  0.0009022002304626732\n",
      "Loss_ML:  -4.228602593931976\n",
      "Logits:  tensor([0.0802, 0.4621, 0.0012, 0.0113, 0.2132, 0.0059, 0.0530, 0.1175, 0.0030,\n",
      "        0.0194, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 51.049 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  657000\n",
      "Loss:  -4.337610881724332\n",
      "Loss_orth:  0.0005282587583081736\n",
      "Loss_ML:  -4.338139140482641\n",
      "Logits:  tensor([0.0805, 0.4614, 0.0012, 0.0109, 0.2131, 0.0058, 0.0534, 0.1179, 0.0029,\n",
      "        0.0195, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.207 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  658000\n",
      "Loss:  -4.41047794582071\n",
      "Loss_orth:  0.000258954560675311\n",
      "Loss_ML:  -4.410736900381385\n",
      "Logits:  tensor([0.0792, 0.4638, 0.0012, 0.0109, 0.2137, 0.0058, 0.0530, 0.1168, 0.0029,\n",
      "        0.0197, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.948 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  659000\n",
      "Loss:  -4.000859951850553\n",
      "Loss_orth:  0.0004623272216522084\n",
      "Loss_ML:  -4.001322279072205\n",
      "Logits:  tensor([0.0799, 0.4580, 0.0012, 0.0110, 0.2145, 0.0059, 0.0543, 0.1181, 0.0029,\n",
      "        0.0196, 0.0345], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.106 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  660000\n",
      "Loss:  -4.479365439101306\n",
      "Loss_orth:  0.0003038902439183297\n",
      "Loss_ML:  -4.479669329345224\n",
      "Logits:  tensor([0.0799, 0.4608, 0.0012, 0.0113, 0.2126, 0.0063, 0.0531, 0.1180, 0.0030,\n",
      "        0.0199, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.997 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  661000\n",
      "Loss:  -4.994411939608623\n",
      "Loss_orth:  0.0005934795402146942\n",
      "Loss_ML:  -4.995005419148838\n",
      "Logits:  tensor([0.0791, 0.4596, 0.0012, 0.0111, 0.2173, 0.0061, 0.0530, 0.1174, 0.0030,\n",
      "        0.0194, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.836 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  662000\n",
      "Loss:  -4.554983960276999\n",
      "Loss_orth:  0.00034372752441641356\n",
      "Loss_ML:  -4.555327687801416\n",
      "Logits:  tensor([0.0792, 0.4639, 0.0012, 0.0110, 0.2122, 0.0060, 0.0531, 0.1174, 0.0032,\n",
      "        0.0195, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.897 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  663000\n",
      "Loss:  -4.412373857417054\n",
      "Loss_orth:  0.0004435818029560147\n",
      "Loss_ML:  -4.41281743922001\n",
      "Logits:  tensor([0.0796, 0.4626, 0.0012, 0.0110, 0.2129, 0.0059, 0.0541, 0.1165, 0.0032,\n",
      "        0.0194, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.374 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  664000\n",
      "Loss:  -4.477654455454869\n",
      "Loss_orth:  0.00023811239816159713\n",
      "Loss_ML:  -4.47789256785303\n",
      "Logits:  tensor([0.0812, 0.4618, 0.0011, 0.0112, 0.2115, 0.0058, 0.0538, 0.1176, 0.0032,\n",
      "        0.0195, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.612 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  665000\n",
      "Loss:  -4.2976928152558305\n",
      "Loss_orth:  0.00025911615045037405\n",
      "Loss_ML:  -4.29795193140628\n",
      "Logits:  tensor([0.0796, 0.4589, 0.0011, 0.0111, 0.2131, 0.0059, 0.0545, 0.1183, 0.0032,\n",
      "        0.0200, 0.0343], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.321 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  666000\n",
      "Loss:  -4.533207545687428\n",
      "Loss_orth:  0.00032428486091031573\n",
      "Loss_ML:  -4.533531830548338\n",
      "Logits:  tensor([0.0796, 0.4622, 0.0011, 0.0111, 0.2127, 0.0059, 0.0532, 0.1181, 0.0032,\n",
      "        0.0196, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.303 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  667000\n",
      "Loss:  -4.3454184545757\n",
      "Loss_orth:  0.000677633288691407\n",
      "Loss_ML:  -4.3460960878643915\n",
      "Logits:  tensor([0.0807, 0.4635, 0.0011, 0.0110, 0.2112, 0.0057, 0.0535, 0.1180, 0.0031,\n",
      "        0.0198, 0.0324], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.783 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  668000\n",
      "Loss:  -4.368482304499499\n",
      "Loss_orth:  0.0005336049362655841\n",
      "Loss_ML:  -4.369015909435764\n",
      "Logits:  tensor([0.0796, 0.4635, 0.0011, 0.0111, 0.2137, 0.0058, 0.0529, 0.1163, 0.0031,\n",
      "        0.0197, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.696 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  669000\n",
      "Loss:  -4.265296279733026\n",
      "Loss_orth:  0.00047161587878102277\n",
      "Loss_ML:  -4.265767895611807\n",
      "Logits:  tensor([0.0799, 0.4591, 0.0011, 0.0119, 0.2126, 0.0062, 0.0546, 0.1174, 0.0034,\n",
      "        0.0199, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.399 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  670000\n",
      "Loss:  -4.588183801639058\n",
      "Loss_orth:  0.0005432243785432064\n",
      "Loss_ML:  -4.588727026017601\n",
      "Logits:  tensor([0.0792, 0.4621, 0.0012, 0.0118, 0.2127, 0.0061, 0.0544, 0.1155, 0.0031,\n",
      "        0.0198, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.384 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  671000\n",
      "Loss:  -4.464353334592825\n",
      "Loss_orth:  0.00041161680717758097\n",
      "Loss_ML:  -4.464764951400002\n",
      "Logits:  tensor([0.0786, 0.4647, 0.0011, 0.0114, 0.2129, 0.0060, 0.0528, 0.1164, 0.0030,\n",
      "        0.0198, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.154 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  672000\n",
      "Loss:  -4.453464256582053\n",
      "Loss_orth:  0.0005519068851568507\n",
      "Loss_ML:  -4.45401616346721\n",
      "Logits:  tensor([0.0796, 0.4628, 0.0011, 0.0111, 0.2141, 0.0059, 0.0530, 0.1178, 0.0030,\n",
      "        0.0189, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.930 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  673000\n",
      "Loss:  -4.748102456462591\n",
      "Loss_orth:  0.0013865697848496747\n",
      "Loss_ML:  -4.74948902624744\n",
      "Logits:  tensor([0.0794, 0.4606, 0.0011, 0.0114, 0.2141, 0.0060, 0.0530, 0.1172, 0.0033,\n",
      "        0.0201, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.083 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  674000\n",
      "Loss:  -4.36694104508575\n",
      "Loss_orth:  0.0003715974993011831\n",
      "Loss_ML:  -4.367312642585051\n",
      "Logits:  tensor([0.0792, 0.4626, 0.0010, 0.0113, 0.2140, 0.0061, 0.0535, 0.1163, 0.0032,\n",
      "        0.0198, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.031 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  675000\n",
      "Loss:  -4.530564462963426\n",
      "Loss_orth:  0.0002968943721391768\n",
      "Loss_ML:  -4.530861357335565\n",
      "Logits:  tensor([0.0804, 0.4586, 0.0010, 0.0109, 0.2149, 0.0059, 0.0543, 0.1183, 0.0030,\n",
      "        0.0195, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.172 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  676000\n",
      "Loss:  -4.633030913388624\n",
      "Loss_orth:  0.00030965902255300596\n",
      "Loss_ML:  -4.633340572411177\n",
      "Logits:  tensor([0.0801, 0.4614, 0.0010, 0.0112, 0.2141, 0.0061, 0.0539, 0.1163, 0.0031,\n",
      "        0.0192, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.426 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  677000\n",
      "Loss:  -4.342244835744832\n",
      "Loss_orth:  0.0002560417982064701\n",
      "Loss_ML:  -4.3425008775430385\n",
      "Logits:  tensor([0.0793, 0.4632, 0.0010, 0.0113, 0.2135, 0.0061, 0.0537, 0.1153, 0.0032,\n",
      "        0.0198, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.395 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  678000\n",
      "Loss:  -4.460036972766851\n",
      "Loss_orth:  0.0009308738305074362\n",
      "Loss_ML:  -4.460967846597359\n",
      "Logits:  tensor([0.0790, 0.4636, 0.0010, 0.0113, 0.2140, 0.0062, 0.0530, 0.1162, 0.0031,\n",
      "        0.0196, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.775 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  679000\n",
      "Loss:  -4.054187829786321\n",
      "Loss_orth:  0.0005482145897582166\n",
      "Loss_ML:  -4.05473604437608\n",
      "Logits:  tensor([0.0798, 0.4618, 0.0010, 0.0112, 0.2129, 0.0061, 0.0527, 0.1185, 0.0031,\n",
      "        0.0197, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.429 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  680000\n",
      "Loss:  -4.638406181993065\n",
      "Loss_orth:  0.00035834833035924\n",
      "Loss_ML:  -4.638764530323424\n",
      "Logits:  tensor([0.0796, 0.4599, 0.0010, 0.0114, 0.2141, 0.0063, 0.0536, 0.1179, 0.0031,\n",
      "        0.0202, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.848 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  681000\n",
      "Loss:  -4.481832015304304\n",
      "Loss_orth:  0.0005516827044315361\n",
      "Loss_ML:  -4.482383698008736\n",
      "Logits:  tensor([0.0785, 0.4623, 0.0011, 0.0114, 0.2153, 0.0061, 0.0529, 0.1165, 0.0032,\n",
      "        0.0199, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.607 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  682000\n",
      "Loss:  -4.441598714733074\n",
      "Loss_orth:  0.0003492567020377663\n",
      "Loss_ML:  -4.441947971435112\n",
      "Logits:  tensor([0.0798, 0.4624, 0.0011, 0.0107, 0.2152, 0.0061, 0.0534, 0.1154, 0.0030,\n",
      "        0.0195, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.106 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  683000\n",
      "Loss:  -4.622160766016498\n",
      "Loss_orth:  0.0006109103133225259\n",
      "Loss_ML:  -4.622771676329821\n",
      "Logits:  tensor([0.0801, 0.4615, 0.0010, 0.0107, 0.2143, 0.0061, 0.0530, 0.1173, 0.0030,\n",
      "        0.0195, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.108 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  684000\n",
      "Loss:  -4.148766853234631\n",
      "Loss_orth:  0.000741885202259295\n",
      "Loss_ML:  -4.14950873843689\n",
      "Logits:  tensor([0.0806, 0.4637, 0.0010, 0.0111, 0.2115, 0.0061, 0.0534, 0.1163, 0.0030,\n",
      "        0.0196, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.188 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  685000\n",
      "Loss:  -4.537506145101669\n",
      "Loss_orth:  0.0007996811838631887\n",
      "Loss_ML:  -4.538305826285532\n",
      "Logits:  tensor([0.0796, 0.4591, 0.0010, 0.0112, 0.2146, 0.0063, 0.0540, 0.1177, 0.0031,\n",
      "        0.0196, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.089 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  686000\n",
      "Loss:  -4.305557123364138\n",
      "Loss_orth:  0.0003990191927836099\n",
      "Loss_ML:  -4.305956142556921\n",
      "Logits:  tensor([0.0793, 0.4627, 0.0010, 0.0112, 0.2138, 0.0061, 0.0530, 0.1171, 0.0031,\n",
      "        0.0195, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.447 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  687000\n",
      "Loss:  -4.673288203757689\n",
      "Loss_orth:  0.00046633297762250364\n",
      "Loss_ML:  -4.673754536735312\n",
      "Logits:  tensor([0.0800, 0.4603, 0.0010, 0.0114, 0.2142, 0.0064, 0.0542, 0.1163, 0.0032,\n",
      "        0.0197, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.830 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  688000\n",
      "Loss:  -4.24281181156193\n",
      "Loss_orth:  0.0005739873905441189\n",
      "Loss_ML:  -4.243385798952474\n",
      "Logits:  tensor([0.0780, 0.4670, 0.0010, 0.0112, 0.2128, 0.0059, 0.0524, 0.1164, 0.0030,\n",
      "        0.0193, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.164 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  689000\n",
      "Loss:  -4.450215602369639\n",
      "Loss_orth:  0.00039955802214942937\n",
      "Loss_ML:  -4.450615160391788\n",
      "Logits:  tensor([0.0800, 0.4627, 0.0010, 0.0111, 0.2118, 0.0061, 0.0536, 0.1177, 0.0030,\n",
      "        0.0196, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.862 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  690000\n",
      "Loss:  -4.596576451440232\n",
      "Loss_orth:  0.0004918826706279553\n",
      "Loss_ML:  -4.59706833411086\n",
      "Logits:  tensor([0.0802, 0.4600, 0.0011, 0.0115, 0.2134, 0.0065, 0.0537, 0.1169, 0.0030,\n",
      "        0.0199, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.026 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  691000\n",
      "Loss:  -4.502238397470391\n",
      "Loss_orth:  0.00017144566834003305\n",
      "Loss_ML:  -4.502409843138731\n",
      "Logits:  tensor([0.0791, 0.4650, 0.0011, 0.0112, 0.2133, 0.0062, 0.0525, 0.1154, 0.0031,\n",
      "        0.0198, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.457 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  692000\n",
      "Loss:  -4.250282014623729\n",
      "Loss_orth:  0.0002553377493763803\n",
      "Loss_ML:  -4.250537352373105\n",
      "Logits:  tensor([0.0798, 0.4595, 0.0011, 0.0113, 0.2123, 0.0064, 0.0548, 0.1182, 0.0032,\n",
      "        0.0198, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.536 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  693000\n",
      "Loss:  -4.403360554222918\n",
      "Loss_orth:  0.0005719265371698289\n",
      "Loss_ML:  -4.403932480760088\n",
      "Logits:  tensor([0.0795, 0.4644, 0.0012, 0.0112, 0.2122, 0.0061, 0.0532, 0.1159, 0.0032,\n",
      "        0.0195, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.592 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  694000\n",
      "Loss:  -4.28529059373613\n",
      "Loss_orth:  0.0004563000433158493\n",
      "Loss_ML:  -4.2857468937794465\n",
      "Logits:  tensor([0.0792, 0.4642, 0.0012, 0.0114, 0.2125, 0.0061, 0.0528, 0.1162, 0.0034,\n",
      "        0.0197, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.527 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  695000\n",
      "Loss:  -4.563339595667361\n",
      "Loss_orth:  0.00037026875548056324\n",
      "Loss_ML:  -4.563709864422841\n",
      "Logits:  tensor([0.0797, 0.4626, 0.0012, 0.0111, 0.2120, 0.0058, 0.0537, 0.1179, 0.0032,\n",
      "        0.0197, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.690 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  696000\n",
      "Loss:  -4.765533569692581\n",
      "Loss_orth:  0.0009242696506738218\n",
      "Loss_ML:  -4.766457839343254\n",
      "Logits:  tensor([0.0803, 0.4615, 0.0011, 0.0110, 0.2143, 0.0057, 0.0534, 0.1165, 0.0030,\n",
      "        0.0193, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.970 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  697000\n",
      "Loss:  -4.496698326865943\n",
      "Loss_orth:  0.000375565371366309\n",
      "Loss_ML:  -4.497073892237309\n",
      "Logits:  tensor([0.0793, 0.4623, 0.0011, 0.0113, 0.2131, 0.0059, 0.0539, 0.1177, 0.0028,\n",
      "        0.0191, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.140 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  698000\n",
      "Loss:  -4.242320027436276\n",
      "Loss_orth:  0.0004697163780413994\n",
      "Loss_ML:  -4.242789743814317\n",
      "Logits:  tensor([0.0788, 0.4630, 0.0012, 0.0115, 0.2118, 0.0063, 0.0542, 0.1165, 0.0030,\n",
      "        0.0198, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.208 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  699000\n",
      "Loss:  -4.997262167881164\n",
      "Loss_orth:  0.0005764853794917207\n",
      "Loss_ML:  -4.997838653260656\n",
      "Logits:  tensor([0.0796, 0.4635, 0.0012, 0.0111, 0.2146, 0.0061, 0.0529, 0.1162, 0.0030,\n",
      "        0.0193, 0.0326], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.160 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  700000\n",
      "Loss:  -4.613825475226425\n",
      "Loss_orth:  0.0008106955612007234\n",
      "Loss_ML:  -4.614636170787626\n",
      "Logits:  tensor([0.0799, 0.4598, 0.0012, 0.0111, 0.2139, 0.0061, 0.0547, 0.1175, 0.0031,\n",
      "        0.0193, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.541 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  701000\n",
      "Loss:  -4.621983474529583\n",
      "Loss_orth:  0.0010964743500689956\n",
      "Loss_ML:  -4.623079948879652\n",
      "Logits:  tensor([0.0800, 0.4621, 0.0011, 0.0107, 0.2138, 0.0057, 0.0542, 0.1169, 0.0029,\n",
      "        0.0195, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.338 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  702000\n",
      "Loss:  -4.43746683403035\n",
      "Loss_orth:  0.0007434783181843945\n",
      "Loss_ML:  -4.438210312348534\n",
      "Logits:  tensor([0.0794, 0.4616, 0.0011, 0.0111, 0.2141, 0.0059, 0.0537, 0.1178, 0.0029,\n",
      "        0.0194, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.069 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  703000\n",
      "Loss:  -4.163808058438788\n",
      "Loss_orth:  0.0005113716719826315\n",
      "Loss_ML:  -4.164319430110771\n",
      "Logits:  tensor([0.0803, 0.4611, 0.0012, 0.0112, 0.2148, 0.0059, 0.0532, 0.1167, 0.0029,\n",
      "        0.0196, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.715 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  704000\n",
      "Loss:  -4.4672364482967994\n",
      "Loss_orth:  0.00039937829762970635\n",
      "Loss_ML:  -4.467635826594429\n",
      "Logits:  tensor([0.0802, 0.4591, 0.0012, 0.0114, 0.2143, 0.0059, 0.0541, 0.1168, 0.0028,\n",
      "        0.0204, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.076 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  705000\n",
      "Loss:  -3.9783249254275943\n",
      "Loss_orth:  0.0002463390371884707\n",
      "Loss_ML:  -3.9785712644647826\n",
      "Logits:  tensor([0.0792, 0.4640, 0.0012, 0.0110, 0.2132, 0.0060, 0.0534, 0.1164, 0.0029,\n",
      "        0.0197, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.568 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  706000\n",
      "Loss:  -4.81193015569913\n",
      "Loss_orth:  0.0004241178245858988\n",
      "Loss_ML:  -4.812354273523717\n",
      "Logits:  tensor([0.0792, 0.4639, 0.0012, 0.0110, 0.2125, 0.0059, 0.0533, 0.1176, 0.0027,\n",
      "        0.0196, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.956 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  707000\n",
      "Loss:  -4.696215176639217\n",
      "Loss_orth:  0.0005975912772614233\n",
      "Loss_ML:  -4.696812767916478\n",
      "Logits:  tensor([0.0790, 0.4648, 0.0012, 0.0110, 0.2142, 0.0059, 0.0526, 0.1157, 0.0027,\n",
      "        0.0196, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.255 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  708000\n",
      "Loss:  -4.383773367233152\n",
      "Loss_orth:  0.0006276515053719532\n",
      "Loss_ML:  -4.384401018738524\n",
      "Logits:  tensor([0.0794, 0.4646, 0.0011, 0.0109, 0.2120, 0.0059, 0.0531, 0.1182, 0.0028,\n",
      "        0.0190, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.442 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  709000\n",
      "Loss:  -4.680225638889988\n",
      "Loss_orth:  0.0004702294780546536\n",
      "Loss_ML:  -4.680695868368042\n",
      "Logits:  tensor([0.0792, 0.4621, 0.0012, 0.0115, 0.2136, 0.0062, 0.0533, 0.1167, 0.0029,\n",
      "        0.0199, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.544 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  710000\n",
      "Loss:  -4.392978520490987\n",
      "Loss_orth:  0.0003862862009355868\n",
      "Loss_ML:  -4.393364806691922\n",
      "Logits:  tensor([0.0790, 0.4680, 0.0011, 0.0109, 0.2123, 0.0058, 0.0525, 0.1158, 0.0028,\n",
      "        0.0193, 0.0324], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.196 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  711000\n",
      "Loss:  -4.365398759869154\n",
      "Loss_orth:  0.0005191081375987008\n",
      "Loss_ML:  -4.365917868006753\n",
      "Logits:  tensor([0.0797, 0.4609, 0.0012, 0.0117, 0.2136, 0.0060, 0.0542, 0.1161, 0.0031,\n",
      "        0.0199, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.043 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  712000\n",
      "Loss:  -4.763149613378359\n",
      "Loss_orth:  0.00034706942272104586\n",
      "Loss_ML:  -4.7634966828010805\n",
      "Logits:  tensor([0.0802, 0.4629, 0.0012, 0.0113, 0.2115, 0.0059, 0.0540, 0.1174, 0.0030,\n",
      "        0.0195, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.883 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  713000\n",
      "Loss:  -4.37575878099929\n",
      "Loss_orth:  0.00043634407188845853\n",
      "Loss_ML:  -4.376195125071179\n",
      "Logits:  tensor([0.0800, 0.4607, 0.0012, 0.0115, 0.2124, 0.0062, 0.0539, 0.1184, 0.0030,\n",
      "        0.0197, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.695 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  714000\n",
      "Loss:  -4.70103565958408\n",
      "Loss_orth:  0.00046361619154714916\n",
      "Loss_ML:  -4.701499275775627\n",
      "Logits:  tensor([0.0796, 0.4596, 0.0013, 0.0115, 0.2143, 0.0063, 0.0533, 0.1166, 0.0032,\n",
      "        0.0202, 0.0341], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.255 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  715000\n",
      "Loss:  -4.631740818813353\n",
      "Loss_orth:  0.00031676136690064505\n",
      "Loss_ML:  -4.632057580180254\n",
      "Logits:  tensor([0.0804, 0.4603, 0.0013, 0.0115, 0.2120, 0.0062, 0.0541, 0.1170, 0.0033,\n",
      "        0.0201, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.130 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  716000\n",
      "Loss:  -4.518009170914534\n",
      "Loss_orth:  0.00037087965481632466\n",
      "Loss_ML:  -4.518380050569351\n",
      "Logits:  tensor([0.0791, 0.4649, 0.0012, 0.0112, 0.2116, 0.0063, 0.0535, 0.1158, 0.0032,\n",
      "        0.0197, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.628 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  717000\n",
      "Loss:  -4.67742131920794\n",
      "Loss_orth:  0.0010374660190953446\n",
      "Loss_ML:  -4.678458785227035\n",
      "Logits:  tensor([0.0795, 0.4613, 0.0012, 0.0111, 0.2144, 0.0061, 0.0533, 0.1166, 0.0033,\n",
      "        0.0197, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.330 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  718000\n",
      "Loss:  -4.719257988856353\n",
      "Loss_orth:  0.0003624917794365997\n",
      "Loss_ML:  -4.71962048063579\n",
      "Logits:  tensor([0.0798, 0.4600, 0.0012, 0.0111, 0.2142, 0.0059, 0.0536, 0.1174, 0.0033,\n",
      "        0.0195, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.026 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  719000\n",
      "Loss:  -4.594157443856329\n",
      "Loss_orth:  0.0004421015834038378\n",
      "Loss_ML:  -4.594599545439732\n",
      "Logits:  tensor([0.0782, 0.4646, 0.0012, 0.0109, 0.2134, 0.0060, 0.0539, 0.1159, 0.0032,\n",
      "        0.0195, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.625 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  720000\n",
      "Loss:  -4.617389495898828\n",
      "Loss_orth:  0.0005748763050194378\n",
      "Loss_ML:  -4.617964372203847\n",
      "Logits:  tensor([0.0800, 0.4644, 0.0012, 0.0111, 0.2109, 0.0061, 0.0539, 0.1163, 0.0033,\n",
      "        0.0192, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.600 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  721000\n",
      "Loss:  -4.456420006489061\n",
      "Loss_orth:  0.0007079848405584423\n",
      "Loss_ML:  -4.45712799132962\n",
      "Logits:  tensor([0.0792, 0.4622, 0.0013, 0.0110, 0.2145, 0.0061, 0.0529, 0.1170, 0.0033,\n",
      "        0.0194, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.846 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  722000\n",
      "Loss:  -3.921567851070662\n",
      "Loss_orth:  0.00021163935358716916\n",
      "Loss_ML:  -3.921779490424249\n",
      "Logits:  tensor([0.0796, 0.4602, 0.0012, 0.0115, 0.2139, 0.0062, 0.0533, 0.1174, 0.0033,\n",
      "        0.0200, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.505 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  723000\n",
      "Loss:  -4.272476572102114\n",
      "Loss_orth:  0.0002860665412922112\n",
      "Loss_ML:  -4.272762638643407\n",
      "Logits:  tensor([0.0797, 0.4626, 0.0012, 0.0110, 0.2143, 0.0058, 0.0526, 0.1174, 0.0033,\n",
      "        0.0193, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 49.339 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  724000\n",
      "Loss:  -4.567240457513083\n",
      "Loss_orth:  0.00032726531317306504\n",
      "Loss_ML:  -4.567567722826256\n",
      "Logits:  tensor([0.0795, 0.4640, 0.0011, 0.0110, 0.2122, 0.0061, 0.0534, 0.1167, 0.0031,\n",
      "        0.0192, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.994 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  725000\n",
      "Loss:  -4.414883965519072\n",
      "Loss_orth:  0.000273216813443744\n",
      "Loss_ML:  -4.415157182332516\n",
      "Logits:  tensor([0.0804, 0.4622, 0.0011, 0.0110, 0.2132, 0.0060, 0.0532, 0.1171, 0.0032,\n",
      "        0.0196, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.828 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  726000\n",
      "Loss:  -4.112720007642996\n",
      "Loss_orth:  0.0004050990928607495\n",
      "Loss_ML:  -4.113125106735857\n",
      "Logits:  tensor([0.0797, 0.4636, 0.0012, 0.0110, 0.2133, 0.0061, 0.0533, 0.1159, 0.0032,\n",
      "        0.0195, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.806 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  727000\n",
      "Loss:  -4.210466455427411\n",
      "Loss_orth:  0.00030476133764321294\n",
      "Loss_ML:  -4.210771216765054\n",
      "Logits:  tensor([0.0796, 0.4620, 0.0011, 0.0110, 0.2124, 0.0061, 0.0533, 0.1175, 0.0032,\n",
      "        0.0200, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.887 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  728000\n",
      "Loss:  -4.583049148824882\n",
      "Loss_orth:  0.0003007347853590216\n",
      "Loss_ML:  -4.583349883610241\n",
      "Logits:  tensor([0.0811, 0.4598, 0.0012, 0.0111, 0.2115, 0.0063, 0.0543, 0.1182, 0.0032,\n",
      "        0.0197, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.744 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  729000\n",
      "Loss:  -4.430070947383651\n",
      "Loss_orth:  0.00036569943734290704\n",
      "Loss_ML:  -4.430436646820994\n",
      "Logits:  tensor([0.0782, 0.4649, 0.0011, 0.0111, 0.2132, 0.0059, 0.0521, 0.1171, 0.0032,\n",
      "        0.0196, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.246 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  730000\n",
      "Loss:  -4.431800075670009\n",
      "Loss_orth:  0.0005798416793587805\n",
      "Loss_ML:  -4.432379917349368\n",
      "Logits:  tensor([0.0797, 0.4646, 0.0011, 0.0111, 0.2136, 0.0058, 0.0527, 0.1163, 0.0031,\n",
      "        0.0196, 0.0324], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.657 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  731000\n",
      "Loss:  -4.665218673838925\n",
      "Loss_orth:  0.0006260618811576418\n",
      "Loss_ML:  -4.665844735720083\n",
      "Logits:  tensor([0.0802, 0.4597, 0.0011, 0.0113, 0.2139, 0.0061, 0.0541, 0.1167, 0.0033,\n",
      "        0.0201, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.503 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  732000\n",
      "Loss:  -4.626405326472768\n",
      "Loss_orth:  0.0006393902559222685\n",
      "Loss_ML:  -4.62704471672869\n",
      "Logits:  tensor([0.0789, 0.4638, 0.0011, 0.0110, 0.2139, 0.0059, 0.0538, 0.1159, 0.0030,\n",
      "        0.0194, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.975 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  733000\n",
      "Loss:  -4.396600386390062\n",
      "Loss_orth:  0.00026390203808929696\n",
      "Loss_ML:  -4.396864288428151\n",
      "Logits:  tensor([0.0784, 0.4639, 0.0011, 0.0112, 0.2141, 0.0060, 0.0531, 0.1168, 0.0029,\n",
      "        0.0196, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.606 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  734000\n",
      "Loss:  -4.16024509907093\n",
      "Loss_orth:  0.0004592685583647086\n",
      "Loss_ML:  -4.160704367629295\n",
      "Logits:  tensor([0.0792, 0.4653, 0.0011, 0.0110, 0.2134, 0.0057, 0.0530, 0.1158, 0.0030,\n",
      "        0.0196, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.237 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  735000\n",
      "Loss:  -4.322810845547256\n",
      "Loss_orth:  0.0005306164040293096\n",
      "Loss_ML:  -4.323341461951285\n",
      "Logits:  tensor([0.0801, 0.4606, 0.0012, 0.0115, 0.2128, 0.0063, 0.0541, 0.1168, 0.0031,\n",
      "        0.0197, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.614 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  736000\n",
      "Loss:  -4.509282600668039\n",
      "Loss_orth:  0.0007792607350986211\n",
      "Loss_ML:  -4.510061861403138\n",
      "Logits:  tensor([0.0797, 0.4631, 0.0012, 0.0114, 0.2114, 0.0065, 0.0530, 0.1172, 0.0033,\n",
      "        0.0196, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.298 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  737000\n",
      "Loss:  -4.231180067897311\n",
      "Loss_orth:  0.00046826034623943525\n",
      "Loss_ML:  -4.23164832824355\n",
      "Logits:  tensor([0.0791, 0.4647, 0.0012, 0.0114, 0.2133, 0.0063, 0.0535, 0.1148, 0.0033,\n",
      "        0.0196, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.746 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  738000\n",
      "Loss:  -4.584732354665108\n",
      "Loss_orth:  0.0003380833433139724\n",
      "Loss_ML:  -4.5850704380084215\n",
      "Logits:  tensor([0.0805, 0.4628, 0.0012, 0.0110, 0.2129, 0.0060, 0.0528, 0.1172, 0.0033,\n",
      "        0.0196, 0.0328], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.040 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  739000\n",
      "Loss:  -4.383200409566182\n",
      "Loss_orth:  0.0009494162582619644\n",
      "Loss_ML:  -4.384149825824444\n",
      "Logits:  tensor([0.0791, 0.4636, 0.0012, 0.0112, 0.2142, 0.0061, 0.0529, 0.1166, 0.0032,\n",
      "        0.0195, 0.0324], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.949 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  740000\n",
      "Loss:  -4.526779576563795\n",
      "Loss_orth:  0.00024290994941096982\n",
      "Loss_ML:  -4.527022486513206\n",
      "Logits:  tensor([0.0795, 0.4601, 0.0012, 0.0115, 0.2144, 0.0061, 0.0534, 0.1169, 0.0033,\n",
      "        0.0201, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.428 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  741000\n",
      "Loss:  -4.482168664600343\n",
      "Loss_orth:  0.0004945850235043804\n",
      "Loss_ML:  -4.482663249623847\n",
      "Logits:  tensor([0.0799, 0.4605, 0.0012, 0.0117, 0.2124, 0.0062, 0.0539, 0.1176, 0.0033,\n",
      "        0.0200, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.357 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  742000\n",
      "Loss:  -4.431913643742168\n",
      "Loss_orth:  0.0002692027209185453\n",
      "Loss_ML:  -4.432182846463086\n",
      "Logits:  tensor([0.0795, 0.4663, 0.0012, 0.0110, 0.2115, 0.0059, 0.0535, 0.1148, 0.0033,\n",
      "        0.0191, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.235 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  743000\n",
      "Loss:  -4.410916371504726\n",
      "Loss_orth:  0.00047427109788379565\n",
      "Loss_ML:  -4.41139064260261\n",
      "Logits:  tensor([0.0792, 0.4644, 0.0012, 0.0109, 0.2129, 0.0059, 0.0526, 0.1175, 0.0031,\n",
      "        0.0193, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.558 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  744000\n",
      "Loss:  -4.504381299631694\n",
      "Loss_orth:  0.00034738391191843767\n",
      "Loss_ML:  -4.504728683543613\n",
      "Logits:  tensor([0.0802, 0.4632, 0.0011, 0.0111, 0.2129, 0.0060, 0.0535, 0.1163, 0.0031,\n",
      "        0.0195, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.850 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  745000\n",
      "Loss:  -4.359552555127454\n",
      "Loss_orth:  0.000611765692192442\n",
      "Loss_ML:  -4.3601643208196466\n",
      "Logits:  tensor([0.0796, 0.4613, 0.0012, 0.0117, 0.2122, 0.0065, 0.0542, 0.1154, 0.0032,\n",
      "        0.0203, 0.0343], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.339 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  746000\n",
      "Loss:  -4.605658551392609\n",
      "Loss_orth:  0.0002962898497552168\n",
      "Loss_ML:  -4.605954841242364\n",
      "Logits:  tensor([0.0787, 0.4640, 0.0012, 0.0112, 0.2140, 0.0062, 0.0528, 0.1167, 0.0032,\n",
      "        0.0193, 0.0327], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.635 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  747000\n",
      "Loss:  -4.590876593126953\n",
      "Loss_orth:  0.000417189297472363\n",
      "Loss_ML:  -4.591293782424425\n",
      "Logits:  tensor([0.0801, 0.4601, 0.0012, 0.0115, 0.2138, 0.0063, 0.0528, 0.1177, 0.0032,\n",
      "        0.0198, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.937 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  748000\n",
      "Loss:  -4.550449638576408\n",
      "Loss_orth:  0.0005051299525428469\n",
      "Loss_ML:  -4.550954768528951\n",
      "Logits:  tensor([0.0798, 0.4635, 0.0012, 0.0112, 0.2123, 0.0059, 0.0531, 0.1165, 0.0031,\n",
      "        0.0198, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.771 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  749000\n",
      "Loss:  -4.396840498954529\n",
      "Loss_orth:  0.0009036167599621198\n",
      "Loss_ML:  -4.397744115714492\n",
      "Logits:  tensor([0.0800, 0.4595, 0.0013, 0.0113, 0.2134, 0.0062, 0.0537, 0.1175, 0.0033,\n",
      "        0.0202, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.030 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  750000\n",
      "Loss:  -4.267215033814805\n",
      "Loss_orth:  0.0008872650384511194\n",
      "Loss_ML:  -4.268102298853257\n",
      "Logits:  tensor([0.0807, 0.4598, 0.0012, 0.0113, 0.2131, 0.0061, 0.0536, 0.1180, 0.0033,\n",
      "        0.0195, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.551 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  751000\n",
      "Loss:  -4.334326603454409\n",
      "Loss_orth:  0.0006811648270376385\n",
      "Loss_ML:  -4.3350077682814465\n",
      "Logits:  tensor([0.0777, 0.4663, 0.0013, 0.0112, 0.2134, 0.0060, 0.0526, 0.1153, 0.0033,\n",
      "        0.0195, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.057 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  752000\n",
      "Loss:  -4.344084750009013\n",
      "Loss_orth:  0.0007327041043893337\n",
      "Loss_ML:  -4.344817454113402\n",
      "Logits:  tensor([0.0778, 0.4631, 0.0012, 0.0111, 0.2150, 0.0061, 0.0534, 0.1159, 0.0033,\n",
      "        0.0195, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.936 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  753000\n",
      "Loss:  -4.644170472524363\n",
      "Loss_orth:  0.0004254585301931836\n",
      "Loss_ML:  -4.644595931054556\n",
      "Logits:  tensor([0.0800, 0.4638, 0.0012, 0.0112, 0.2126, 0.0061, 0.0537, 0.1159, 0.0032,\n",
      "        0.0197, 0.0326], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.400 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  754000\n",
      "Loss:  -4.77436726854357\n",
      "Loss_orth:  0.0003790631970996697\n",
      "Loss_ML:  -4.77474633174067\n",
      "Logits:  tensor([0.0792, 0.4630, 0.0013, 0.0112, 0.2139, 0.0060, 0.0535, 0.1158, 0.0033,\n",
      "        0.0194, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.856 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  755000\n",
      "Loss:  -4.4202628388733745\n",
      "Loss_orth:  0.0002845896893931012\n",
      "Loss_ML:  -4.4205474285627675\n",
      "Logits:  tensor([0.0803, 0.4582, 0.0012, 0.0114, 0.2149, 0.0061, 0.0539, 0.1177, 0.0033,\n",
      "        0.0198, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.928 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  756000\n",
      "Loss:  -4.384412238816946\n",
      "Loss_orth:  0.0001966761130434827\n",
      "Loss_ML:  -4.38460891492999\n",
      "Logits:  tensor([0.0791, 0.4633, 0.0012, 0.0111, 0.2152, 0.0062, 0.0528, 0.1152, 0.0033,\n",
      "        0.0196, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.051 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  757000\n",
      "Loss:  -4.686402117897475\n",
      "Loss_orth:  0.0010189106853841143\n",
      "Loss_ML:  -4.687421028582859\n",
      "Logits:  tensor([0.0801, 0.4627, 0.0011, 0.0109, 0.2125, 0.0060, 0.0537, 0.1182, 0.0032,\n",
      "        0.0190, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 46.357 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  758000\n",
      "Loss:  -4.322178956443017\n",
      "Loss_orth:  0.0011124441027982636\n",
      "Loss_ML:  -4.323291400545815\n",
      "Logits:  tensor([0.0791, 0.4636, 0.0011, 0.0113, 0.2117, 0.0063, 0.0542, 0.1156, 0.0034,\n",
      "        0.0199, 0.0337], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.524 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  759000\n",
      "Loss:  -4.555229215365821\n",
      "Loss_orth:  0.00034245108420354785\n",
      "Loss_ML:  -4.5555716664500245\n",
      "Logits:  tensor([0.0797, 0.4613, 0.0011, 0.0111, 0.2136, 0.0060, 0.0532, 0.1175, 0.0035,\n",
      "        0.0199, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 45.237 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  760000\n",
      "Loss:  -4.530558294091818\n",
      "Loss_orth:  0.0009546949182853623\n",
      "Loss_ML:  -4.531512989010103\n",
      "Logits:  tensor([0.0804, 0.4606, 0.0011, 0.0117, 0.2123, 0.0062, 0.0535, 0.1176, 0.0033,\n",
      "        0.0199, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.295 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  761000\n",
      "Loss:  -4.653295922555544\n",
      "Loss_orth:  0.00043537150816543734\n",
      "Loss_ML:  -4.653731294063709\n",
      "Logits:  tensor([0.0796, 0.4612, 0.0010, 0.0111, 0.2123, 0.0060, 0.0534, 0.1199, 0.0033,\n",
      "        0.0195, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.360 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  762000\n",
      "Loss:  -4.8154872029304885\n",
      "Loss_orth:  0.0003535504407521208\n",
      "Loss_ML:  -4.815840753371241\n",
      "Logits:  tensor([0.0807, 0.4624, 0.0011, 0.0113, 0.2120, 0.0061, 0.0533, 0.1164, 0.0031,\n",
      "        0.0198, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.703 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  763000\n",
      "Loss:  -4.44632738493342\n",
      "Loss_orth:  0.00038673218426195377\n",
      "Loss_ML:  -4.446714117117683\n",
      "Logits:  tensor([0.0800, 0.4596, 0.0011, 0.0114, 0.2162, 0.0058, 0.0536, 0.1167, 0.0031,\n",
      "        0.0195, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 43.180 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  764000\n",
      "Loss:  -4.450786252677725\n",
      "Loss_orth:  0.0007923228566200228\n",
      "Loss_ML:  -4.451578575534345\n",
      "Logits:  tensor([0.0789, 0.4604, 0.0011, 0.0112, 0.2158, 0.0058, 0.0532, 0.1173, 0.0032,\n",
      "        0.0201, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 44.722 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  765000\n",
      "Loss:  -4.345384283353106\n",
      "Loss_orth:  0.0006736177503021992\n",
      "Loss_ML:  -4.346057901103408\n",
      "Logits:  tensor([0.0801, 0.4618, 0.0011, 0.0107, 0.2131, 0.0059, 0.0544, 0.1169, 0.0031,\n",
      "        0.0192, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 51.414 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  766000\n",
      "Loss:  -4.406171906994982\n",
      "Loss_orth:  0.0007511936067139405\n",
      "Loss_ML:  -4.406923100601696\n",
      "Logits:  tensor([0.0795, 0.4625, 0.0011, 0.0107, 0.2133, 0.0059, 0.0532, 0.1176, 0.0030,\n",
      "        0.0195, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 48.259 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  767000\n",
      "Loss:  -4.130446858490572\n",
      "Loss_orth:  0.0005844993802002367\n",
      "Loss_ML:  -4.131031357870772\n",
      "Logits:  tensor([0.0807, 0.4617, 0.0011, 0.0108, 0.2127, 0.0060, 0.0533, 0.1180, 0.0031,\n",
      "        0.0194, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.735 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  768000\n",
      "Loss:  -4.551004940907777\n",
      "Loss_orth:  0.0006261043137084091\n",
      "Loss_ML:  -4.551631045221486\n",
      "Logits:  tensor([0.0804, 0.4621, 0.0011, 0.0113, 0.2119, 0.0062, 0.0534, 0.1175, 0.0032,\n",
      "        0.0198, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 47.582 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  769000\n",
      "Loss:  -4.652724003908834\n",
      "Loss_orth:  0.00042719266853004855\n",
      "Loss_ML:  -4.653151196577364\n",
      "Logits:  tensor([0.0801, 0.4606, 0.0011, 0.0112, 0.2132, 0.0061, 0.0541, 0.1169, 0.0032,\n",
      "        0.0198, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.054 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  770000\n",
      "Loss:  -4.794575824541926\n",
      "Loss_orth:  0.0006909717732673092\n",
      "Loss_ML:  -4.795266796315194\n",
      "Logits:  tensor([0.0796, 0.4605, 0.0011, 0.0109, 0.2145, 0.0062, 0.0532, 0.1173, 0.0033,\n",
      "        0.0199, 0.0336], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.740 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  771000\n",
      "Loss:  -4.397155839249303\n",
      "Loss_orth:  0.0005629702392899676\n",
      "Loss_ML:  -4.397718809488593\n",
      "Logits:  tensor([0.0793, 0.4618, 0.0011, 0.0110, 0.2159, 0.0062, 0.0533, 0.1166, 0.0033,\n",
      "        0.0191, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 41.471 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  772000\n",
      "Loss:  -4.453023094017359\n",
      "Loss_orth:  0.0006555302776390929\n",
      "Loss_ML:  -4.453678624294998\n",
      "Logits:  tensor([0.0796, 0.4631, 0.0011, 0.0111, 0.2137, 0.0061, 0.0525, 0.1172, 0.0033,\n",
      "        0.0193, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 41.237 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  773000\n",
      "Loss:  -4.432342451812038\n",
      "Loss_orth:  0.0005292607960215094\n",
      "Loss_ML:  -4.432871712608059\n",
      "Logits:  tensor([0.0792, 0.4642, 0.0011, 0.0114, 0.2133, 0.0061, 0.0530, 0.1157, 0.0033,\n",
      "        0.0194, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 42.311 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  774000\n",
      "Loss:  -4.23756579207264\n",
      "Loss_orth:  0.0005202773223609929\n",
      "Loss_ML:  -4.238086069395002\n",
      "Logits:  tensor([0.0803, 0.4604, 0.0010, 0.0107, 0.2150, 0.0059, 0.0539, 0.1178, 0.0032,\n",
      "        0.0189, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 41.550 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  775000\n",
      "Loss:  -4.522166458552119\n",
      "Loss_orth:  0.0004203957692522435\n",
      "Loss_ML:  -4.522586854321371\n",
      "Logits:  tensor([0.0797, 0.4585, 0.0011, 0.0114, 0.2135, 0.0061, 0.0547, 0.1180, 0.0031,\n",
      "        0.0199, 0.0340], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 41.299 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  776000\n",
      "Loss:  -4.5284445488169265\n",
      "Loss_orth:  0.00047135154626972727\n",
      "Loss_ML:  -4.528915900363196\n",
      "Logits:  tensor([0.0807, 0.4598, 0.0010, 0.0112, 0.2134, 0.0062, 0.0538, 0.1177, 0.0030,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 41.941 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  777000\n",
      "Loss:  -4.4486905209259975\n",
      "Loss_orth:  0.0005362764206051656\n",
      "Loss_ML:  -4.449226797346602\n",
      "Logits:  tensor([0.0799, 0.4611, 0.0010, 0.0112, 0.2153, 0.0061, 0.0533, 0.1166, 0.0030,\n",
      "        0.0194, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 41.836 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  778000\n",
      "Loss:  -4.291198697771475\n",
      "Loss_orth:  0.000258679777281362\n",
      "Loss_ML:  -4.291457377548756\n",
      "Logits:  tensor([0.0808, 0.4614, 0.0010, 0.0116, 0.2122, 0.0061, 0.0535, 0.1175, 0.0031,\n",
      "        0.0196, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 41.687 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  779000\n",
      "Loss:  -4.467986910574433\n",
      "Loss_orth:  0.00035996587571166016\n",
      "Loss_ML:  -4.468346876450145\n",
      "Logits:  tensor([0.0802, 0.4635, 0.0010, 0.0110, 0.2141, 0.0060, 0.0530, 0.1157, 0.0030,\n",
      "        0.0193, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 39.442 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  780000\n",
      "Loss:  -4.715845390787725\n",
      "Loss_orth:  0.00043994536748047386\n",
      "Loss_ML:  -4.716285336155205\n",
      "Logits:  tensor([0.0811, 0.4601, 0.0010, 0.0113, 0.2121, 0.0062, 0.0541, 0.1166, 0.0032,\n",
      "        0.0200, 0.0343], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 38.517 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  781000\n",
      "Loss:  -4.631223491767551\n",
      "Loss_orth:  0.0003132570988940975\n",
      "Loss_ML:  -4.631536748866446\n",
      "Logits:  tensor([0.0793, 0.4618, 0.0010, 0.0115, 0.2131, 0.0061, 0.0531, 0.1176, 0.0031,\n",
      "        0.0200, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 38.026 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number  782000\n",
      "Loss:  -4.527871820690556\n",
      "Loss_orth:  0.00036354861239156936\n",
      "Loss_ML:  -4.528235369302947\n",
      "Logits:  tensor([0.0794, 0.4633, 0.0011, 0.0112, 0.2130, 0.0060, 0.0528, 0.1169, 0.0030,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 41.611 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  783000\n",
      "Loss:  -4.489595433118697\n",
      "Loss_orth:  0.0004937602622866841\n",
      "Loss_ML:  -4.4900891933809834\n",
      "Logits:  tensor([0.0794, 0.4606, 0.0011, 0.0116, 0.2131, 0.0061, 0.0538, 0.1177, 0.0031,\n",
      "        0.0200, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 40.466 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  784000\n",
      "Loss:  -4.596829935032184\n",
      "Loss_orth:  0.0007835726738437725\n",
      "Loss_ML:  -4.597613507706027\n",
      "Logits:  tensor([0.0788, 0.4634, 0.0012, 0.0114, 0.2128, 0.0061, 0.0539, 0.1166, 0.0030,\n",
      "        0.0196, 0.0333], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 40.546 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  785000\n",
      "Loss:  -4.4364278362577725\n",
      "Loss_orth:  0.0008329153304795872\n",
      "Loss_ML:  -4.437260751588252\n",
      "Logits:  tensor([0.0789, 0.4631, 0.0011, 0.0113, 0.2122, 0.0062, 0.0544, 0.1160, 0.0031,\n",
      "        0.0198, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 40.368 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  786000\n",
      "Loss:  -4.619819969678049\n",
      "Loss_orth:  0.0004166949732785548\n",
      "Loss_ML:  -4.620236664651327\n",
      "Logits:  tensor([0.0802, 0.4586, 0.0012, 0.0111, 0.2137, 0.0063, 0.0532, 0.1186, 0.0032,\n",
      "        0.0200, 0.0339], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 39.962 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  787000\n",
      "Loss:  -4.611500365378277\n",
      "Loss_orth:  0.00040822699152626157\n",
      "Loss_ML:  -4.6119085923698036\n",
      "Logits:  tensor([0.0808, 0.4612, 0.0013, 0.0113, 0.2119, 0.0059, 0.0531, 0.1177, 0.0031,\n",
      "        0.0197, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 40.153 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  788000\n",
      "Loss:  -4.540037718916965\n",
      "Loss_orth:  0.0004776772820160398\n",
      "Loss_ML:  -4.540515396198981\n",
      "Logits:  tensor([0.0804, 0.4623, 0.0011, 0.0111, 0.2118, 0.0061, 0.0534, 0.1174, 0.0032,\n",
      "        0.0194, 0.0338], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 39.856 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  789000\n",
      "Loss:  -4.34095951171645\n",
      "Loss_orth:  0.0004349277871590657\n",
      "Loss_ML:  -4.34139443950361\n",
      "Logits:  tensor([0.0783, 0.4657, 0.0012, 0.0109, 0.2133, 0.0058, 0.0524, 0.1162, 0.0033,\n",
      "        0.0199, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 39.681 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  790000\n",
      "Loss:  -4.291559681711062\n",
      "Loss_orth:  0.0005621976834069864\n",
      "Loss_ML:  -4.292121879394469\n",
      "Logits:  tensor([0.0799, 0.4627, 0.0012, 0.0115, 0.2139, 0.0058, 0.0530, 0.1171, 0.0033,\n",
      "        0.0191, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 41.151 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  791000\n",
      "Loss:  -4.468854009493678\n",
      "Loss_orth:  0.0005570561537323275\n",
      "Loss_ML:  -4.46941106564741\n",
      "Logits:  tensor([0.0787, 0.4676, 0.0012, 0.0110, 0.2108, 0.0057, 0.0532, 0.1162, 0.0031,\n",
      "        0.0195, 0.0330], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 40.105 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  792000\n",
      "Loss:  -4.0108346671803705\n",
      "Loss_orth:  0.00028195840812259644\n",
      "Loss_ML:  -4.011116625588493\n",
      "Logits:  tensor([0.0794, 0.4617, 0.0012, 0.0110, 0.2135, 0.0061, 0.0534, 0.1173, 0.0030,\n",
      "        0.0202, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 41.477 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  793000\n",
      "Loss:  -4.58246197005867\n",
      "Loss_orth:  0.0005301519599194278\n",
      "Loss_ML:  -4.58299212201859\n",
      "Logits:  tensor([0.0802, 0.4620, 0.0013, 0.0114, 0.2121, 0.0062, 0.0539, 0.1169, 0.0031,\n",
      "        0.0199, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 41.198 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  794000\n",
      "Loss:  -4.354161897606772\n",
      "Loss_orth:  0.0003894078720015477\n",
      "Loss_ML:  -4.354551305478774\n",
      "Logits:  tensor([0.0804, 0.4622, 0.0014, 0.0118, 0.2127, 0.0063, 0.0535, 0.1157, 0.0031,\n",
      "        0.0196, 0.0334], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 41.037 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  795000\n",
      "Loss:  -4.15135996652729\n",
      "Loss_orth:  0.000517980623645561\n",
      "Loss_ML:  -4.151877947150935\n",
      "Logits:  tensor([0.0795, 0.4628, 0.0014, 0.0112, 0.2134, 0.0061, 0.0537, 0.1163, 0.0031,\n",
      "        0.0194, 0.0332], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 40.169 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  796000\n",
      "Loss:  -4.382876553118896\n",
      "Loss_orth:  0.0004908714378486711\n",
      "Loss_ML:  -4.383367424556745\n",
      "Logits:  tensor([0.0802, 0.4618, 0.0013, 0.0107, 0.2147, 0.0059, 0.0531, 0.1177, 0.0031,\n",
      "        0.0192, 0.0325], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 40.410 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  797000\n",
      "Loss:  -4.635473335956249\n",
      "Loss_orth:  0.0003650914435291698\n",
      "Loss_ML:  -4.635838427399778\n",
      "Logits:  tensor([0.0805, 0.4615, 0.0012, 0.0108, 0.2131, 0.0059, 0.0540, 0.1168, 0.0030,\n",
      "        0.0197, 0.0335], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 40.871 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  798000\n",
      "Loss:  -4.2720506801701426\n",
      "Loss_orth:  0.00025494536911551264\n",
      "Loss_ML:  -4.272305625539258\n",
      "Logits:  tensor([0.0796, 0.4626, 0.0012, 0.0110, 0.2132, 0.0059, 0.0531, 0.1175, 0.0029,\n",
      "        0.0198, 0.0331], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 40.907 seconds\n",
      "@----------------------------------------------------------@\n",
      "Batch number  799000\n",
      "Loss:  -4.390932035647856\n",
      "Loss_orth:  0.00039200434539436876\n",
      "Loss_ML:  -4.39132403999325\n",
      "Logits:  tensor([0.0799, 0.4634, 0.0012, 0.0112, 0.2135, 0.0059, 0.0528, 0.1174, 0.0029,\n",
      "        0.0188, 0.0329], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "Time taken: 40.640 seconds\n",
      "@----------------------------------------------------------@\n"
     ]
    }
   ],
   "source": [
    "n_EL = 10\n",
    "n_Hm = 10\n",
    "\n",
    "epochs = 800000\n",
    "qml_AHO_HM = QML(n_EL, n_Hm+1)\n",
    "\n",
    "[loss_hist, loss_ML_hist, loss_orth_hist, levels_hist, logits_hist, var_HC_N, fl_coeff, levels_fin, logits_fin] = \\\n",
    "            main_train_states_QML(qml_AHO_HM, x, y, 500, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scl489/.env/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(epochs), loss_hist)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "plt.plot(np.arange(epochs), np.log(loss_ML_hist - np.amin(loss_ML_hist)))\n",
    "plt.title(\"Log Loss_ML\")\n",
    "plt.show()\n",
    "plt.plot(np.arange(epochs), loss_orth_hist)\n",
    "plt.title(\"Loss_orth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_np(coeff, x, latt_pt):\n",
    "    coeff = coeff.reshape([-1,1])\n",
    "    x = x.reshape([-1,1]) \n",
    "    latt_pt = latt_pt.reshape([1, -1])\n",
    "    a = x - latt_pt\n",
    "    z = np.tanh(a)\n",
    "    z = np.matmul(z, coeff)\n",
    "    z = z.reshape(-1,)\n",
    "    \n",
    "    det_x = np.matmul(1/(np.cosh(a)**2), coeff)\n",
    "    \n",
    "    return z, det_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square integrated over the region: 1.000000000000022\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square integrated over the region: 1.0000000000000222\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square integrated over the region: 1.0000000000000233\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square integrated over the region: 1.0000000000000226\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square integrated over the region: 1.0000000000000226\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square integrated over the region: 1.0000000000000215\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square integrated over the region: 1.000000000000023\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square integrated over the region: 1.0000000000000244\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square integrated over the region: 1.000000000000024\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square integrated over the region: 1.0000000000000202\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square integrated over the region: 1.000000000000025\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(-10, 10 , 0.01)\n",
    "n_latt_spacing = 400\n",
    "latt_pt = np.linspace(-10, 10, num = n_latt_spacing+1)\n",
    "[z, det_x] = flow_np(fl_coeff, x, latt_pt)\n",
    "\n",
    "Y = np.sqrt(det_x) * HM(n_Hm, z)\n",
    "\n",
    "SUP = np.matmul(Y, var_HC_N)\n",
    "\n",
    "for i in range(n_EL+1):\n",
    "    plt.plot(x, SUP[:, i])\n",
    "    plt.title(\"Level \" + str(i))\n",
    "    plt.show()\n",
    "    print(\"Square integrated over the region: \" + str(np.sum(SUP[:, i] * SUP[:, i]) * 0.01)) #check wavefunction normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scl489/.env/lib/python3.7/site-packages/IPython/core/pylabtools.py:132: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEECAYAAADj+mWwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAACDmUlEQVR4nO2dZXhURxeA39W4Ew8hSCC4u7vVaAulLdWvQqkbpdSoUaBUqQM1KlCgQgvFvbgTPIEQd89m/X4/brLJEg8JJDDv8/Cwd+7cmXM3u2fPPXPmHIUkSRICgUAgaBQor7YAAoFAIKg+QmkLBAJBI0IobYFAIGhECKUtEAgEjQihtAUCgaARIZS2QCAQNCLUV1sAwfVDmzZtCA0NRaVS2bXPmzePTp06XSWp7Lnnnnu4/fbbufnmm+t03GHDhjFv3jx69OhRp+MKrj+E0hZcUZYsWUJAQMDVFkMgaLQI94igQRAfH8+AAQP48ccfufHGGxk4cCBr1qwBQJIkPvvsM0aPHs3QoUN55513sFgsgGwZf/TRR4wdO5ZDhw4RHx/PLbfcwrBhw3j99dd59NFH+f3333nqqadYvHixbb6zZ8/Sp08fzGZzhTIdPHiQ2267jZEjRzJp0iTi4uLIzc2lU6dOZGZm2vq9++67zJ8/v1I5izGbzbzyyiuMHj2akSNH8sQTT5Cfn1+Xb6XgGkcobUGDISsrC6VSyd9//83MmTP5+OOPAfjrr79Yu3YtK1asYMOGDcTFxfHrr7/arouMjGT16tV069aNefPm0b9/fzZv3sygQYPYtWsXADfccAP//POP7ZoNGzYwatQo1OryHzbz8/N57LHHeO6559iwYQP33nsvTz/9NO7u7vTu3ZstW7bY+m7atImxY8dWKSfAzp07iY+PZ+3ataxfv55WrVpx+PDhunoLBdcBQmkLrij33HMPY8aMsf276667bOfMZjO33norAO3btycxMRGALVu2cNttt+Hm5oZarWbixImsX7/edt3gwYNRKuWP8oEDB7jhhhsAGDFiBH5+frY+sbGxnD9/HoCNGzcybty4CuU8ePAg/v7+9O/fH5CVfmxsLImJiYwePZrNmzcDcOLECdRqNe3bt69STgBvb2+io6PZsGEDhYWFPPPMMwwcOLD2b6jgukP4tAVXlMp82iqVCmdnZwCUSiVWqxWAvLw8Fi9ezLJlywCwWCx4e3vbrvPw8LC9zs3NtTv29/cHwMHBgZEjR/LPP/9w++23k5aWRq9evSqUMzc3l7i4OMaMGWNr02q1ZGZmMmLECObMmYPBYGDjxo2MHTu2WnICdOrUiVdffZUlS5bw0ksvMWzYMN544w3c3d2reOcEAhmhtAUNHj8/P4YNG8aUKVOq7Ovi4oJOp7Mdp6Wl2V6PHz+e9957Dzc3N0aPHm2zziuas0WLFvz+++/lnu/UqRO7d+9m48aNvP/++zWSs/gpIzs7m5kzZ7J48WKeffbZKu9NIADhHhE0AoYPH85ff/1FYWEhAEuXLuWPP/4ot2+nTp34999/AdmtkpqaajvXr18/srOzWbJkic06rojOnTuTlpbG0aNHAYiLi+PFF1+kOCnm6NGj+e233zCZTERERFRbzpUrV/L5558D4OnpSYsWLWr0XggEwtIWXFHuueeeMnHaU6ZMYciQIRVeM2LECM6dO8eECRMACA0N5d133y2374svvsjzzz/P6tWrGTRoEF26dEGhUACy+2XMmDFs2rSJ7t27Vyqno6Mjn376KW+//TYFBQVoNBqefvpp21gjR47kzTff5JFHHqmRnMOHD2fmzJmMGjUKlUpFs2bNmDNnTqWyCASlUYh82oJrDUmSbMr1tttu47HHHmPEiBEALFy4kKysLKZPn341RRQIao1wjwiuKebOncubb74JQHR0NOfPn6dDhw4AZGZm8ttvv3HnnXdeTREFgstCWNqCa4rU1FSmT59OQkICSqWSqVOnMmHCBJYuXcrXX3/NY489xqRJk662mAJBrRFKWyAQCBoRwj0iEAgEjYh6iR7R6/VERkbi6+tbJlJAIBAIBOVjsVhIS0ujQ4cOODo6ltunXpR2ZGQkd999d30MLRAIBNc8P//8c4VpfOtFafv6+tomFmk4BQKBoHokJydz991323RoedSL0i52iQQEBBASElIfUwgEAsE1S2VuZbEQKRAIBI0IobQFAoGgESGUtkAgEDQihNIWCASCRoRQ2gKBQNCIEEpbIBAIGhFCaV9HDP9gK2EzVrNsf2yFfXIKTYTNWE3YjNX8ezwJi1WkphEIqmL27NnccccdTJ48mWPHjtXrXKIIwnVCap6e6LQCAF5aeZxxHQNxc9SU6df5zZJCtI/9fMju3OHXRuLlogXknNXRaQWEeDmhUSlRKRX1KL1A0HDZt28fFy9eZNmyZURHRzNz5kxbndD6QFjataDX7pPszym42mJUG7PFSq93N9m1dZy1vky/X/dVbIEDdH17AyaLlaX7Ymn+8hpGfLiNiNfW0nLmmjJ9RfJIwfXC7t27bUU2WrZsSU5ODvn5+fU2n7C0q8ELp+OYHOhNDw8X/k3LJlZv5MZD59jcpgXeLloCPEoSu/y05yKv/hkJwPnZ4yg0WdgXk8nQNn5XVOZcvYlOs9bTM8yL/TFZ5fYJm7GameMieGRQSxbtOM87q09VOW74K/9WOFYxrfxciUqVP7Qxc8bXQnqBoHasPBjPbwfi6nTMST2aclv3ind2p6en0759e9uxt7c3aWlpuLq61qkcxQilXQUBW44A8FNSBl+0a8a0kxdt58Z9ugOA1v6uLH2kL93e3mB3bYtSFui7Ezpwd+9mAFitEvFZhYT6ONdIFqtVIr3AgJ+b/CNhNFuJySgg3M+Vp5cewdtFy6yb5A9PpyJLurTCnnNrR27pGkzEa2ttbbPXnGb2mtN28xybNYqsAiOD398KwJj2Aaw9kVxtOYsVNsjK/NRbY3DSqmwy37VwDx9M6gxAqLezrTSYQHAtUN9PmUJpV0Kxwi6mtMLGZLW9PJuSX0ZhX8orf0Tyyh+Rdm1tA9359+mB1ZLFapVsPwI7pg8l0MOR1q+WtXq/3xVT7vV/TOtH11AvAO7vF1ZhPwB3Rw3ujpoyVnJpaxrkH6t/nhxYrhylafv6Wk6/PQaNSmnrW/yDAPDl3d0Y2zGw0jEEgupwW/eQSq3i+sDPz4/09HTbcWpqaqUJny4XobQvIV5vxEGpoON/Jyrtp92TetlznUrK5bGfDvLlFPvK4GdT8jiZmMstXYMBsFglO7/xwHlbajxXscIGeOPGdvi5OxDu58bDPx6wte+YPpSm3hVb/6ffHsOiHed5bEgru4XHYuUuSRJbz6Th7qThti932V1b2rq/lMd+PsRfj/enc1PPmt6WQHDV6d+/PwsWLGDy5MmcOHECPz+/enONgFDadjx7OpZfkzLLtP/SqQV3HTsPgCo6D01Uru2csZMX9zm58eteeRFvUGtffnigJ2dS8hjz8Y4q5/w3UnY7fLzxLB9vPIeLVkWB0QLAwYtZtAty5+Xfj9fqfg69NpI95zPKKEOFQsG0Ia0A2DdzOL1mb8JJo6pUYQM4alQ8MSy8wvMKhYKhEbLvvliRX2qdF9PMx5mLGTrb8c2f/8cPD/ZicOv6s1AEgvqgW7dutG/fnsmTJ6NQKHjjjTfqdb5q1Yg8e/Ys06ZN4/7772fKlCkkJSUxffp0LBYLvr6+vP/++2i1Wlv/+Ph4hg8fzqZNmxpNatYEvZHuu0+Wad/Vuy0tnB0ASMwupN+czXbn9aOCuNnXk3U/n+TlsRE8Oril7Vy2zsibf5/kozu6yHNkF9K/6Pod04fWymIuzQujWtsp0Y83nmXh9vM2pd9QFgEvVdz7XhmOn5tjuQr98GsjOZWUS79WTQDQmyysP5nCoPAmeDpry/QXCK4lqqM7q1TaOp2ORx99lLCwMNq0acOUKVN4+eWXGTRoEGPHjuXDDz8kICCAu+66q0YTNzQu9V8DvNEyiMdCS6I+LlUyH97TjWmpKQDED+6MupqxypIkoVAo+GD9GRZsjqq2jEffGEVSTiFjPt7B8Vmjyo2zBnmxz2y14qxtGA9SRrPV5ste8r9eDAyXrWmTxYrZIrH9XBqPLjlod82apwbaFnqLqepHKC5TRxNXB9ui59VkV3Q6PZp5o1WLqFpB9amO7qzyE6XValm4cCF+fiXKa+/evQwfPhyAoUOHsnv37joS+eqzqH0YyUO7cKJ/BzuFveFkil2/mDnjubV9yeJZyLaj1Z6jOFri+VFtypz75p7u/DdjGL892tfW9uvDfYiZMx4PJw0RAe7EzBlfocIG0KqVDUZhA3aKq1hhA2hUSpy0Kka3D+Du3qF211yqsAEy8g2EzVhNap7ert1otpJvMDNw3hbavl6x7xxg/Ylk245PvUl+IrFYJf73/X4Ox5YfGlkRkiSRozNxKimX1Dw9t3z+H1vOpPL+utPctXAvrV/91zZX2IzV5BvMlY5XaLSQmivfW4HBjLUB7UZdcTCe/TFlXYeCK0+V32y1Wo1abd+tsLDQ5g7x8fEhLS2tfqS7QugtJZEgN/h5AuBTpPTOpeQx8qPtdv3fuaVDueNcLDSwNTOP+4KbVHvu02+PYfnBeL7deYH1zw5Co5IVXLCnE+dnjyMmo4AWvvW3qHGlqMpKfnF0G37eW/nmnu7vbAQos1HoUoqfiFr4unA+rQBfNwf2vzKCV/44bjdHxGtrWf/sIEYV/X03nS5ZXF71RH86hXhWOIfJYi03Zv2B7/ZXeE2HN9ZVGJHzz5MDuGHBzjLX+LhoOfjayArHvFK8sFw2Sir7O1qsEnl6k3Bj1TOXbY5dCzvfHjkRU+G5SxX29w/0ZEipjTKH+rajW5EvvPceeXPKBH8v3NXVe0R31Ki4p08z7unTrMw5pVJxTSjs6uDprOXCe+NYvPMC89efQV8UUll6YbamnC/atp+WZ0CSpHJ/FEZd8vct5qbP/gMgIsCN8R0D+WDDWRbc2ZUbOgWiUCgq3GRUFW//c5I7ezWllZ8bu6JKwsTKU9gAGQVGFu04z0MDW9RqvsuhvDWHsBmrbYpbb7JUGBV0bNYo3Ct5GqwJ+QYzzhoVSpEqAajlNnZnZ2f0evkxLiUlxc510hhZnyFHg6zv0dquveMb68r0HXLJzsYgRy0L24fZtcXrjXUr4HWCQqHgoYEt2D1jOA8NaE707HGceGsMx2aNuuyxm79cEjK586Wh1b7udHIeH2w4C8CTvx6m+ctrKoyIKc2Xd3ezvd73ynDb68U7LzDiw+089tNB7lq0t1oyVGenanXRGc0cvJjF8fgcwmasZsmei2X6rDqaWOk9Tl8hW92VhXF2mrWebWdr9wS+bH+snQurwxvraDFzDbl6U63Gq0sSsgttsl0tamVp9+vXj3Xr1nHzzTezfv16Bg6s3gaRhk4nt5KQt/Np+eSV8kGO7RDA+xM7l3vdjX6eUCqse1tmHu1cnepLzGseLxctr97QznZcnsW25YUhNG/iwp7zGeTpzYxs5287N3/dGbqGevLssiP0CPNm82n7mPoQL2dWPzWA8Z+WWLcX3htHVGo+u6IzaBfkzsSvql6nCfFyYudLw8q0J+UUEujhZOdKGB7hZ+d+KQ71vJTiBeZLlcKZ5Dya+TgzbP5WfpvalxCvmu2mLabd6/aGyGt/RvLV1mj+mzGM08m5vLfmdJXK9rcD8aw7kVJpH4D7vt0HgIeThu7NvHhpTASujmqCPSv+bqw5nsRLK0tCXEv/MHSatf6KRUSN+mgbZ1PyWflYP7o3k/c4lImCupBJr+beV0Se0lQZPRIZGcncuXNJSEhArVbj7+/P/PnzmTFjBgaDgaCgIN577z00mpIvVmOKHllwMYV3zycBkDy0CyC7fEpbZrtfHkagR9VKOM1ostuUkzSks9ii3QDYHZ3BnQv3AHBT5yA+vbMrAAs2naN9sDvDIvzLve7zLVG8v+4MAIEejiTl2C+Anp89rtqP7DqjuYzCLOa7+3vywPf7y91gVJlF5+6oJldv5pkR4TwzonW5fVYejGfHuTRm3dSetZHJzKhhzP+6ZwYx+uPt5UbzFNM11JPOIZ58vyuGYE8n/n5yQKU7hEsrwmKqG0nVwteFTc8N5r1/TzOxewjRaQWM6RBQrXspNFp4/a9IZt/a0bZ2dCmXfveLKX4fLqX4R+TSsOjaUichf/U1cUOhONSvk6sT63vK0RylvyhrnhpIuyD3Go8H8FW7ZtziL38434hK4Ou4NM4M6ICHpuFEdlwv/HUkgaeXHuHsO2NrFIb33LIj/H44QY4W+uI/DsVmA7WLgQ+bsZrmTVwI8nTkv6gMABbd24MR7cr/0YDKlX1pypOnqkf4n/7XmymLK3bRlE7FC/DM0sP8eSSxWnO3fuVfjKUW+Cu75oXlR1lxMN7u/JxbO9r9wKiUigpzuy97pA+9W/iwPyaTLk09bQpZkiR6vruJ9HxDmWvOvTsWqyQx5uMdLJ/alyau8l6Mmro9nhoezqfrIumX9DstWzS3hUXXFqG0qyAyT8eIA7K/MmFIZ1QKRZlf2pp+OS+N904c0hmlQmHX3tfThd3ZBTbLXnD98f6603y+Jbpan6+Xfz9eZdrcYt66uT339g2rVPmcfGs0KqUCB7WKveczuOObPbZzE7uHMO/2TpU+Iabm6olMzCHMx6XKhfK7Fu5hV3RGmfbHhrSkuY8L01eWXzAgZs54W76dz+/qxvhOgdVWqFteGMLQ+Vur1beY87PHoVDYr318fU/3MvsHOgZ78PeTA+xlsVpAsvBc0zi8vb2F0q5PSivSYgVaOrVqbawpiyTRZsdx8iuxMoqZ0TyAZ8Kq92gnuL75aMNZPtl0jo7BHnx9T/cyO3NrwqWfa0mSiErNx81RY5dmuK74YVcM7k5qJnQNqVTxls4mWd53Ly5TV+Uu4luV25mk3nZ5AgN9mvvYXq/VjmDq8dZ2cs359zRfbYu2u0Z1ai2S1oU3np3Kff3CajVvdXTndfuc/unFkoWUw/1KFr2KFfadvULLXFMdVAoFUYM68VDkBf5Jy6m075wLySxJzCDBIK+KPxDchHfCg1EJP7jgEp4d2ZoH+zfHw1leO4qZM57kHD0/7I7hy63RFV6386WhhHg5Y7VKJOYUlhtDrVAoCPd3qzfZSyuw5VP7lrvIe+G9cVgluRDHxB7lK6um3s48N7I1HxZF8wB8OKkzz/1W+ca2Ps19sBbZpgoF7L1Q+SYhZ419uO6Y9gHE3G3/IzJjbASHY7PKHeuNVSdQqxS2VMx1zXVraRdb2eOaeNA20YBWpWLDqWQiE+Twv6h3x6KuYLGipnPUBuE6EVSXsBmrCXB3ZOdLQ2lVKn78wnvjGuRCuCRJrDgYT1NvZzqFeOCkUdVIzs+3RPFg/+a2dAVWq4TRYsVRo7Kz5O/vF8ZdvUNpXc4PUnEqidIpj4tZMbUvPcKqjgopzr55c5cg/jqSaLO0rS3laLraPKkLS7sa9MywMHeLvaXi46K9bIUNcHFwJ5ptO8bx/u3x1WrIN1toteM4Q73d+F+IL1OKMgeWR8CWI3Rxc+b2AC8eChGZ7wQVU1o5FEd5bHlhSINU2CBb9hN7NK319Y8PbWV3rFQqcFTKCnztMwP5cfdFZk/oWKUMxdcWv38Wq8Se8xnVUtggL44WX+vn5sC3pcLpf5/Wr1pj1IbrUmkXWCwogOdC/Zm78FCZ83W1bdhBqbSzmF3VKruwQoB3woNtSvlSy/xIno4jeTpePZcgLG9BtWgX5N5gsjteDSIC3KtU2BWhUiro36r6KSiKiYyM5NSvc1DFRiEpVPR3TKCFe/9ayVAdrkulHaWTtzV/Xo7CvlIoFIoyijh5aBcmH4lma1Zemf4BW47Q1c2Zf3u0psBswaWa2+QFAkH90qFDB3766SfMFitKhaLet9tfl0r7bIEeZXpJ7OaAVk346aHeV1GiEn7s1Jw3ohJp7eLIy2ftY1cP5+louf0YBUWRKRt6tKajW+12xgkEgrqlLlyq1eG6TPY790IS2kMlsaNL/tfrKkpjj1ap5L3WITwQ3KRcl0hBqVDCkQfO2lbFi4nW6QnYcgRTA0rrKRAI6o7rztKWJIn0v2Jsx5ufH9xgF2xA3gr/Z2o2PySksyenoMz5oK1yuFM/T1d2ZZdUQW+67ajwgwsE1yDXnaU96Wv7GNGGnvpUoVAwwd+LP7uFc6RfewA6uDrhfslW7NIKu5jnT1dvF51AIGg8XHdKe39MSXWSC++Nu4qS1JwABw3JQ7uwsWcbzg7sxCCvyn9wfi6nSLFAIGjcXFfukb+PliS7UYwNadBukerwWxc5XjXNaCKm0EgXN2d+TcpgeqkFzOIwwqP92uPvUDdJ6QUCwdXjulLaT/562PY6sn/5JcMaI75aDb5aWSHfG9yEe4ObELL1COZSa5Gdd50oc53weQsEdcO8efM4ePAgZrOZRx99lFGjLr9wR0VcN+6RnMKSqhf6UUHXfJzzxcHlF2wozX3HK96RKRAIqseePXs4d+4cy5YtY9GiRcyePbte56u1pV1QUMBLL71ETk4OJpOJxx9/vMFWsJEkic5vri9paORukeqgUijo4+FSbsRJMevSc+m5+yRxeiMuKiXLO7ekm4eLXZ/fkjMZ5eOOp8gBLhCUS8+ePenUqRMA7u7uFBYWYrFYUKnqxzCs9Tfxjz/+oHnz5jz//POkpKRw3333sXZtxTXjribf/hdje23oc/3k8fizW7jttdkq8X1iOi2dHPDQqBh38BwAcUX1LAssVsYdOsdbrYJ4pKlcB3PayYv8niIv3J4e0IGVKVlMDvC2PaVIksTrUQlkmiwkGUx4aVQs7tD8St6iQGDHquhV/HHujzodc0L4BG5qeVOF51UqFc7O8ia3FStWMGjQoHpT2HAZStvLy4szZ+RSTLm5uXh5eVVxxdXj7X/kaumBzdy54KElQHv9LciplQq7xFOTArz4LTmrTL/XoxL5MCaFhe3DbAobIGKnnLL2lVJ5UL6JT2NhfLrd9QFbjrC2e2u6uIudmoLri40bN7JixQq+/fbbep2n1kp7/Pjx/P7774wcOZLc3Fy+/vrrupSrXrgQIadovNW/4f7AXCk+bduMdi5OzIpO5CY/T1alZtvOZZstLE6ouLhrVSlnxxw8yy+dWjDMp/pl2hozhRYrWqVC5EFvANzU8qZKreL6YseOHXz11VcsWrQIN7f6y00Ol7EQ+ddffxEUFMSGDRv44YcfeOutt+pSrjpjbWRSmbbbAoTSBpga6kfy0C580z6M3b3b0qFUBfm16XJe8f1921V0uY1nmvkzpom9gr7r2Hnii1wvdcmmjFxG7j9Dntlia8sxmcts5z+YU8Ath85RD+ni7cgymWm+/RjBWytPxC+4dsnLy2PevHl8/fXXeHp61vt8tba0Dx06xIABAwCIiIggNTW1Xp3vtWXqT2Uz+bVzqfuSSo2d5s4ObOzZpkxF+ZCiDT3ROj3ROgP3Hr9Q5toZLQJtr8/rDPTbKycW7rH7ZJmwwjSjiWSDiXejk3iymR/9veytkvXpOdx7/AI93V34IKIprV0cMVklmm6zV4rhO+Sir4819eXLOPmp4O5A7zIbigK3lt3Of9Ohc0zw9+KB4Jqn4SyNwWqlbZHbSHD9smbNGrKysnjmmWdsbXPnziUoKKhe5qu10m7WrBlHjx5l9OjRJCQk4OLi0uAUdmn+eXIAI87KCqexb6qpT3y1Gn7v0opbj0QBJe9VS2dHWjo72hRgsYvk4wj7ZPYtnB1IGtKZwCLL84mTF1mRUtZ3DrA1K89OoZZ2u+zPLWDQvtM82tSXr+MqdtV8WepcRTtAM01mvIuiXz6KSWZfTgH7cgp4/VwCe/q0BSDYsWwZrmIKLBYclcoy7o9m2+yL0t5xJJplXVpWOE4xL5+N52yBnufDAvB3UNPSuWIjovg9qSym/rETMaxOy+Hi4E5kmy2sSs3m3iCfWn3OXzwTx5LEDLq5O7Omu1wXMcdkJsNkoYWzQ43HqwyTVUKBvN5SW/LMFtrsOI6VkiLaV5o77riDO+64w3a8NCkDvUf9pceotdK+4447mDlzJlOmTMFsNjNr1qw6FKvu6RDsAWer7ieAfl6uVW68SR7aBZ3FinM56ShLK4uKFHYxGzNyK63gU5nCri7tdkZyekAHuuw6gb5U9kOTJNF9t7xIfbBvO7JMZkYcKPmQ7O3TllsPR5FgMJXx+1/6YwWwLSuP2EIDoU4OmK0S4w+d5Wheod1u1P+y8vguQV68/a/ohzFpSGcUCgUBW45wo68nCzuEyfKVkjVgyxHb3+Tuo+fZlJnL2YEdcVMp+aNIrsBSLpqXSu2KjRnUic2ZuTwYGcMNvh7cH9yE24+UVGs62LcdwY5aDFYrSxLl7JeHcnV8EpPC02H+tCl6moge1BFnpZLArUcJdtBwsCgXTm0osFhouf243f1XF4sk8UVsKncG+tDhv5InnaCtRzncrx2BDhX/ANc3z5yKZWlyJn5aNcfqaQPfNV0jMltnpMtbGwA48e4YWm4/zswWgTzVzP+qyXS9sDAujdeiEmp17YcRTdmQnsu/6faFkcOdHVjSqQWPnbhIX09XvohLBeC7DmG0c3Wi955TvNYyiPcvJDEt1I+T+YU233x9oUTeyFTaffNiWADvxyTXesziz2jbHcfJKuW7vz+4CaN83Lmrkh+5K8k/3cJxUSnZlpnH1FA/W7vOYkWtAI1CgUKh4L7j51EAH7QJxUerLrOQ/UqLQJ4s+k6+fDaeB4Kb0LrIhbkqNZtHTsSwqmsrbjocxVutgjBJ8HZ0IhWxpns43dxdyrQXu97iB3e2s+4zTWaclUocq8iHLUkSEw5H8VxYAP08XRmy/zRPhPrR08OF/ntP2/W92c+Tr9uHVTpeeVRHd17TSvt4fA43fraTr+/pTmgzD4buP8NX7Zpxi4geuSLkmMy02RlJoIOG/X3asScnn76eruzOzmeAl1u5USgXBnXCqejLM3L/GY7nF7KyS0s6uDrhUYsNPuXN0dRRy74+be0s09pycXAnHJRKzhXoGbjvdNUXNALaujhyqkBfo2v+7hZOhIujba3hShPu7MA5XUlhk7jBndEoFfySmMHylEyaOmrtQlxPDejAu9FJ/JRUkle/9NPlnPNJfHwxxXb8TDN/u+OqqG2KiOu+sO9fR2RLL8jDiR1FJbxcr/Ht6w0JD43a7sM7oGjRcYBX2ZCoYuVXmlXdwkk1mmjmVHtf6q3+Xnbx5qXlKX79eWyqzXJ7tUUgHhoVFglmnI1nsJcbtwd48eQpOc3trt5teelsHDuy5FS4xTKHuziiAC61gP7rHVHGCgP4sWNzRjXxoNX2Y+SXKmxRXd4JD+bVc/Lne0HbUJt8NeFmP0/+KuXyKWZLr4gqwzov5cZD52o8/12B3vxSB5koYwd3QqtU8tiJGJur6NKF693Y7wwubwG5snuuicKOGdSp2n1rwzWrtI1GI4t2yguP4X4ubE2SLYf2riJypKGQPLQLOzLziHB1LKOwAZxUystS2ABftGvG521DCdx6lEUVPK4+HurH46Ue74u5v1R0SW8PF47kFdLC2YHlXVrxyIkYHrok+uSLds147ORFwL5gc/LQLlgkiT9SslgQm8qGHq3RFt1vVNEXvPiB91Lr/4eOzenv6UqrSyzYB4Kb4KBUMKaJB75aDcEOWm49EsXO3hG0cHLg5kNR/NK5BSqFghbb5QXT+MGdWZWWjZtKyUAvNxxVSr5qJ88bXWjg1sNR/NG1lU1mgCSDERUK/Bw0fJeQzs+JGWzs2YZ16TncV04kUXVZ16M1nd2c0Vslux/Vyghz0hJTWBJGeqk1+2X7MP5IPVJrmWrKV+2aMbXo712ePPXFNesemTVrFt/rewLw35NdWFgIPySkc35QJxE9IqgXzFaJkCIL73K+wP+kZmOSJNQKBTf6edaNcPXIpRZq6Xs/mV/IsuRM3mwVzOmCQobsO0MnNyfW92gDyD9W+3IK6OXhYvvButXfi27uzgQ5aPgrNdvON1zslz4zoEOF7rJL5XmzVRA93F14IyqBFV1aEba9JOrn3+6tCXHU2IW5luZ4//aoFAraFVnmU5v68nrLIKySHPXyQ0K6bdG3LpT2devTtlgsPPXmh6w2yhtDVk4MYHyu7BYR6UgF9UmWyQyA13WUYOtkfiFr0nKYH5PM8f7tbWmCa0qG0YxGqcD9Ml2YkiRhlKRyn96qQ7HSTxjS2RbmGa3T46BUElJOaOhXUXHs+3gexuwsDAYD06ZNY+jQobWa+7r1af/111/kSfJj9TCniyQnA87BV1cowXXB9aSsi2nn6kQ7VydeaB5wWeP4aOvmvVMoFDhcxtN04pDOmCTJLi6/slj60LPHUXXuxMMPP0xCQgIPPvhgrZV2dbgmP2HHjh1jv0nOJ93K2cCug4dgoFDaAoGgapQ1VPrjxpWULUxKSsLfv35Diq9Jpe3i4kKhXn6M0SospDrIv5IflbMhQiAQXDtk//knOSt/r9MxPW67Fc9bbqmy3+TJk0lOTuarr76q0/kv5ZqrXPPZxRQ+6DHSdjx27Fh2tewIgBKxACkQCOqHpUuX8uWXX/Liiy/Wa6Kya8rSliSJd87bZ/Vz8fEh1kcuNeZXRz4zgUDQMPG85ZZqWcV1SWRkJD4+PgQGBtK2bVssFguZmZn4+PjUy3zXlKVt2yhQ9Ctnbu5Kn1Ml24mHeNdvnluBQHD9ceDAAVvhg/T0dHQ6Xb0WhbmmlPYXsXIuin6H5arryoySba1DTh8S8dkCgaDOmTx5MpmZmdx111088sgjvP766yhrGW5YHa4pf8Gx/EIAvHJyAX8sTUuSxkSk1Hybr0AgEFSFo6MjH3zwwRWb75qytItJV8tbkh9vH8ypAR2Yuu1PAKKjoyu5SiAQCBo+14zSliQJR6WC3ikX0Vjl/ARPtQ/BS6PGw8MDgCVLllxNEQUCAWCx6LBazVdbjEbLNaO0CyxW9FYJRW4OyQXyQqSrg+z9mTZt2tUUTSAoF0myVHFeQpKqzgAoSRL/7RpEbl7dlD4rLIzHZCrJZW61miuUIyn5T/YfuL1IDgsWS2Epucq/Zuu2jmzZ2obU1HWkZ2zl3LnZbNrckiNHHqhWqNy5c7PZt/8mos9/xKbNLTGZssv0yc8/iyRZMRjTbbJZrUbORb1HQUFUlXMAmExZGI3lZyGUJAmDIQWLxUB8/M9cuPCZTXar1VSt8WvLZfm0V61axaJFi1Cr1Tz11FMMGTKkjsSqOelFOR+cLCbiVfJ22uSoswS0ao2DQ0mmOLPZjFpd9ratVhOZWf/RxGcIh4/cT2bmDgYPOoZaXTaZuqD+kL/oisteNLZazWzZ2oaWLZ4nOPhuJMlCTu5h0tLW067t3EvmlAArVquBuLgfCQubCoBOdxEHhwBUKvtMgwZDCidPTqdz54UYjRlotU1QKkvybRw8dBfZ2XsZOGAvhYXxuLi0Qq22Lz+VkbGDI0fvLyP3wAF70Wh8yMs/wf79NwMwbOg5EhKXcubMawB06vgl2TmHaB72BDv/64fFIqcdLe4PEBr6ECZjJtk5h3B370j7dh+iUCiRJAmzOYftO7oDMGjgQbbv6I67e1e6df2ZrdtKCjk7OjZFshoxGOW0pEMGR5KWtoG4+B9oFvoIxyNLjKHYuO84d+6dSv8mPXv+RaEuxnZc+nqAjMztbN7Synbcv99OHBzk73JhYQyJSStQoCA2bjEAeXlykqfie6kusbGLatRfrfakR/dl7Nk7moCACbRrO5ftO3piNtsX6Th/4SPba1/fUXTq+GWN5qkutU4YlZWVxeTJk1m5ciU6nY4FCxbw9ttvA1cnYdSmjFzuPnaeMZF72Jog73z8e7SGjkNHodcnsWHjOGIudGXChMcJCbH/I5tMuWzf0bXccYcOOW33hRTUHJMpG43GE7M5j4yMbfj732A7F33+I2JiPmPY0HMcOjyF7Oy9AAwfFk1S0kr8/MaiVDqyeUs4Xl59ycraDUDbtnMJ8L8FhULJuajZFOSfJTPrv2rL1KH9p/j7jwdg0+aydR07dfqGY8ceqdF9Ng25n9zco+TkHi73fI/uKzl67GFMpsvPIS1o+AwfVvM1tHrN8rdmzRr27dtXbm3Iq6G0/0zJYurJi0zct4m/syLwQcHcVhcZ8dBjZb6Upd9Ms7mAbdsrT1pemzf/crFaDSiVdVtIteo5zVitetRqVywWHSqVM5s2tyQ09GHCW80AYMvWDjg7N8PdvTOJicsAaN/+Y/z9brBZSSEh9xAfb79+4OMzhIyMrXZt7drO5+SpF6ohmRKoeaGAqmjdehZnz86q83EFVePm1pHAwNuuyfe/S+fv8PEZVKtr6zXLX3x8PHq9nqlTp5Kbm8uTTz5J3759azvcZZNqkBcf1UbZn9QRFf6x/pjNeWX6btrckuHDopEka4UK29//RlJS/rb1L6Zf3+04OcnJpwyGFFQqZ1QqFxSKqurLWZEkU4WKWJIk0jM249tkuG2+zp0W4eXVB4tFh1Zb/u4qq9XIiZMv0DbiXdTq8jcPSZKVuLjvCQy8DY1GXpSNjf2Wc1HvVipzMbGxC4mNXWg7zs8/TX5+STWWEyee4cSJZ2zHlypsoIzCBqqpsKE+FDZwRRRG715r2LtvXLnnXFzC6d3rXzuXQGn69N7Anr1ySoa2EXNxdW3N/gMTANl1odfHoVa70yz0YdzcOpbrbnF1bUt+/qky7e5uncjNk/NKd++2jIOHSqqJDx8WjdVqJitrN5mZO2jV6mU7Gd3du5Jb9DQxfFh0uZ+lYkMnI2M7iUkraNP6dXbvGUnTpg/SPGwaCoWcfjUwYEIZ1xFAQUE0e/aOQqVyxWLJtzs3eNBR9u2/kcLCWNs8ZnM+CoUGq7UQvSEZZ6dQLJZCtFofJEkiI2MLPj5D2bqtPVarvH+jTZu3bS6n4cOiMZvzyM2LxGzOxcuzLxqNO1DyJO7tPZCgwNuJPPE0bm4daNduPulpGwgLm0Z6+hb2H3iED+aHMm1aOrfeWvbvWVfU2tL+5ptvOHToEJ999hmJiYnce++9bNmyBYVCcVUs7Rd27OMXo5qbtm1mrbEtb+FEd3MuyeOeL7d/hw4LiIx80q5t0EDZ5xkYeCsKhZIDByeSk3Oo1jL177cDkzmXffvG27UPHxaNwZDGyZMv4OgYRGLSb9UeU6Pxwt//BvLzz+LoEEByyl+V9i9PaYSFPU5MzOfVv5ErSGVuCZXKlWbNHuH8+Q+rHKdH95VYJRNennIhDEmSsFqNqFQOWCwGO98tQK+e/7Bv/w0MGXyS7Jz9HDlyH4MGHkanO09BwVmCgiYBkJ6+GZMpi8DA22zXyn7iPJuLbeiQM0X+YzNKpZy4LC7uB86eewuApk0fpCD/DF27/lhG7vj4nzhz9g0GDTyARlN2V53FUohS6VChkbB7z0jUajd69ig/aZIkWSu8NifnCB4eXco9B5Cc8jfnoz+kX78tFfapT+SFW0WVBlJV5OefwdW1Td0IVYqPPvqInTt3cvfdd3NrLbV2vbpHVq5cSXp6Oo8++igA48eP58cff8THx+eqKO2bflpBZJNgWu44wzmLLx/hTE/UnBl1PwAD+u/mgw/fp3fv8j/Mw4ZGlbv4FX3+wwar4OoDd/fO5OZWr+Bt717/4uLSis1bwm1tpZWuk2Mo/fptsT05lF7YlSTJZr116/orXl69bGNYLHrS0tbj73+jrU9dry3odBfZvWcY/fpuwckptE7GlL9K0mUrFUHjIzo6mg8//JCIiAiCg4PrVWnX2j0yYMAAZsyYwcMPP0xOTk6977e/FEmS6PhDZ5BUfDFgNelmM85GA1ZJVrztsa9+oUh1wmhwYe+eW+ndx15xV+azbtniOZr4DMNgTMHDvSs7/7t6LqC6xturP61bv8H+A7fSpfNiPD172M6lZ2wlJflv2rf/AIulkF27h9K+3Qd4evYg+vyHhATfa3MTDR8WjdGYjlrtjlKpLfN+lvf+KhQKevdei9mUYzcvgErlSEDATUDFP6aXi7Nzszpfq5DlFKkSrian9yRx6r+kqjvWgLb9A4noE1hpn7lz5/Laa6/x559/1unc5VFrpe3v78/o0aOZNEl+bHz11Vfrdb/9pXT4ti8F594D4N4zh3Ft44qTyYCEgmBPJ3ROaWgz5EdTldGN1M+PMP2l55n3yQfs3jWRvv2WA9Cx4xdVzlX6kbFYQe3Y2RtHx2DaRszBy6svF2I+IyXlL1q1ehknp1D27h1jN0aXLj/g4z2AqKi5XIz9BgAnp1D69N6AJFlISl5JcNCdpKdvwsdnMCZTJjv/62eb02BI4cTJ58nK2o2LSzh9eq+1WbCXKh+zOY/c3OMkJi4jJfUfuz4mUxbHjz9Bp05f2XzgQwaXtayb+Ayhic8Q+f1TOTFwwB7bufBWL5fpr9U2KdNWFa4u4VX2EfliBA2dP//8ky5dutC06ZXJ198oa0SeyDjB+Pdj7NpU7RwJ1hQQe1S2sPdNbcvx8/IijltSH4KOT0UT5MKXmasAmDChLyhW0rnTN7WSwWTKRa12rfBROCX1XyIjnwDKtxbz8k7h6tqm3h+lr9Q8AsH1yjPPPENcXBwqlYrk5GS0Wi1vvfUW/fr1q/FY11yNSEmSOJFxgjv+fBSYaXfOKGnR6jMBZwB8mzWH8/K5oLOPARKmxAJG3jiSDRs28Mcfu5k+/eNay1K8slwR/n5j8a/k8dvNrW2t564JV2oegeB65eOPP7a9XrBgAcHBwbVS2NWl0ZhfGy5uoNOPnbhz9Z3oYh63td/ddT8AVqUSS6H80PDF3d3sLNvg10rewGbNmtlez5s3D6u1fsLJBAKBoD5oNJb2c1ufA0CSFEhmOdb4g8GvokDiZ3qCVaLQIkcXtPaX4z6tJgcKkwNQqEt+m6TPzkOpwspvvfUWISEhPPTQQ1foTgQCwbXKk08+WXWny6RRWNq/nSmJYy6Iesn22tMhF0dVUaEDi4RzjpyDIcTLWd5RqDGQmyy3KTTyrSpQ8MYbb9iNHx8fz6xZs1i8eHF93oZAIBBcNo1CaX94UN5M8XbHV5HMnnbntCojIKEwS5hN4K1V4ahRYTDIVWxMBRosZhN+T9nnFilv+31cXBxms0gZKRAIGi4NXmknFyRTYJKt5VPzltraF496iiNft2W6fjmSSgkWK1aLAl9nOcxPp5NXIS1GJRu++QyNr7Pt2vRFxwFZcb/22mt2873zzjucOHFCKG9Bo8ZoNGKxVJ769UpxqRxWq7Veq5UXYzabbf9qO9/x48fJz89Hr9djNBor7ZuUlMSsWbPIzc2t1VzVpcH7tEeuGGl7vTxogt25NN+mJDorcVArwCxhklS4WeUFSHNRukpTgYYT2zYxZtqzaJu5Y7yYiyG6JKWiSqVi1qxZLF++nBMn5FSPy5fLMdzlWeOC2mM2m8nNzcVsNuPnJ1cXkreAy+0+Pj7k5+dTWFiIt7c3SqUSi8VCfHw87u7uODk5MXfuXB599FECAwPJzs7G0dGRtLQ0W4ys2WxGqVQSFRVF69atkSSJjRs34uPjw6pVqxgxYgQDBgywfYmNRiMGgwFHR0cOHjxISkoKtxRV887KysLLy4vCwkKcnJxISUnhq6++IiIigoiICNRqNYGBgXh7e9vu0WQyoVAoUKlUth9+jUZjO5ebm4skSfj4+LB161aCgoJo1aoVO3fuJDo6mgcffJDffvuNIUOGsHr1anr37k27du1YsWIFkZGRdOzYEScnJ+Li4khKSuKOO+4gIiKCNWvWsH//fmbMmMGcOXPs3vfnnnuOxYsXc8stt5CamkqzZs1IT0+nXTt5K/9bb8nb6ydNmsRvv/2Gn58fEyZMwGKxoNVqWb16NUajkRYtWhAaGkpwcDBqtRqLxcL777+PUqlkwoQJrFy50jZnr169cHJyorCwkH379tna27dvb/uelccDDzzA6tWrUalU3H333cyfPx+A8PBwcnNzadq0KcePH8dgMJS59oYbbiAwMJCFCxeWOVfMkCFD2Lp1a4Xnq0Px++Ts7IxOpytz/sMPP6xX3dHg47Q7/tARgNae4Rzc/T8Anun6JQ+N/4BW++WE69qdKUhuGjxSs+nm5MWPrw0lOno+MRe/5MRPrTAVaHh+mbzJJH7GDgBC5gwsM1dFb/TAgQMZPnz4Zd1HVUiSVCaW22w2U1hYiKurq+2cJEn8/vvvdOnShYCAANasWcPAgQMJCAiwXZeZmcmpU6fw9/fHz8+PtLQ0XFxcaNKkCWazmTlz5vDSSy+hUqmYPXs2jz76KBkZGZw5c4bjx4/TsWNH2/9JSUlMnDiR+Ph4Tp8+zU033cSiRYvIyclBpVLx0ksvodFobPLt2bMHd3d3fvtNXofw8PAgJ8c+73AxSqXymoneKf68CwQAarWaV199tcbX1WvukcuduDqkFKQwYsUIdLH3YymIsLUvHvUUG8//wnct5Yx5wZtP4e+ewKmMCO4MD2D2/3rYdgseXRiBZFWUUdrB7w5AoSq72y4jI4MFCxaUK8+rr77KO+/Iid4nT55MeHg4ZrPZVmSh2CIrJjk5ma+++gp3d3fatWvHmDFj+P7770lISKBp06acP3+e4OBgEhISav0eCQSChoe3tzdPPfVUja9r9Jtrvjz6JZJVY6ewAe5WrIRSKbIVkpGMQh8kFHho5UdRT4+e6AovIlnL3wZtiMnBsaVnmXYfHx+effZZPvroozLnihU2wNKlS8ucr4jc3Fz27NnDnj0lW8HPn5d97kJhNy6KH/mvBEOHDmXLlpKMeq+++ip//vkn/fv3Jzs7G3d3dw4cOMDhw3Ka1JtuuolVq+Qdv15eXjz99NP88ccfHD16lLvvvpuff/65yjmnTp3KV199Vaa9a9eutnlKo1KpsFgsDB48GIvFwrBhw4iPj+fbb7+16zd8+HACAgJwdnbm6NGjjBsnZ54sXUmq+En35ptvplmzZnz66acATJ8+nXnz5tG1a1duuOEG0tLSKCgowNfXF7VaTVxcHB4eHja5X3nlFTQaDRaLxfakWuy2ysnJ4fz583h4eHDw4EGGDBmCh4cHzs4la14FBQW8//773HjjjbRt2xaLxYKbmxtZWVl88skngJxeYerUqfj7+/P333/bQoddXFxo0aJFrRR2dWnQlnbHHzqSd8reP6cfHgil4q6PnoTbEk4Sb5Vjt6e3b8q0ezqxd9+NODoEsHG2nDzm2V//QqlUoT+TSfp3sk+tPBdJMYcPHyYmJoYRI0bwwQcf1PoeGiItWrSw/WhcyvPPP88HH3xAeHg4FosFs9lMbGysXZ+2bdvi5eXFrl27KpyjefPmdOvWDbPZTNu2bVEoFKjVapRKJQaDgejoaP7880+eeuop3Nzs84CfO3cOnU5HREQE+fn5+PiU5BI3Go3o9Xrc3d2xWq0kJiYSEhKC1WpFoahZmbLyXFLFpKSk4OLigqtr2VzPpYmJieGPP/7A19eXKVOmlDmv0+kwGAx4eXlVOJ/Var2ieXuKycnJsRW9rg7FqkLkg7Fn7969/Pzzz7Yfmcuh0VvaklTy4Xi44w8sCJpZpo9/2mAUlKROTdiTCveAyZSJm1s7QFbaiWdOEdK2Aw7h1ctE2LVrV7p2lcMEZ82axbZt22xWT7HPtzr4+fmRmppqO3Z1dWXQoEGsWbOG2267DbVaTUxMDGPHjsVsNqNSqcjIyMBkMiFJEh4eHlitVtzc3JAkCYvFUqbGZWXKpyJ0Oh0nTpyge/fuZRRGdRdRRo0aVaM5i3F0dKR9+/a0b9++3PPh4SWJpErX9wTQarVotXKEkFKptH2wa6P0KnvP/P39qzVGWFgYzz77bIXnnZ2dbVZcRfNdDYUN1Ehhg1DWDYUGq7TjczIpvPio7bhP4EGKPc1/bs8nuFCiqaNca1BrUdoyYrpaZSVmNGai1Xij0miwmEyc27ebkLYdUChr98EbPHgwgwcPth3fdpucBP/o0aNkZGSwfft2Xn755TJKpiJ69SrJH922rZwfpFgZN2lSfsa8Ymu1vPaa4uzsTM+ePWt8nUDQkDmxbRORWzfU6Zgdhoyk/eDKAxGioqKYOnUqOTk5PPHEE/Tv379OZShNg1XaDy7ZhKUwDIA3+8opWJtKFylUNiekUEJJSUSCg6SyKW0XSYHFUoAkGdFovGjVsy9ndm0nav9uht73sN0cuuNpOHf0vSw5O3fuDMCwYcMuaxyBQNA4CQsL44knnmDs2LHExcVx7733sn79etsTYV3TYJX22fiShQFf53TiCSFO0QwkOUTMz+EZACQJnMyOoAUXlR4VThj06QBotN6E92rLmV3byU0rcVF43xlB5q+nyVkbc9lKWyAQNBzaDx5epVVc1/j7+9sWVkNDQ2nSpAkpKSn1ll/7spxper2eESNG8Pvv5ZfwqiscVCZeUnxi16YiA2blcLbVp2gUsiJ308ir+nnZsoLWanxo0a2sC8Cpg+x+sGTor8jOLIFAcO2yatUqW96itLQ0MjIyqr0mUhsuy9L+8ssva7yYUR1KK9KWkn1O6r3r5OrqiiJFvfG/pmhcsgDQWouUdo4cRqfVNkHjIKf0K628S8dnF+xNwrVPUF3fgkAguE4YNmwYL7zwAps2bcJkMjFr1qx6c43AZSjt6OhooqKiGDJkSB2KI7P6uBzx0So/ihm3fMVXPGE7pwICtPLOSMkqK3cX5O3C5qK6kOfPrUDtDi4uclHYkLYdMOgK7OZQeTpgyTaQ/We0UNoCgaDWuLq6lhvbXl/U2j0yd+5cZsyYUZey2HhpxTEAWurOk61tzg7FULvzamUKvJzA3wuOAOCiMAFgLPoNMplSALm2IYCrtw/5WZl2YwS8VGJ5SxbhIhEIBI2DWint+i5kWWCUs4L9dc8DLDaXlKJfvrMAX+3z8oGDK3GnZLeIk0K2ojVFytvRK8ZuvOiD+8hJScZqLck2VjpMLuGVnXV+DwLB1cCSZ8RqKJvdr/ip9GpgNdRtxsyK1qEkSSr3nGQpP79N4ZlMrDpZZ0gmC1ajBVNa2QRQlY1jztRjyZGTV5mSCzCl6rDkVp4N8HKplXtk69atxMXFsXXrVlshy4CAgDqpi5agt7/hw4oettdhBVYcHM/Ai/a7+RxVRxjre56hTTeTljIXhdL+D2fSy77uvb//Rt/b77S1+z/bjZSPDl22zILqIZksKDSq8s9dsttOkiTMaYVo/Jxtx5LRitJBhTlTT9afUTS5rz0KlQLJZAGVEoVSYbfRyKo3o1ArMacXkrLgMO7DQ3EfFgqAJd+ItcCE/kwW2hA3lM5qcrfGYcnU4zG2OWlfH8O1XxDGpAIUKgWG6GyC3+pH3s5E8jbH4tTZF22wKy59Am3z6c9loT+bhUKlwH10GEjIMlkkzOk61D5OWPVmVK5asldFk78rEf/nuqPy0CKZJSyZehQaJdmrz+M+ohmG8zm4DQ7BlJhP6mdHKnxfXfoEIhkt6A6lVtinNF63hpO/KwFTsg7Hdj7oT2agCXHFFJ8PQJOHOoIkkb44kuB3B4ACJLMV3cEUsv+S15iUbhqseaYK5/Ce3AbJKpH129lqyVQZ3pPbYDifQ8G+5Io7qZVgbjjJx9xHNsN9eGi9jH3Z29iLC1neemuJRXw529hv2n+WYyvPAaAfHWxr378uDwUQ8kZHcPJkyau7yE3X0zzCkSPJX9OsZSoBzc5y9u9PaD3haQCGFxXW3bX8F3av+IVet0xk4J332c1XnEDKuYc/3re3rvH9N3bMGYWofZzs2iSrhFVnQqFVoVDLytCqM2EpMGHJMaIJdEGhViDpLeRuicPrllaYcwyYkgqQ9GYs+Sa0Qa6kfXOswnndR4RiSi+k8Ehafd+iQHBVqCxNRkU0ym3sfdMtXPpV/3drPgog2OFWcJK/5LnpegD8mjphSW+CUcoBNTaFXZouo8eze8UvuHhWvIVddyAFc6oOv2ld6uhOaoYlz4jSRVPujk2rwSwr0HJ2Pub9l4BLjwAUWiWSwYLSUY3VYMacrid340X0p2RfvtvgENmqOp1J3pY41E2cMKfXTeKjgj1JNb4md2Ns1Z0EgkZK0Fv1V439spV2XReydM6VH4Fu4wDjJDlTlq/hezzVn6PwDQPsfVrt+zbhn+NuGEtX6wU6tC9J3uLk5o5KrSYvI73MfMGzB5AwU/ZpG2PzbJZ30Ot9UDpran0fksmKOVtP2jfHcBsUgmufQBQalW189xGhaIJcMcbnkbc5rtbzAOT8XX7yp9LkbYsnb1u87biuFHZjIeitfuhPZJC57Ixdu9+TXdGfyyJ3bQzaZu5ow9wpPJqG540tKDyZiSbQBSRQ+ziS8eNJFBol3ne3RalVojueTsHusj9YAdN7kjxvP9rm7hgv2Fcx8XuiC6ZkHc6dm2CMy0d3PM02hkvfQAxR2bj2D0Ib6o5ktpK7/iKGmByCXuuLJUuPOUuPU1sfJLMVa6EZlZsWS44ByWwt88QEkL0qGrfBISjdtRjO56By12KIysapYxPMaYWkfX0Mz1ta4RjuiSXPiCXHQOavJe+RQytPrPkmTMkFdt8JU3IBllwjmmBXLFl6tCFust/cKqE7mkbelji0Ia64DQ+VC2tLoPZ2LCNfMZLJikVnQu3hgGSyIlmt5G6IxamDDxo/ZxROaqz5JhRaJUqHErVlKTBhSirAsZUn+uhstIEulX5vjfF5KJ01qLzkdBMVpYAodq1ZdWZQKVBolCi1Ksw5BlTuWgr2JOHSJxDMEqhrlqjscmlwWf4So87y0VtzmNbiBs4PehGnzAhCD8wgxPEGcPKCl2LQ5Rr5bvpOBkwKp3MfF959Zzbh7sfx6RVlG6fYNVLMB3fIeUqK82qXkblImZZG29yDJve1Q6FSkLczAbcBwRgTC9CGuqFQyL5Kq86E7lAqOf9eqNF9Xstow9zRhrihCXDBqaMPxrh8HFp4gFVCoVYiSRL6Exk4tvVGoSpZC5fMVhRqJbrjaVgLzLj2Cax0HskqYck1oPZ0RDJZQamwi8GXrFIFTy6WIoWnsZu/ttQmYZfg2mLVqlUsWrQItVrNU089VetQ6EbpHvEIDWZfz/08YJYzwLmldifI4Q755HOnANhRtLhhNUug0iIp1aiMJSvmUavep28PI87uZQPcK/qCBczoRfKcfXZtxgs5JM7abTvOXXfx8m7uCuN9ZwSaIBeMMbk4hHuSu/4izt380Pg6o3TRIBktVT5NZK85j9JZg/uQ2kcKObbylF8UKVCFQmHblVoaRVHK3eqmFlAoFag9ZetNoSmrfCtKDqZ0UKF0KH9BtDYIhX19k5WVxeeff87KlSvR6XQsWLCgXvavFNPglHb8++/zc94XJHb4GoCm+s9RKopChjTy41/UAXmV3NlDi1WlxazSYjrlDgMgL74LZr0nCWezCO9RspW069gbOfzv3+RlpOHexK/MvGpPB9vCQXlWd23QBLngdXtr0hdHYi2QV9oVGiUeN7Yg+/cofO5th9rHEavBgmS0oNCq5EdBVVHWQlXdPHYVFzX2ntTGrl2hrtrK9BzX4rLnFwiuZXbv3k3fvn1xdXXF1dWVt99+u17na3BK2yGnByghL0i2cF10RRZ0/2fK9G3Vww+D0QAKJRarhaBpWv4b+RgA8aftlba1KMZy4eMPVugiKSZkzkDMGYUkv3+gWjK79A6gYG8ywe8NwJJlQOXpYGflBb3WB5D9b0pHNQqVAtdelT/6CwSCmlNwMIWCAyl1OqZLD39culecSyQ+Ph69Xs/UqVPJzc3lySefpG/fvnUqQ2kanNLO7huJz96SlVeNucjlPvJNW1twG090OUZUKqWtGrJBLcd3e7sYScp25OTORIZOKSlTNvieBzm6fnW15VD7OFUasnOpm8Vrgpy4v7LFFpVL7Rc2BQJBwyU7O5vPPvuMxMRE7r33XrZs2VJvbrMGp7S7jHyQE28PglHgavWEWdFl+piNVtyKlGN+djYA6a7yrqSmGz4gqecrtO5l/8uo0VavOEF1EX5MgaDh4dK9cqu4PvDx8aFr166o1WpCQ0NxcXEhMzPTrkxeXXJ16hxVhqsfFg/Zug7r+FaZ05JVIuVCLrkZcpx2dkwMAEke8rGzTg4ZNOgq3jq7c+mPdSmxQCC4jhkwYAB79uzBarWSlZWFTqfDy6t6ZQ1rQ4NT2hcScolrK7tHHBzK/mJ+/fQ2ALJTZLdIdrwcexzrJSttZVGRhPxsQ5lre9wo79rc+8dvdSy1QCC4XvH392f06NFMmjSJhx9+mFdffbVe6342OKW9/b+LZPaUNyT8Nb9siJ3FJCvlSa/IWfpS/vkHhdXKRR8jFNVPVKkV6HLKKu1Bd91ve735+6/rWnSBQNAAyE0vycEiSRIWc9kcKSa93u7YYjaTl1l28111mTx5Mj99/z0rVqxg+PD6rZzT4Hzaku4CGmc5e19+hhs7lp3Fw8+JTkOb2u2E9G3qBkChoxOOej0GBwW+s14l7dVZWMwSheUks1EolbbQv8P//k3zzt1p3rVHmX6CK0dFcfNmoxF1LRPJm00m1JqSRd+E0yfJTUth57Il3P3uhzh7eCJJElEH9pASHUWHISNwcHVl9Sfz6DxqHCER7clOSaIwNxdHVzcCWoWjVKo4uuFfNi76nPZDRtCsQ2dCO3axpUYwGfQYCwv56tF7AHjm5z9RFRkRkiSRdvECW39YSHjvfhTm5SFJVkBBv4l3oVAoyIiPw8XLi/S4i+hysgloGc7xTevoN2kKmxZ/ydENa2r1XlREu4FDGfHw45zcvpmNi76wOzf16yVkxMeycvYbTH5rLs7unnj4+ZOVnMjfH82hz6138PeHct3WW6a/xrGNazl/aL887qBhjJn2LPv+WsHOX3+otXw9b7qN/atWAhDRfzDewSHs+u3nWo9XlyhVajz8/MhKSqywzx2z5hDStkO9zN/gdkQeORHHyaMP4umZyoVVH9na73mnLyaDhaVv76Nt/0CG3dMWyWTim2mPk+/pxPcdNrPZbzbpz07nxMCXSFGF8vhXZYvtSlYrH955k+142INT6Tr6htrf7DWAUV+IRuuAopJHOqvVAhIoVSWbUgqys3B0dbMpJ6vFgkKpRKFQkJmYwHfPPlruWIPv+R8evv6s+nB23d6IQNCAqCq0uDwa5Y7I1q0CyEgpm0sjMSqbTd/LOyI9fOVNNllLl6F3csSx6FFH1a0TAMrUOAgMxaAz4XDJjj+FUsmT3//GgvsnAbD526/Q5+XZpWxtjOSmpeLo6orZZEKjdcBkNPDf0iUc27SWgXfdT8vuvYk7eZyE0yc4/d+2qyrrtiWLr+r8AkF59L39TlJjLhB9YM9lj/XgJ9/UgUTl0+CUtrNDiZLt4XSMA4WyIi5W2ACdhslbqlPefZesyXfgnScH01vcinb+ZZ0hKbA/+dmGMkobQOvkzGPf/MSXj0wBYNfyn9m1/GeeW/p3nYby6fPz+X3uLCa9NhuL2Yxaq+XohjV4+gcS0Ko15/buYuOiz8u91tnDE11Odp3IseOX79nxy/d1MlZjpEW3nox46HGcPTz4/b1ZxEYetZ27b/7n7F7+C0aDnpCI9sRGHiE28hg3PT8TFApyU1MwG43oC/Ix6fUMmvIAGgdHMhPi+P75aWXmGvnwE7QbPJxPpkywa/dt1px75y0gPTYGSZJw8fLm++ceozAvF++gEMY+/hwXjhzkwD+/M/aJFzAV6vAObsqmxV/i4R/AuCdfsPtsSlYrFovFzg1UHoX5eTi5yq5Eq9WCUik/KRl0OrIS4/EJCQWlApNej7O7B1arhe0/fYvFbKbD0FEc2/gvF48dJidV/o49/Nm35GdlENCyNUqVCpPRwO7lv9Ciey/8W7Ri5y8/ENalO0fW/cNNz79iezIr73tlLNRhKNTh5l02pYHJoLfVdzUZDeiys3H39bONYzIaUKnUtrEVSqWdq81iNgMSKrX9+yNZrZU+Udr1LXJCSJLV9r5JkkRWUgKgwDsouJKr648G5x4B+HdtOzLSmzFgvR+h333Hl49vtZ0rdo0ARLZrz4pJEwFY2Xwl625bR06P4aR7t+dYp2n4hroxaWbZauzF6Avy+fzByeWem/TGe5zYuokx054BICM+Dq+gINsf71LSY2NQaTRcPHaE3PRUmz/ueubhz7/FvYkfFrMZpVJp+7JYrRZyU1PxDCjZFZqXmY6zu0eZL1ljoDA/D5VajdaxbJY9q9WCQqEUcf2CatEo3SOSZEGrNSABxzMyCLskC9vQu0t2Oea6uwMQ6n4aAL1Zj2PnTnickIsopMXmVTqXo4srzy/7x5YBsDS/vfkyACe2baz1vVxJHJxdMOgKGPnwE2xY+Bl9bptM8y7dcXB2xd3Xl8itG+k8cixWswUJqcxmI6vVQk5KMl6BJdbDpdVkakuxz7sYpVJlp7CBcq2txkKxJVseFf3ICwS1pcEp7by8kwCYzVoO9uzKmMREHv10MOcOpBLRN6CkHJXRyPoxo+WLJPkxSmfWoTp6jNK2WnXSZj6/7B+Ob17P+q8/rbRfbehz22T2rFxqO3Zr4ktY526kx8bQrFNXvAKDCe/dr053bHYaMaZMW/Fiq1JbvhJRKlV2ChvErk+BoDosX76cVatW2Y4jIyM5fPhwvc13WUp73rx5HDx4ELPZzKOPPsqoUaMuW6DcvOMA5OfJW0CjRo2mbeRx2vazt8zyd+7ENS+PfDc32nvKVVAKTAWEv/IKKe++a+u3felZBt9pn92uPDoOG0XHYbL8GfGx5forK2PwlAdp038Qhvx8LGYz/i1a2c71nzSlzqxWgUDQsJg4cSITJ8pu2n379vHvv//W63y1Vtp79uzh3LlzLFu2jKysLCZMmFAnStvfbxw7T0eSmSmL5tSrfJ904eEj5LvJj6WuRYsdOpMOxw5yHu7BnXLYdsyDyG0J1VLapfEJCa00XMek16PX5Zf7SF/RY75Q1gLBtc/nn3/O/Pnz63WOWivtnj170qmTHNnh7u5OYWEhFosFleryfHgajSdW16lI0rcAfB8ayqxy+mV89x3cfhsAzgrZIaIz61B7y/mfm2ScAOTt8AU5Blw86s79oHF0RONYcTY/gUBwdThy5Eiduya6du1Kly5dqux37NgxAgMD8fWtXhGP2lLrbewqlQpnZznEbsWKFQwaNOiyFXYxLg4qVhva2o7LDXApZbk6K0uUtiYoCABLbkltvu9f+o/Pp24m4UxWncgnEAgEl7JixQomTJhQdcfL5LIXIjdu3MiKFSv49ttv60IeAHzdHEiTXG3HWUuW4H3vvXZ9dGFhttcuSi1Y4UzmGRStZQWe+/ffTN70OkvfLikh9udHh3lw/gCcXGu3PVrQeLGYrSjrqBLQ1UCySuRl6nHzccRqlVCplGQk5KNxVKHLNeId6ELUwVQcnTWkxeVhNlroc3NLVBolFpMVZRXFZ61WCavZirqChWqQjSerWUKlUWK1SuhyDLh6lTxxGvVmNFqVXQEQSZIwm6xotCokq8TRzXFoHdW07uWPSq3EUGhGkiQcXTQU5pkozDPiFeiCUqmQx3NQ2cldkGNg60+n6XNLS9y8HdE6qbFaJZRKBVaLlSCvFuw+kEVEnwBO/pfEXbN6k3A2G42DCp9gV3yCXYg7lcmxzfEknstmwvPdyEwqoCDHwIUj6XgHuTDojtZYLFa0jiVpCFJicvEKcLa1AeRl6oncnoAu28CAO1rz347dvPjcjFr9fWvCZSntHTt28NVXX7Fo0SLc3CoOe6opLX1d7Y73//QTo6ZMscX5SlYr51xdALjzzjtxOiQXSIhMj7S7zifYlSF3t2HrzyXVpb99YSfjp3UirFPjDTFrbJhNFiwmK/lZBnyCS/62h9fHsuv3KG58sjOB4Z6c2ZNMq+5+KBRyuKaDs4YV8w7g4KSm+5gw3H2d8AlyITEqm8CWnkRuT8BQYKLdgCB0OUYK84206OrLkQ2xdBzSFEcXNV8/Zb/708XTgYkzerB/9QVO7CibO0KtVWI2Wqt9bw9/PAhdrpEDa2KIOZZuSwns4qGlx/jmOLlqSI/P58CamHKv73Vjc/b9XT9FoY9sjKuzsdQaJWZT9d+Xqtjy0+nLuj7meEal50/+J1e4/2XW3kr7/TZ7v91x8vkcTu6sOKdIRRzYdhpDrsSPM+TdlB0GBTP4rpqtpVWXWivtvLw85s2bx/fff4+np2cdigTeLrIlrPEOwZQZT7J/AAlPP0PIAjkkz5KRwek28hvSsmVLVMe0+Okh3CvcbhzJbKb9wGDaDwzm8IZYdq2Uq7Wv/uIYAPe82xd3n7IbIq4lyrNWoKj8mkJhs1D0BWYcnNUoVQpSLuSiVClwctPi5u1IYb6RpHM5BEd4cXZvMtkpOo5tiSeghQe3vtgNY6EZq0VC66jGbLKw7ZcznDuQWoFEZfl7QckOxW2/nClzvjDPxM7l5yq8/tSuJNvr4h/oQ+tiy+1bkG3g+xn/VThWTRQ2wMJntpc/T46x3Hu5lPpS2HVNXSrsaxGdMQdnbYnhGrk9oeEp7TVr1pCVlcUzzzxja5s7dy5BRT7ly0GjUuLqoMYU1hsy40kJ8Cfv739sW1AT3pgFfrKzX61Wg1KNjwQZhfa/vgX//Yfr4MEAdB0Zim+oG399VLJIseSV3Th7aHlg7oDLlrmusVisSBYJq1XCbLSiyzXi4qHlv5VR+Ia60ay9D3lZegrzjJzcmUjCmWwCWniQfD7nismYfD6HLx7bcsXmu54J7+lPkxBX4k9nEtLWm92/RzNuWiecXDXEn8li71/nmfRKT3yCXFAoFEQfTmPdQvnJc8T9bbGYJeLPZHFuf/n1E9v2CyQvU0/86eqv+/g3dyflQm6V/Vr38keXa0ShgBZd/WgS4kpKTC7N2vsQdyoTZ3ct54+m4RPkim9TN1Z9esR2bWBLD5Ki7T/T46Z1Yk2R4VUe074YikFnRqEElUaJQWdGn29i1adH0OUYGfdYR0Lb+YASjm6Mo8uIpjaXU0pMLrEnM0k8m0XC2WzbmDc91cVOLgAnNw1dRobSdWQoWUk6Xve/jxPbE3FwVhPes/6q5zTIbewA/d7bRKiPMxGJ6wC4Y+ky3G+6kaC5c9nXqzf/jh9Hq7Awptx/P/wxlYcy/iPOM4h1t68javRoTBdjcR02jKZf2Of2yM0oZMkru8vMF9EvkAETw1EosPNb1Zaz+5LZ8O1Ju7bOw5pydHPdPbI2JryDXMhMLCjTPvXzIexcdo7U2DyG3RvB0rfkNYjbZ/RAkiS8A13QOqrJSSvk7L5k/Jq54x3kgtVixcPXGYvFysq5B+kwOBiNg4r1i07w6ILBbPrhFFEHUhnxQDva9A6wzWc2WshO1eHp51yp/7Y66HKNbPr+JLEnMxn7aEecPbQEtPAAwGS0oNGW5KuAsmGfDTV2v7Ts0HDlvBZplNvYizGYrThp7L9Uuav+xqlDBzK9vQEYOnKkfEKlYa8GKJB9UV6T7iD1/ffJ37y5zLjuPk48/tUwctJ0/PRaSTav07uSOF3qMRvA0UXDbS91x6OJE2f2JpOfpadNn0Bbfcpidq44x9Fq+A8bmsIObe+Ni6cDYR2b4Oyu5cTORAJbeqBSK2ndy58dv53j+Ba5MtCAieG07OaLq5cj+gKT/OPmpGbHb+cIaOGOl78LmUkFqNRKvAKc8fBzQq2pnlIs/RhZXjpdkDM79hzfvEy7SqW0yy8T3kO2cEY/1IHRD5UdR61V0SSkbtZfnN213PhUl3LPlVZ6FSm7hqoENZf8mDVUOa9XGqzSbh/sQWaBkVu7d+fgwYNIgAJImf0esQPlKum2OmwqLbfpTKx01mCVrHjcfBOp779f6fgevs5M+3Io/351nAtHy69YoS8w8fPr9mka9666cj7ILiOaEtzaC+9gF1RqJUqVAgcnNdmphTi7a1GqFGgd1aRezKVJiCsK5eVFRxRbicUMuqM1g+5oXaafY6mq8qXP+4bW3WK0QCAonwartH1ctJxPy+fgwYMA/Db5Du5YugwA1/x8AFucOCotLUxmQEOeMQ+PJtWLDFEoFIx7rBNmo4Wz+1NQa5VsWHyy6gurwMFFTaehTek5LswW/qQvMBF3KtNmCV4O3oEudsd+zdwve0yBQNA4aLBKu4mrlvR8A9OenMYXX8jlkCxKJSqrlXNtLrH+VBrczSbAiVxjLh4OHmUHrAS1VkW7/vICauue9v7PnLRCzh9JI6JvIBaTlaiDKXbW9oBJ4bTq7oezu7ZSK9fRRVMnClsgEFzfNFil7emsRW+y4uzhbWtbMWkik4qsbTtUWtzNRgDyjHI6VoVWi2Q0IpnNKNS1u021tjggvyS2uMe45vQYV9a3KhAIBFeCBleNvZijcdkArI1MJiKiJId2+rPPlO2s0mJGXuE+lyXH80pGWYknvjyzXuUUNA5MCQlYCwtrfb1kNGLJybF9rmqD4fx5TIlVb9y4NKBLMhpJnPkKuWvXkr/zP6x6PZIkUbBnD+asLNK/+prsP/7kVERbu3+mlBQko5H8HTvJXbsWySQXu5asViSr1fbaajBgSkoi/7+K49cBJIsFS16eTcbSclp1OjK+/Q7JLG8usuTnYy0sRH/mLPrTp5GsVgznzhH7v4c4FdEWY3w8ppQUCvbsJW/zZizZ2WT//gfpCxeWyCZJFB4/bpvDGBtL/JNPcSqiLblr15H5yy9YDQasRiOSxYIpNZW4x5+wew+iRo/GEB1N+sKFJL35Jpb8fC5MnGQ7n/z2O2Xet1MRbYn930M2ObJXrJDnXLPGTraCPXs4FdGWEzfcyH0REdzWpg23DR3K9nICIOqSBhvyN+ff03y1LRqA87PH8tZbb5XpM2vWLPnFzo84v+0dbg4J4r2B73FDixsoPH6cmIlyHci2p0+VuVZw5TBnZaHbuxfD2bM0efxxFEU5ak5FyPllXIcPx6lDe9I++RT3ceNQ+/uT+d13eEyYQM4ffwDg3Ls3ur178ZvxEnnrN2C8eBFLhhyXr/L0xJKdLU+mVoPZTNC8uWhbtCTm9tvLyOPSry8Fu8qGfdaGposX4dK3L6fbta+T8QSNj9WSRCYS9yiUZEoSryHx4+gxhHz6SY3HatQhf48OamFT2kqlkpkzZzJ7dkn17iFDhpR0VmnxsRT9KuqzAXDq2NF22hgbiyYkBEtmJiofn+smhEmSJAqPHMG5a9ey58xmUCiwZGZybuAg1IGBBLzxOgC6/fvJXPwtDm3b0uz770h8eSbO3bpiSk0l68clduOEfP4ZSBLpX3yJz8MPkbN6NfkbN1UoU/oXX5Zpy9+0ifxN8jW5a9bY2osVNoBur7wdOXXO3DLX2xQ2QJGllzj9pQplqCuFDRD3v3LiCgXXFe5ATNHr/KLjvPXr622+Bqu0vVxKkjpJkoRWa5/kacCAUrsYVVrcrFZUCiWZ+swyY0WPGl12/HvvQRscjPd999Wd0HWM/vRp1P7+SCYTGYsWYUnPsCk1VZMmWNLLD1WsDeakJOKnPmbXZjh1irO9+wCUG/MOEP/4E7bXCc8+V2fy1DV+L71E6tyyCr9GFFnxtUXlK0c1WdJq/nfzvu9ePG65BYfwcHJXryZ37Tp8Hn4YkNCEhJA6Zw5+L72Exl9e7JasVszJyegOHsJ18CCMFy+ij4zEcOFCmR/eJk8+gcrNHU1o0zKfgUtx7tUL3T55A1Tot4uJffB/AAS88Tq6w4fJXfW3ra/byJEoXVxw6tIZTXAISmcnnLp2xZySAkoVpoQEHFq1RKHVYk5Lw5KRgcrbm6yffyHzhx9w7NAB/5kzuXjXXaiDAgl88y1cBw7AlJhI1LDhBLz5JnmbN+EQ1hxUKtxHjyLbL5rEpBU2GSSDHoVag7WwEIWjI5asTFRu7iiKUytbLKBU2mUNlSxmFAollvx8TLGxNLH0ofX9X6Pbv5/UOXPRn5QjzAJmvYFTt25EhIfz0EMP8dTFi+RkZfHlxx/TtigsuT5osO4RgG93XuCtf07yz5MD6BDswTfffENiYiJ333034eGl8owc/B7+fprBbToyImw0r/V9DQBLXh5ne/aqch6P228j8PXXUWgvP/tfsc8rb+NGEp562u6cy4ABFOzcedlzNCZ8HnkEh/Bw3G8Yj2Q0kvLOO2Qvl79UwZ9+gtvIkZhTU1F5eaFQqzHGxJDy3hyCP/wAhVqN0sk+N4wpMRF1YKB9ZfKiknKSJMlKVa2m8NAhHDt2RKHR1NuTlWQ0YkpOJm/9ejwnTkTlUbOopcaCZDIhWSwoG0EO+aSk3+2Udl0QFHg7gYG3Vnj+r7/+4sCBA7z99tucPn2amTNn8vvvv9dqrkbtHgFIyzcAcMOCncTMGc8jjzxSfkeVrGzdNa5kG7JLmt3c8H3mGdI+/rjSeXJWrCRnRUn19OCPP8Zt2FA7JV5RrUnJaiXzu++r3MwDXBWFHTh7NpnffYvhXJR9+7vv4jZ6FKBA0hei8vICiwXdgQM4duyI0tUVU0IiCq0GlYsLCmfncu/fEBWFytMTpbMzqFQoHSouNqFwcCDw7bcJfPttu/Zi6xDAoUULQhd+U+EYmnJy2xTLpVAoQCNv/HHu3r3CMeoKhVaLNjQUn4eubReJQqNBodFU3bEBEBh4a6UKtj44dOiQ7ck/IiKC1NTUOikIUxENWmk/NSycL7dGV92xSGnHFCQQU5Bgd6rJ1EdpMvXRMpeY09I4N3BQucMllEqCdTVQ+/piTksjfMd2dIcOowkKwqGlXJFHWbShqDoFi4vxvLWKxOxFaW5RqXDp18/WrA0JruCCEhxataqyj0BwLdOsWTOOHj3K6NGjSUhIwMXFpd4UNjRwpe1U3YQ+qppbAWpfX1tUiVWv50yXsot1l0ubI4dROjrK4VFGI9aCAtTe3lVfWAr30eXX3bxeFlMFgobOHXfcwcyZM5kyZQpms7kkqq2eaNBKu9oUWdoPNBvHL/GbamSFAigdHe3CAi05OVgLC4kaMrRa17dctxZNaGiliYEUDg6Vug4EAkHjxMXFhU8+qXl4X21pNEq7UkVcZGl7qpwwWAwUmgtx1jjXei6VhwcqDw8R3y1oNJitZiQkkOB8znmCXINw05ZN4FVTg6YmVGdsq2TFZDXhoKofA8ZgMRCXG0eoeygaZfmL0DqTDm2RoWeVrKgUKpQKJTmGHLIN2YR5hNVozvTCdDRKDTqTDi9HLxzV9btg22iU9vZz6QxuXUGV46I/gEtRgd8MfcZlKW3BlSHXmEtCXgIR3vKOV4PFgKPaEYvVAoBKqeJE+glC3UMpNBcSkxNDr8CSaCCDxcCO+B0MaToElaKkOk++MR8XjVwMIM+Yx6gVo8g3yUnGtkzaQhOnJuQZ8xiybAgtPFvQN6gv7bzboVFpGBQyiHUx6ziUcoiMwgw2x1W8u23ZDcto59POdvzhwQ/5LvI7AHbfuRuVUoWT2olUXSpRWVE8ulFeW7kr4i4kJNIL05k7cC5phWnM3DmTZ7s/i86k45EN8oL7TS1v4sUeLzJwWf2Ej40OG826mHVl2r8Z+Q2HUw9jtprxcvQivTCdp7s9TecfOwPgqHJEb9FXOK6fkx+phdWvXHQt8kKPF7ivff2EE9c65G/27NkcPXoUhULBzJkz6dSpk+1cXYX8ASw/EMeLK47x68N96NvSp/xOsXvh21F8POABFidsYkKrCbzVv+wOSkH1kCSJXGMuCoUCd619BkGT1USqLpUA5wDyTfl4OHggSRL5pnybZZdrzGXBoQUk5CewI2HH1bgFgeCqc/y+41V3uoR6C/nbt28fFy9eZNmyZURHRzNz5kyWLSsnkVMd0DVUzpn9z7HEipV2kXuku2sYi4E/ov64ZpX2vqR9+Dn7EeQaRGxuLEfSjtDNrxtBrkHE5Mbw74V/yTfmk2vMZW3MWtt1/s7+NHNvxr7kfZWMLmjstPZqzcOdHubXU79yKPXQ1RanzhkcMpht8dsq7bN0/FK2J2wnLjeOv8//XW6fjk060sy9Gf+c/4eHOz5se1o7kXGCt/e8Xe41VTF7wGxm7pRzHf1585+1GqM61Epp7969mxEjRgByYd2cnBzy8/NxdXWt4sqa09Rb3lzx895Y3p3QsfxORe6RAW4VZ9+zSlbb411p3uj7Bre3Lpuf4nJJyk/iztV3kqHP4KdxP3Ek9Qhjwsbw6eFPMVgMrI9ZL/sgrxApuhRSdOXXB7yaPN3taT45JC/itPZqzdmss3bnV92yiilrppBrLFuL8O3+b+Pt6M3jmx4HQKvUYrSWTeh07N5jNtfJiYwTTP5nMu182vHT2J8wWU1YJSsJ+QkEugZyJvMMPfx7YJEsdi6X8uj4g/3ncfWE1YS6h2KVrOSb8knKT2L1hdUMCBqAQqGgZ4BcYaf44TbHkEOGPgN/Z39cta4cSzvGhZwL3NTyJhQKBRmFGfg4VWCoVMGYsDGVnq+shFiaLg1PR0/UCjUKhYKNFzfyV9RfTAifwLBQ+8pCucZcFChw07phlazoTDryjHm4ad1w1da9Pqgu7ZvIuWBmD5xdab/3Br5X5rpJbSbVet4bW95Y62urS63cI6+99hqDBw+2Ke677rqLd999l+bNZaVZl+4RgLAZqwE4P3scSmU5X6K0s/B5T7htMR0PvQnIv3QtPVsCEJkeyZ2r76zWXCqFilW3rCLAJcC2WFEZJouJRccX8cXRL6p5Nw2Tkc1GsuHiBttxD/8eHEg5UKbfgOABjAkbg9lqJjonmiUn5S3REd4RnM48DcC7A97lxhY3irBEgaCGXLEdkfWwE75cDsdl072ZV9kTxXHaFpOt6Za/buH4fceRJKnaChvAIlkY/8f4yxW1TnFSO9GpSSdOZpzkzf5vsvDYQsI8wpg9YDYKFOjMOtIL0wlwCcBJLUfQaJUVF2WoywiC6T2n18k4AkFjxWq18sYbb3Du3Dk0Gg2zZs2iZcuW9TZfrZS2n58f6aWSFaWmpuLrW0FkRx3w+V3dePyXQ+hNlvI7FFvEFiP77t5Hr5/lCINLH1+/Hf2t7REVZOVllsx0W9KtXuT+99Z/CXEL4XTmafRmPdO3T2fdbetsCjNNl4avc83ft5HNRtodu2nd7MK7qgqnEhawQFB3bNq0iby8PJYuXUpsbCzvvvsuX3/9db3NVyul3b9/fxYsWMDkyZM5ceIEfn5+9eLPLibcXx47s6CCBPSllLaT2qncLvMHz7dT2CArL41CY7fKa7aaiUyPpMBUwNSNU6sl35KxS2jt1brCMMPikLb1t9una6yNwhYIBA2LmJgYW/RcaGgoiYmJDS/3SLdu3Wjfvj2TJ09GoVDwxhtv1LVcdngXpWl965+T3Ni5bMIgm3tEJ6dl3XHHjjKxraPDyqZnLQ+1Uk0Xvy5AxSE79blBQSAQ1J7fkjP5NSmjTse8M9CHSQEVp59o3bo1P/zwA/fddx8XL14kLi6OrKwsmlSzwHhNqbVP+4UXXqhLOSrFp0hpN3Gt4LFfXdQeKye393T05Ph9x/ngwAe082nH2OZj61QeobAFAkExgwcP5tChQ9x99920adOGFi1a1Os6X6PYEalQKOgW6omjpoLHjeJtowEd7Jqf7/F8PUsmEAgaEpMCvCu1iuuLZ5991vZ6xIgR+PjULlSzOjTYwr6X0tTbmdhMXfkniy3fXQuunEACgUAAnD59mpdffhmA7du3065dO5TK+lOtjcLSBvB3dyQ93yD8yQKBoEHRunVrJEni9ttvx8HBgfnz59frfI1GaefoTOhNVvINZtwcy8mf3XsqHFoCkmRX700gEAjqE6VSyZw5c67cfFdspsvEx1VejMwpNJXfoUk4mAogN/EKSiUQ1ACrRTYqaoskyWMUv96/CMxGMOnlyKkts2HvN/DvDLluajFmIyQcgqL6pRWSHFn5ebMB8tMqPnfgu7LtuYkl45oNcOofiNtfct5qle/FYpLPm0plD7RaQJ9TcixJkHoKDv4A+lzITbKfS5Lk+5zlAfsXw3fjoKBoP4mxoGTMnR9DwkE4ux4KMuRrDv0oX/fzJHnOlJP246afg5yEsvMlHpZlT4+C78bby1tPNBpLu3NTTwCydSZCytkUSZPW8v8Z58Cj6jJZgiuMqVD+cDuWyhr470uw9yt47hQUZsn//NpBRhRsmwujZ8PnRalY7/gJdn8BN38G29+H9hPg6FI48Tu8cA7WvyZfP+Y9SDsDYQPkub4aCMnHSuZsMRQixsOaCqKfNM5gqmDt5FL8O8LUHfKTnVEHswNLzTME/DuAd3NYXcmC+IBnYedHFZ9v2gfi9lR8vrKx/3664nOV4eAOhktyvXSaDMeWVn3tP8/Ubs6a8vdTlZ9f/Zz8//s13Jl4bh3MCa2dTFBybY8H4YZK/q6XQYOuxl6aQ7FZ3PrFLr69vwfDIvzLdshLhg/awLj50OvhOpnzmkeSQJ8NF3ZAYGdwCwS1VrY+Dv0A0Zvh/n/kfpEroc1Y+Ly3/F73eAC0rtDrETnk8vBP0PMhyImHo7/Czg+v9t0JBFeXWTW3uht9NfbSeDvL7pGsggrcI67+gEJ+XLkWyDwvW6a+beRjow6M+bDpLdkSdAuE3Z/J58IGgkdTyLpgi1WvM2Z5lN++r6hiemnlvOG1up1bUEK7m2WrO7AzrHgA8lPg7pXw820w8Xs4+RcMew0kqxwCa8iDPx+DpCPQ/lbo+wQsHiGfLw+tK3SdIj/51AetRkLnydB8kOyKOPg95MSBiy/0+B8kHQW/CNmNUfzZAlAo7WV+KUZ2BS3oBk5e8tNVMW3Gy09aXs1kw8PRAxIOwIY3oP9T8ncn7TQ8dRg8QmVXRtopCO0LyqJw4vw0OP6bbHgkl9pcd9tiWPk/+3ty8YU7fgaNkyx3aB/Zwg8fJRs49USjsbRzCk10fnM9r45vy0MDW5TfqVjBlPcLl58mP2r3ngpbZ8t/BGcfaFm9OpA1JuUEfFlU2XzcfDi/FVqPgVVP1M98DZmwgTBmDsTshLUvlbQH94D7Vsk+z/NbZKt9zxdQkAZj58kWvsZR/v/8Fmg2QHaN9Pyf7MZwdC/y85pBqYboTRB/EHo/Cj9PlP2pD64Fz6b28mREy19450vieWu6iK3PlZVl5Eq45QtwL2e37rWAxSQrT30OOHpCPYazXe9UR3c2GqUtSRJtXl3LA/3DeHlc2/I7FSvtlxPAoVQulN1fwLqXK5+g/QTZ0mjSBhzcwMmzeoJZzLDpTdj1afX6NyQe2wX/fQrDX5ct+21zZeXXdQq0u0VWoMXW81OH5S+sk1eJYivMhoVDYdIS8AyVfdFuAXIfTfk5YAQCQcVcU+4RhUKBv4cDybkV16az8du9cM/v8muLuWqFDXDiD/lfQ2LsPPmxq8OtslXn0kS25gx5oHYClbp869Bqrb41dGtRNjKPYGh+SS3C/k/J/yrCyVNW5sUE10+2RIGgoXP27FmmTZvG/fffz5QpU0hKSmL69OlYLBZ8fX15//330Wqrzs9fHRqN0gaIyywkLrOQTyZ3Lb/DqHdg/avyY/IsD3h4MywsVWmj50Mw/gP5tT4XMqPhmyH1J/ArKfLjPciPlsnHoVn/y48jdyhVZbu8scTjq0BwxdDpdLz99tv07dvX1vbpp59y1113MXbsWD788ENWrFjBXXfdVSfzNSqlXYzJYkWjKkcx9X1CVtrFlFbY0y/Y+zAd3SGoa4n/OzkSCjPlkLOahgnNTJQXf5SVpGJ09JDD0AQCwTWFVqtl4cKFLFy40Na2d+9e3nxTrqI1dOhQvv322+tTaU/u2ZSl++O4kF5Aa3+3sh0UCngtA96+JFlLr0fKLjpdSulkU7UI1REIBFeflQfj+e1AXJ2OOalHU27rXvHanFqtRq22V6WFhYU2d4iPjw9paRVsSqoFjUpp39Q5iKX74youhgCyn/e1DDi2TI5CaHsj+NRf6R+BQCCojLqO9aiV0jabzbzyyivExsZisViYPn06PXr0qFPByqM450i+3lx5R5Uaut5d7/IIBIKGxW3dQyq1iq8Uzs7O6PV6HB0dSUlJwc/Pr87GrtWK1V9//YWTkxO//vor77777hVLlqJVy+LuPl+3lSkEAoGgLunXrx/r1q0DYP369QwcOLCKK6pPrSztm266iRtuuAEAb29vsrOz60ygynDWygt9i3de4LUb2l2ROQUCgaAyIiMjmTt3LgkJCajVatatW8f8+fOZMWMGy5YtIygoiFtuuaXO5quV0tZoSlKj/vDDDzYFXt+EeIkNGwKBoGHRoUMHlixZUqb9u+/KyXpYB1SptJcvX87y5cvt2p588kkGDhzIzz//zIkTJ/jqq3rKV3AJoviBQCC43qlSaU+cOJGJEyeWaV++fDmbN2/miy++sLO8BQKBQFB/1GohMi4ujqVLl/LZZ5/h4FBBhfR6YnLPphVXZRcIBIJrnFr5tJcvX052djaPPPKIrW3x4sV1tre+Mpq4OpBZYMBqlVAqhbtEIBBcX9RKaT/33HM899xzdS1LtfBx1WKVILvQhLdL/f9ICK4NTBY5J3O56Q+qQXFB6Ty9CZVSgbO25l+dPL0JtVKJk7aSdAcVYLZYScrR4+/uiMlixUGtZNHOC0zsHkJMRgGt/NwY98kO1CoFwyP80ZstvHtLBxQKBXGZOpy1KnxcHSg0WsrMn5ZnwN1JjcUqVXpfKbl6ziTnMai1L1arhEJRss4kSRJpeQb83B3trknMLgQgyNMJSZLYfi6dv48m8u6EDqgUCvRmK84aFQazlcScQpy1KgI9SgIOcnQmPJw1tjnOpuTz+ZYoXhwt55lv6u1s6ytJEl9tO8/ctad5ang4JouVwa196dPCh9Q8PR5OGixWiX0XMjmZlEuh0cIjg1oQk67jxs92AuDjouX7B3oR7u+Ko6bkfcrWGfF0ttc3epOF5QfiaOXnRoHBzEM/HmD9s4PK361dhzSa1KzFrDqayFO/HmbDs4MIL/XmdH97AxkFRmLmjK/T+QSXh9FspcBgRqGQlUPpv1nYjNUA/PPkAM6nF/DmqhM8NLAFsZk6VhyM4+2bOzDjdzkR/ad3duWpXw/zz5MDWLo/lu7NvNh3IZNf98Xx0pgIzqflU2A0M7i1L/PWnmHe7Z3o08KH9m+sKyPT1heGMGT+1jq5v5g54zFZrDy99DBrjieXOf/ooBZ8vf18ncx1pVArFZit9mrhxs5B/H1U1F+tLi+ObsPjQ1vV+LprKp92Mbui0rlr0V5+ebg3/Vo2sbUXK4Cnh4fz7MjWZa574Lt9bDlTsv//qyndGNMhsEy/a43SlkppsnVG1kYm4+fuwDv/nGJ0hwAe7N8cdyc1W06nMfWng4CslCRJYuOpVFr6ujDsg20AuDvKltlfT/THx8WBDzecZVKPpizdH8vPe2Ov6D0KBA2R2hiQ11Q+7WK8ilwiZ5LzbEo7V19SguyTTefKKO1ihV6aqT8dsr3+7oGeDGnt26BCCk0WK2uOJzG6fQD7YzIxWaxsO5PGD7svAhDo4UhSTjVyi1eTL7dG8+XW6DLt5b13ALlFqQRGfLjd1rZkz8U6k+daxc1BTZ6hijQM5fDpnV1x0aro36oJ/eZsJrPAyLf392B3dAZT+jRj2f44Hh3UkgMXM2kf5MFfRxJ479/TANzWLYSHBzXnxeXHUCrgaLx9QjSNSsHt3ZvSzMeZOUXXVAdPZw3ZupLvnreLtsK8QA/2b86h2Cw+vqMLR+OzSczWo1SAl7OWPIOZQxezyC400qOZN59sOlfhnKffHkNspo5RH23n/ds78eKKkqLNDmolG58bTIiXk+27HJWax/x1Z7m7TyjbzqSxaOcFdkwfSoiXE8m5elJzDbQNdLfttpYkidPJeXy+JYp/jsnV3iMC3Pjxf714cfkxtp0tMfyGR/jxyvi2KBQKErML6d+qCRfSC4jJKKBvi0uS1tUhjc7S1pssRLy2Fn93B/bOHAFAbIaOQe9vsfUp/Qtntlhp9cq/1R7/chW43mRh1dFEYjN0fLYlyu6cg1qJwVxBjb5rmBljIwhwd8TVQc1DPx6wtY/rGMDnd3XDKoHOaEapUHAyKZfYDB0j2vmTrTPSzMcFSZI4Fp9DpxAP9pzPpFdzb5RF/lRJkohOy6eVnxt5ehP/Hk/m1m7B3PLFf9zfrzntAt1pF+RuJ8/x+BwCPBzxdbu8KKSY9AJ+3H2Rb/+7wO/T+tG1qaftc2OxSqiukYXyixkFADTzcbnKklz7XJPuEZCtv1u6BPFxUTGEY/HZ3PTZf7bzpZV2aUuxdHtcpo6B80oUfUU083HmqWHhPL/8KM18nHn75g4MDG/C7DWneHhQC77YEs33u2Lq4K7qhxdHt+H9dWfKtI9o68+MsRHsu5DJbd2DydebWX08CaPZyq3dQvBy1rDlTCrrT6RwMUPHK+Pb4qBW2vmkLVaJz7dEcVPnIMKauJCrN6FWKlApFTioa77YJhBc71yT7hEAf3cH2+MMyEV/S2OyWNEZLHR+a72t7a/H+9v1aertTMyc8VisEm+siuSnPeX7YS9m6Hh++VHb63u/3Wc7t3DHhcu+F183B9LyDLbjnmFeHI7NxmyV2DdzOChAq1KiVSsxWSQ8nDRVhjsWRzoUU9mCSCs/uZamg6uKe/uG2Z0bFuHPsAj/Cq9VKRU8NTzcduzuKDZZCQT1TaNU2u6OGvJKpWfNLbT3EYZf4g5xd1TTualnuWOplAreuaUj79zSEYB8g5kO5UQc1IRv7unOtrNpvDuho117XcWWVzVGQ/LNCwSCuqVRKu1zqfmcS823HetNFgA+mNjZZhWX5tis0dUe29VBXeGqr8UqcfBiFpO+3s0nk7sQn1WIu6Oaey6xUAFGtQ8o0yY2AwkEgsulUSptNwe1nQIsXtzr36oJv0/rx61f7ALg/ds7MbFH0zqbV6VU0Ku5t4gFFwgEV41GqbRHdwjgv6h027HBLFvajhol3UK9hFIVCATXLLXb03uVOR6fQ1KO3lZ7TW+SLW0RsSAQCK51GqXSHtLGF5AXDaHE0nZQN8rbEQgEgmrTKLVccaxw8e4rg9mKVqUUC30CgeCap1EqbU8nOR64eAut3mQRVrZAILguaJSazrMoAVLxphqD2YqDplHeikAgENSIRqnpipV2dpHSNhW5RwQCgeBa57I0XXp6Oj179mTv3r11JU+1cC9yj+ToZJ+2yWJFLZS2QCC4DrgsTTdv3jyaNq27zSvVxcPJ3j1iskhoVGIRUiAQXPvUWmnv3r0bFxcXWrcuW3CgvimOxy7OrmeyWGtdRkogEAgaE7XSdEajkc8//5xnn322ruWpEen5Je4RrYgeEQgE1wFVbmNfvnw5y5cvt2sbNGgQEydOxN3dvYKrrhxWq4TJIqEWMdoCgeA6oEqlPXHiRCZOnGjXNnnyZKxWKz///DOxsbEcO3aMTz75hPDw8ApGqT/2xWRiFO4RgUBwnVCrhFFLly61vZ4xYwYTJky44gp7+dS+TPxqN7GZOkwWKy7aRpn7SiAQCGpEozVPW/rKFVd2R2dgMFlxFJtrBALBdcBlm6dz5sypCzlqjJezBo1KgYeTBr3ZgoNGZPgTCATXPo3WPFUoFJgsEt/vikFvtOAo0rIKBILrgEartEujN1tx0l4TtyIQCASV0qg13QP9w3DWqtCbhKUtEAiuDxp1yEWYjws6Y3GpMaG0BQLBtU+jtrRDfZxtr0X0iEAguB5o1JouzMfF9lpY2gKB4HqgUSvtYE8n22uhtAUCwfVAo1bapZNEJeUUXkVJBAKB4MrQqJV2aZyEpS0QCK4DGr3SfmJoKwAmdAu5ypIIBAJB/dOoQ/4AnhvZmocHtbBVsxEIBIJrmUZvaSuVCqGwBQLBdUOjV9oCgUBwPSGUtkAgEDQihNIWCASCRkStlfbixYu5+eabue222zh27FhdyiQQCASCCqhV9Mi5c+dYvXo1K1eu5MyZM2zatIlOnTrVtWwCgUAguIRaKe0tW7YwduxY1Go17du3p3379nUtl0AgEAjKoVZKOyEhAZVKxf/+9z/MZjMvv/wyERERtvMWi5wuNTk5uW6kFAgEguuAYp1ZrEPLo0qlvXz5cpYvX27Xlp6ezsCBA1m0aBEHDx7klVdeYeXKlbbzaWlpANx99921ElwgEAiuZ9LS0mjWrFm55xSSJEk1HfDTTz+lRYsW3HDDDQD06dOHPXv22M7r9XoiIyPx9fVFpRI5QQQCgaA6WCwW0tLS6NChA46OjuX2qZV7ZNCgQSxdupQbbriB6OhoAgMD7c47OjrSo0eP2gwtEAgE1zUVWdjF1Eppd+nShe3bt3PHHXcA8Prrr9dmGIFAIBDUkFq5R+qT2bNnc/ToURQKBTNnzqzzUMKzZ88ybdo07r//fqZMmUJSUhLTp0/HYrHg6+vL+++/j1arZdWqVfzwww8olUomTZrExIkTMZlMzJgxg8TERFQqFe+99x5Nmzbl9OnTzJo1C4A2bdrw5ptvArBo0SLWrl2LQqHgiSeeYPDgwRXKNW/ePA4ePIjZbObRRx+lY8eOV12uwsJCZsyYQUZGBgaDgWnTphEREXHV5SpGr9dzww03MG3aNPr27XvV5dq7dy9PP/004eHhALRu3ZqHHnroqssFsGrVKhYtWoRareapp56iTZs2V12u5cuXs2rVKttxZGQkv/76a7XHzMvL4/nnnycvLw9nZ2c++OADPD092bVrFx9++CEqlYpBgwbx+OOPA9XXLQUFBbz00kvk5ORgMpl4/PHH8fX1vepy2ZAaEHv37pUeeeQRSZIkKSoqSpo0aVKdjl9QUCBNmTJFevXVV6UlS5ZIkiRJM2bMkNasWSNJkiR98MEH0s8//ywVFBRIo0aNknJzc6XCwkJp/PjxUlZWlvT7779Ls2bNkiRJknbs2CE9/fTTkiRJ0pQpU6SjR49KkiRJzz33nLR161YpNjZWmjBhgmQwGKSMjAxp9OjRktlsLleu3bt3Sw899JAkSZKUmZkpDR48uEHItXr1aumbb76RJEmS4uPjpVGjRjUIuYr58MMPpVtvvVVauXJlg5Brz5490pNPPmnX1hDkyszMlEaNGiXl5eVJKSkp0quvvtog5CrN3r17pVmzZtVozAULFkgLFy6UJEmSli5dKs2bN0+SJEkaO3aslJiYKFksFunOO++Uzp07VyPdsmTJEmn+/PmSJElScnKyNHr06AYhVzENahv77t27GTFiBAAtW7YkJyeH/Pz8Ohtfq9WycOFC/Pz8bG179+5l+PDhAAwdOpTdu3dz9OhROnbsiJubG46OjnTr1o1Dhw6xe/duRo4cCUC/fv04dOgQRqORhIQE269j8Rh79+5l4MCBaLVavL29CQ4OJioqqly5evbsySeffAKAu7s7hYWFDUKucePG8fDDDwOQlJSEv79/g5ALIDo6mqioKIYMGdJg/o7l0RDk2r17N3379sXV1RU/Pz/efvvtBiFXaT7//HMefvjhGo1ZWq7ivnFxcXh4eBAYGIhSqWTw4MHs3r27RrrFy8uL7OxsAHJzc/H09GwQchXToJR2eno6Xl5etmNvb29b+GBdoFary6zIFhYWotVqAfDx8SEtLY309HS8vb3LyFG6XalUolAoSE9Px93d3da3qjHKQ6VS4ewsV5ZfsWIFgwYNahByFTN58mReeOEFZs6c2WDkmjt3LjNmzLAdNxS5oqKimDp1KnfeeSf//fdfg5ArPj4evV7P1KlTueuuu9i9e3eDkKuYY8eOERgYiEqlqtGYpdt9fHxITU0lLS2twr7V1S3jx48nMTGRkSNHMmXKFKZPn94g5CqmQRdBkK6wu72i+WrSXtMxSrNx40ZWrFjBt99+y6hRoxqMXEuXLuXUqVO8+OKLdv2vllx//vknXbp0oWnTppc9f13KFRYWxhNPPMHYsWOJi4vj3nvvtdskcTX/jtnZ2Xz22WckJiZy7733Noi/YzErVqxgwoQJ9TJ/RVTW/6+//iIoKIjFixdz+vRpHn/8cdzc3K66XMU0KEvbz8+P9PR023Fqaiq+vr71OqezszN6vR6AlJQU/Pz8ypWjuL34V9BkMiFJEr6+vrZHqcrGKG6viB07dvDVV1+xcOFC3NzcGoRckZGRJCUlAdC2bVssFgsuLi5XXa6tW7eyadMmJk2axPLly/niiy8axPvl7+/PuHHjUCgUhIaG0qRJE3Jycq66XD4+PnTt2hW1Wk1oaCguLi4N4u9YzN69e+natSve3t41GrO0XNXpW13dcujQIQYMGABAREQEBoOBrKysqy5XMQ1Kaffv359169YBcOLECfz8/HB1da3XOfv162ebc/369QwcOJDOnTtz/PhxcnNzKSgo4NChQ/To0YP+/fuzdu1aQM6/0rt3bzQaDS1atODAgQN2Y/Tp04etW7diNBpJSUkhNTWVVq1alStDXl4e8+bN4+uvv8bT07PByHXgwAG+/fZbQHZd6XS6BiHXxx9/zMqVK/ntt9+YOHEi06ZNaxByrVq1isWLFwPyjraMjAxuvfXWqy7XgAED2LNnD1arlaysrAbzdwRZebm4uKDVams8Zmm5ivuGhISQn59PfHw8ZrOZLVu20L9//xrplmbNmnH06FFATtnh4uJCy5Ytr7pcxTS4kL/58+dz4MABFAoFb7zxhl1Ok8slMjKSuXPnkpCQgFqtxt/fn/nz5zNjxgwMBgNBQUG89957aDQa1q5dy+LFi1EoFEyZMoWbbroJi8XCq6++SkxMDFqtljlz5hAYGEhUVBSvv/46VquVzp078/LLLwOwZMkS/v77bxQKBc888wx9+/YtV65ly5axYMECmjdvbmubM2cOr7766lWVS6/X88orr5CUlIRer+eJJ56gQ4cOvPTSS1dVrtIsWLCA4OBgBgwYcNXlys/P54UXXiA3NxeTycQTTzxB27Ztr7pcILu4VqxYAcBjjz1Gx44dG4RckZGRfPzxxyxatAigRmMWFBTw4osvkp2djbu7O++//z5ubm7s37+f+fPnAzBq1Cj+97//AdXXLQUFBcycOZOMjAzMZjNPP/00vr6+V12uYhqc0hYIBAJBxTQo94hAIBAIKkcobYFAIGhECKUtEAgEjQihtAUCgaARIZS2QCAQNCKE0hYIBIJGhFDaAoFA0IgQSlsgEAgaEf8HrueaMYB+EyUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scl489/.env/lib/python3.7/site-packages/IPython/core/pylabtools.py:132: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = 2\n",
    "\n",
    "for i in range(n_EL+1):\n",
    "    plt.plot(np.arange(epochs), levels_hist[:,i]*T, label = str(i))\n",
    "\n",
    "plt.title(\"Energy levels\")    \n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for i in range(n_EL+1):\n",
    "    plt.plot(np.arange(epochs), logits_hist[:,i], label = str(i))\n",
    "\n",
    "plt.title(\"Probability of mixed states\")    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy: \n",
      "[-1.2679517  -0.49136666  0.10681308  0.4916364   0.8914576   1.37502284\n",
      "  1.90402944  2.45808609  3.0898353   3.86726354  4.63523604]\n",
      "Probabilities: \n",
      "[0.46318527 0.21305324 0.11713913 0.07972148 0.05344846 0.03295532\n",
      " 0.01941694 0.01115725 0.00593187 0.00272621 0.00126483]\n"
     ]
    }
   ],
   "source": [
    "print(\"Energy: \")\n",
    "print(levels_fin)\n",
    "print(\"Probabilities: \")\n",
    "print(logits_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001429300599833507\n"
     ]
    }
   ],
   "source": [
    "print(np.amax(np.abs(np.matmul(var_HC_N.T, var_HC_N) - np.identity(n_EL+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
